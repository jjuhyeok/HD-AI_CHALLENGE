{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fb92a9eb-6b28-4ac5-a4c4-9e5baf5dc9ae",
   "metadata": {},
   "source": [
    "# Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f5ec1ce8-e37d-43e9-8909-98034a721ca9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import random\n",
    "import numpy as np\n",
    "from autogluon.tabular import TabularDataset, TabularPredictor\n",
    "import autogluon.core as ag\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import lightgbm as lgb\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "def seed_everything(seed):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "\n",
    "seed_everything(42) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a3794db-a395-456c-be4d-d9b3d3aa6848",
   "metadata": {},
   "source": [
    "# Data Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "32bbff56-2b00-49e2-8896-73f1199c79eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('train.csv').drop(columns=['SAMPLE_ID'])\n",
    "\n",
    "test = pd.read_csv('test.csv').drop(columns=['SAMPLE_ID'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7035713d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ARI_CO</th>\n",
       "      <th>ARI_PO</th>\n",
       "      <th>SHIP_TYPE_CATEGORY</th>\n",
       "      <th>DIST</th>\n",
       "      <th>ATA</th>\n",
       "      <th>ID</th>\n",
       "      <th>BREADTH</th>\n",
       "      <th>BUILT</th>\n",
       "      <th>DEADWEIGHT</th>\n",
       "      <th>DEPTH</th>\n",
       "      <th>...</th>\n",
       "      <th>V_WIND</th>\n",
       "      <th>AIR_TEMPERATURE</th>\n",
       "      <th>BN</th>\n",
       "      <th>ATA_LT</th>\n",
       "      <th>DUBAI</th>\n",
       "      <th>BRENT</th>\n",
       "      <th>WTI</th>\n",
       "      <th>BDI_ADJ</th>\n",
       "      <th>PORT_SIZE</th>\n",
       "      <th>CI_HOUR</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CN</td>\n",
       "      <td>EKP8</td>\n",
       "      <td>Bulk</td>\n",
       "      <td>30.736578</td>\n",
       "      <td>2020-10-15 4:03</td>\n",
       "      <td>Z517571</td>\n",
       "      <td>30.0</td>\n",
       "      <td>28</td>\n",
       "      <td>73100</td>\n",
       "      <td>20.0</td>\n",
       "      <td>...</td>\n",
       "      <td>3.77</td>\n",
       "      <td>15.9</td>\n",
       "      <td>2.730798</td>\n",
       "      <td>12</td>\n",
       "      <td>42.01</td>\n",
       "      <td>43.16</td>\n",
       "      <td>40.96</td>\n",
       "      <td>1407.668330</td>\n",
       "      <td>0.001660</td>\n",
       "      <td>3.048333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CN</td>\n",
       "      <td>EUC8</td>\n",
       "      <td>Container</td>\n",
       "      <td>63.220425</td>\n",
       "      <td>2019-09-17 2:55</td>\n",
       "      <td>U467618</td>\n",
       "      <td>30.0</td>\n",
       "      <td>15</td>\n",
       "      <td>37900</td>\n",
       "      <td>20.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-6.72</td>\n",
       "      <td>24.5</td>\n",
       "      <td>4.289058</td>\n",
       "      <td>10</td>\n",
       "      <td>67.53</td>\n",
       "      <td>64.55</td>\n",
       "      <td>59.34</td>\n",
       "      <td>2089.046774</td>\n",
       "      <td>0.001614</td>\n",
       "      <td>17.138611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CN</td>\n",
       "      <td>NGG6</td>\n",
       "      <td>Container</td>\n",
       "      <td>90.427421</td>\n",
       "      <td>2019-02-23 6:43</td>\n",
       "      <td>V378315</td>\n",
       "      <td>50.0</td>\n",
       "      <td>7</td>\n",
       "      <td>115000</td>\n",
       "      <td>20.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>9.4</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>14</td>\n",
       "      <td>65.30</td>\n",
       "      <td>66.39</td>\n",
       "      <td>56.94</td>\n",
       "      <td>603.193047</td>\n",
       "      <td>0.001743</td>\n",
       "      <td>98.827500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>RU</td>\n",
       "      <td>NNC2</td>\n",
       "      <td>Container</td>\n",
       "      <td>8.813725</td>\n",
       "      <td>2022-08-13 12:57</td>\n",
       "      <td>D215135</td>\n",
       "      <td>30.0</td>\n",
       "      <td>10</td>\n",
       "      <td>27600</td>\n",
       "      <td>10.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.31</td>\n",
       "      <td>22.8</td>\n",
       "      <td>2.345875</td>\n",
       "      <td>14</td>\n",
       "      <td>90.45</td>\n",
       "      <td>93.65</td>\n",
       "      <td>88.11</td>\n",
       "      <td>1107.944894</td>\n",
       "      <td>0.000197</td>\n",
       "      <td>96.030556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CN</td>\n",
       "      <td>NGG6</td>\n",
       "      <td>Container</td>\n",
       "      <td>81.435335</td>\n",
       "      <td>2015-09-08 14:24</td>\n",
       "      <td>Z156413</td>\n",
       "      <td>30.0</td>\n",
       "      <td>22</td>\n",
       "      <td>18100</td>\n",
       "      <td>10.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>22</td>\n",
       "      <td>45.75</td>\n",
       "      <td>48.89</td>\n",
       "      <td>45.92</td>\n",
       "      <td>820.288044</td>\n",
       "      <td>0.001743</td>\n",
       "      <td>42.078056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>220050</th>\n",
       "      <td>IN</td>\n",
       "      <td>UJM2</td>\n",
       "      <td>Bulk</td>\n",
       "      <td>30.199074</td>\n",
       "      <td>2022-03-23 8:35</td>\n",
       "      <td>Y242521</td>\n",
       "      <td>30.0</td>\n",
       "      <td>2</td>\n",
       "      <td>63500</td>\n",
       "      <td>20.0</td>\n",
       "      <td>...</td>\n",
       "      <td>3.54</td>\n",
       "      <td>36.5</td>\n",
       "      <td>4.306719</td>\n",
       "      <td>14</td>\n",
       "      <td>111.93</td>\n",
       "      <td>120.65</td>\n",
       "      <td>113.90</td>\n",
       "      <td>2077.159292</td>\n",
       "      <td>0.000217</td>\n",
       "      <td>53.400833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>220051</th>\n",
       "      <td>CN</td>\n",
       "      <td>QQW1</td>\n",
       "      <td>Bulk</td>\n",
       "      <td>55.408765</td>\n",
       "      <td>2022-06-16 14:27</td>\n",
       "      <td>D236761</td>\n",
       "      <td>30.0</td>\n",
       "      <td>16</td>\n",
       "      <td>26500</td>\n",
       "      <td>10.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.96</td>\n",
       "      <td>28.2</td>\n",
       "      <td>2.651752</td>\n",
       "      <td>22</td>\n",
       "      <td>108.43</td>\n",
       "      <td>114.13</td>\n",
       "      <td>109.56</td>\n",
       "      <td>2067.433444</td>\n",
       "      <td>0.000595</td>\n",
       "      <td>83.960833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>220052</th>\n",
       "      <td>CN</td>\n",
       "      <td>YRT6</td>\n",
       "      <td>Bulk</td>\n",
       "      <td>59.018184</td>\n",
       "      <td>2017-11-11 22:23</td>\n",
       "      <td>J661243</td>\n",
       "      <td>40.0</td>\n",
       "      <td>13</td>\n",
       "      <td>93200</td>\n",
       "      <td>20.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6</td>\n",
       "      <td>61.25</td>\n",
       "      <td>62.21</td>\n",
       "      <td>55.70</td>\n",
       "      <td>1333.609109</td>\n",
       "      <td>0.000360</td>\n",
       "      <td>65.850000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>220053</th>\n",
       "      <td>SG</td>\n",
       "      <td>GIW5</td>\n",
       "      <td>Container</td>\n",
       "      <td>1.768630</td>\n",
       "      <td>2022-07-14 7:58</td>\n",
       "      <td>Q635545</td>\n",
       "      <td>30.0</td>\n",
       "      <td>6</td>\n",
       "      <td>25000</td>\n",
       "      <td>20.0</td>\n",
       "      <td>...</td>\n",
       "      <td>3.36</td>\n",
       "      <td>31.7</td>\n",
       "      <td>2.557156</td>\n",
       "      <td>15</td>\n",
       "      <td>97.73</td>\n",
       "      <td>99.10</td>\n",
       "      <td>95.78</td>\n",
       "      <td>1601.291086</td>\n",
       "      <td>0.002615</td>\n",
       "      <td>0.997500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>220054</th>\n",
       "      <td>CN</td>\n",
       "      <td>EKP8</td>\n",
       "      <td>Bulk</td>\n",
       "      <td>32.152412</td>\n",
       "      <td>2021-06-04 14:54</td>\n",
       "      <td>V628821</td>\n",
       "      <td>40.0</td>\n",
       "      <td>10</td>\n",
       "      <td>87200</td>\n",
       "      <td>20.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.84</td>\n",
       "      <td>19.8</td>\n",
       "      <td>3.177475</td>\n",
       "      <td>22</td>\n",
       "      <td>70.10</td>\n",
       "      <td>71.89</td>\n",
       "      <td>69.62</td>\n",
       "      <td>2115.046707</td>\n",
       "      <td>0.001660</td>\n",
       "      <td>8.464167</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>220055 rows × 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       ARI_CO ARI_PO SHIP_TYPE_CATEGORY       DIST               ATA       ID  \\\n",
       "0          CN   EKP8               Bulk  30.736578   2020-10-15 4:03  Z517571   \n",
       "1          CN   EUC8          Container  63.220425   2019-09-17 2:55  U467618   \n",
       "2          CN   NGG6          Container  90.427421   2019-02-23 6:43  V378315   \n",
       "3          RU   NNC2          Container   8.813725  2022-08-13 12:57  D215135   \n",
       "4          CN   NGG6          Container  81.435335  2015-09-08 14:24  Z156413   \n",
       "...       ...    ...                ...        ...               ...      ...   \n",
       "220050     IN   UJM2               Bulk  30.199074   2022-03-23 8:35  Y242521   \n",
       "220051     CN   QQW1               Bulk  55.408765  2022-06-16 14:27  D236761   \n",
       "220052     CN   YRT6               Bulk  59.018184  2017-11-11 22:23  J661243   \n",
       "220053     SG   GIW5          Container   1.768630   2022-07-14 7:58  Q635545   \n",
       "220054     CN   EKP8               Bulk  32.152412  2021-06-04 14:54  V628821   \n",
       "\n",
       "        BREADTH  BUILT  DEADWEIGHT  DEPTH  ...  V_WIND  AIR_TEMPERATURE  \\\n",
       "0          30.0     28       73100   20.0  ...    3.77             15.9   \n",
       "1          30.0     15       37900   20.0  ...   -6.72             24.5   \n",
       "2          50.0      7      115000   20.0  ...    0.00              9.4   \n",
       "3          30.0     10       27600   10.0  ...    2.31             22.8   \n",
       "4          30.0     22       18100   10.0  ...     NaN              NaN   \n",
       "...         ...    ...         ...    ...  ...     ...              ...   \n",
       "220050     30.0      2       63500   20.0  ...    3.54             36.5   \n",
       "220051     30.0     16       26500   10.0  ...    0.96             28.2   \n",
       "220052     40.0     13       93200   20.0  ...     NaN              NaN   \n",
       "220053     30.0      6       25000   20.0  ...    3.36             31.7   \n",
       "220054     40.0     10       87200   20.0  ...   -0.84             19.8   \n",
       "\n",
       "              BN ATA_LT   DUBAI   BRENT     WTI      BDI_ADJ  PORT_SIZE  \\\n",
       "0       2.730798     12   42.01   43.16   40.96  1407.668330   0.001660   \n",
       "1       4.289058     10   67.53   64.55   59.34  2089.046774   0.001614   \n",
       "2       0.000000     14   65.30   66.39   56.94   603.193047   0.001743   \n",
       "3       2.345875     14   90.45   93.65   88.11  1107.944894   0.000197   \n",
       "4            NaN     22   45.75   48.89   45.92   820.288044   0.001743   \n",
       "...          ...    ...     ...     ...     ...          ...        ...   \n",
       "220050  4.306719     14  111.93  120.65  113.90  2077.159292   0.000217   \n",
       "220051  2.651752     22  108.43  114.13  109.56  2067.433444   0.000595   \n",
       "220052       NaN      6   61.25   62.21   55.70  1333.609109   0.000360   \n",
       "220053  2.557156     15   97.73   99.10   95.78  1601.291086   0.002615   \n",
       "220054  3.177475     22   70.10   71.89   69.62  2115.046707   0.001660   \n",
       "\n",
       "          CI_HOUR  \n",
       "0        3.048333  \n",
       "1       17.138611  \n",
       "2       98.827500  \n",
       "3       96.030556  \n",
       "4       42.078056  \n",
       "...           ...  \n",
       "220050  53.400833  \n",
       "220051  83.960833  \n",
       "220052  65.850000  \n",
       "220053   0.997500  \n",
       "220054   8.464167  \n",
       "\n",
       "[220055 rows x 26 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = train[train['DIST'] != 0]\n",
    "train = train.reset_index(drop = True)\n",
    "train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f12c1388-bc30-4840-9f86-1c10d31a3a14",
   "metadata": {},
   "source": [
    "# Data Pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "44a236d9-144d-4b53-a972-f260bd08eaae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# datetime 컬럼 처리\n",
    "train['ATA'] = pd.to_datetime(train['ATA'])\n",
    "test['ATA'] = pd.to_datetime(test['ATA'])\n",
    "\n",
    "# datetime을 여러 파생 변수로 변환\n",
    "for df in [train, test]:\n",
    "    df['year'] = df['ATA'].dt.year\n",
    "    df['month'] = df['ATA'].dt.month\n",
    "    df['day'] = df['ATA'].dt.day\n",
    "    df['hour'] = df['ATA'].dt.hour\n",
    "    df['minute'] = df['ATA'].dt.minute\n",
    "    df['weekday'] = df['ATA'].dt.weekday\n",
    "\n",
    "# datetime 컬럼 제거\n",
    "train.drop(columns='ATA', inplace=True)\n",
    "test.drop(columns='ATA', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "05466468-b155-4dcc-888f-7fb310b4b272",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Encoding features: 100%|██████████| 6/6 [00:12<00:00,  2.07s/it]\n"
     ]
    }
   ],
   "source": [
    "# Categorical 컬럼 인코딩\n",
    "categorical_features = ['ARI_CO', 'ARI_PO', 'SHIP_TYPE_CATEGORY', 'ID', 'SHIPMANAGER', 'FLAG']\n",
    "\n",
    "\n",
    "for feature in tqdm(categorical_features, desc=\"Encoding features\"):\n",
    "    encoder = LabelEncoder()\n",
    "    train[feature] = encoder.fit_transform(train[feature])\n",
    "    for label in np.unique(test[feature]):\n",
    "        if label not in encoder.classes_:\n",
    "            encoder.classes_ = np.append(encoder.classes_, label)\n",
    "    test[feature] = encoder.transform(test[feature])\n",
    "\n",
    "# 결측치 처리\n",
    "train.fillna(train.mean(), inplace=True)\n",
    "test.fillna(train.mean(), inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3b508c1d-e5a5-4f85-b403-28c5c6148511",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_importance_features = ['month', 'day', 'BDI_ADJ','year','CI_HOUR']\n",
    "test_importance_features = ['month', 'day', 'BDI_ADJ','year']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f711774b-4aea-45c2-a795-ff81cebaa86f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train[train_importance_features]\n",
    "test = test[test_importance_features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e13151de-2028-496b-b51b-586d0e4d4df2",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = TabularDataset(train)\n",
    "test_data = TabularDataset(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcf25893-feaa-4179-9c8e-20f7b2896c5f",
   "metadata": {},
   "source": [
    "# Autogluon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e3c18394-b6ba-457f-8ba5-1f16a5bf49db",
   "metadata": {},
   "outputs": [],
   "source": [
    "label = 'CI_HOUR'\n",
    "eval_metric = 'mean_absolute_error'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "6837370c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No path specified. Models will be saved in: \"AutogluonModels\\ag-20231017_073916\\\"\n",
      "Presets specified: ['best_quality']\n",
      "Stack configuration (auto_stack=True): num_stack_levels=1, num_bag_folds=8, num_bag_sets=1\n",
      "Warning: Training may take a very long time because `time_limit` was not specified and `train_data` is large (220055 samples, 6.16 MB).\n",
      "\tConsider setting `time_limit` to ensure training finishes within an expected duration or experiment with a small portion of `train_data` to identify an ideal `presets` and `hyperparameters` configuration.\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to \"AutogluonModels\\ag-20231017_073916\\\"\n",
      "AutoGluon Version:  0.8.2\n",
      "Python Version:     3.8.16\n",
      "Operating System:   Windows\n",
      "Platform Machine:   AMD64\n",
      "Platform Version:   10.0.22621\n",
      "Disk Space Avail:   159.40 GB / 511.09 GB (31.2%)\n",
      "Train Data Rows:    220055\n",
      "Train Data Columns: 4\n",
      "Label Column: CI_HOUR\n",
      "Preprocessing data ...\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    18316.77 MB\n",
      "\tTrain Data (Original)  Memory Usage: 4.4 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 1 | ['BDI_ADJ']\n",
      "\t\t('int', [])   : 3 | ['month', 'day', 'year']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 1 | ['BDI_ADJ']\n",
      "\t\t('int', [])   : 3 | ['month', 'day', 'year']\n",
      "\t0.2s = Fit runtime\n",
      "\t4 features in original data used to generate 4 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 4.4 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.19s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'mean_absolute_error'\n",
      "\tThis metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'NN_TORCH': {},\n",
      "\t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, 'GBMLarge'],\n",
      "\t'CAT': {},\n",
      "\t'XGB': {},\n",
      "\t'FASTAI': {},\n",
      "\t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'KNN': [{'weights': 'uniform', 'ag_args': {'name_suffix': 'Unif'}}, {'weights': 'distance', 'ag_args': {'name_suffix': 'Dist'}}],\n",
      "}\n",
      "AutoGluon will fit 2 stack levels (L1 to L2) ...\n",
      "Fitting 11 L1 models ...\n",
      "Fitting model: KNeighborsUnif_BAG_L1 ...\n",
      "\t-41.3952\t = Validation score   (-mean_absolute_error)\n",
      "\t0.19s\t = Training   runtime\n",
      "\t0.64s\t = Validation runtime\n",
      "Fitting model: KNeighborsDist_BAG_L1 ...\n",
      "\t-35.5951\t = Validation score   (-mean_absolute_error)\n",
      "\t0.22s\t = Training   runtime\n",
      "\t0.47s\t = Validation runtime\n",
      "Fitting model: LightGBMXT_BAG_L1 ...\n",
      "\tWarning: Exception caused LightGBMXT_BAG_L1 to fail during training... Skipping this model.\n",
      "\t\tThe model requires minimum cpu 1, but you only specified 0\n",
      "Detailed Traceback:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\ineeji\\anaconda3\\envs\\v1\\lib\\site-packages\\autogluon\\core\\trainer\\abstract_trainer.py\", line 1733, in _train_and_save\n",
      "    model = self._train_single(X, y, model, X_val, y_val, total_resources=total_resources, **model_fit_kwargs)\n",
      "  File \"c:\\Users\\ineeji\\anaconda3\\envs\\v1\\lib\\site-packages\\autogluon\\core\\trainer\\abstract_trainer.py\", line 1684, in _train_single\n",
      "    model = model.fit(X=X, y=y, X_val=X_val, y_val=y_val, total_resources=total_resources, **model_fit_kwargs)\n",
      "  File \"c:\\Users\\ineeji\\anaconda3\\envs\\v1\\lib\\site-packages\\autogluon\\core\\models\\abstract\\abstract_model.py\", line 829, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "  File \"c:\\Users\\ineeji\\anaconda3\\envs\\v1\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\stacker_ensemble_model.py\", line 169, in _fit\n",
      "    return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
      "  File \"c:\\Users\\ineeji\\anaconda3\\envs\\v1\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\bagged_ensemble_model.py\", line 266, in _fit\n",
      "    self._fit_folds(\n",
      "  File \"c:\\Users\\ineeji\\anaconda3\\envs\\v1\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\bagged_ensemble_model.py\", line 571, in _fit_folds\n",
      "    fold_fitting_strategy: FoldFittingStrategy = fold_fitting_strategy_cls(**fold_fitting_strategy_args)\n",
      "  File \"c:\\Users\\ineeji\\anaconda3\\envs\\v1\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 476, in __init__\n",
      "    self.resources, self.batches, self.num_parallel_jobs = self._get_resource_suggestions(\n",
      "  File \"c:\\Users\\ineeji\\anaconda3\\envs\\v1\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 684, in _get_resource_suggestions\n",
      "    resources_info = resources_calculator.get_resources_per_job(**get_resources_per_job_args)\n",
      "  File \"c:\\Users\\ineeji\\anaconda3\\envs\\v1\\lib\\site-packages\\autogluon\\core\\ray\\resources_calculator.py\", line 56, in get_resources_per_job\n",
      "    assert cpu_per_job >= minimum_cpu_per_job, f\"The model requires minimum cpu {minimum_cpu_per_job}, but you only specified {cpu_per_job}\"\n",
      "AssertionError: The model requires minimum cpu 1, but you only specified 0\n",
      "Fitting model: LightGBM_BAG_L1 ...\n",
      "\tWarning: Exception caused LightGBM_BAG_L1 to fail during training... Skipping this model.\n",
      "\t\tThe model requires minimum cpu 1, but you only specified 0\n",
      "Detailed Traceback:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\ineeji\\anaconda3\\envs\\v1\\lib\\site-packages\\autogluon\\core\\trainer\\abstract_trainer.py\", line 1733, in _train_and_save\n",
      "    model = self._train_single(X, y, model, X_val, y_val, total_resources=total_resources, **model_fit_kwargs)\n",
      "  File \"c:\\Users\\ineeji\\anaconda3\\envs\\v1\\lib\\site-packages\\autogluon\\core\\trainer\\abstract_trainer.py\", line 1684, in _train_single\n",
      "    model = model.fit(X=X, y=y, X_val=X_val, y_val=y_val, total_resources=total_resources, **model_fit_kwargs)\n",
      "  File \"c:\\Users\\ineeji\\anaconda3\\envs\\v1\\lib\\site-packages\\autogluon\\core\\models\\abstract\\abstract_model.py\", line 829, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "  File \"c:\\Users\\ineeji\\anaconda3\\envs\\v1\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\stacker_ensemble_model.py\", line 169, in _fit\n",
      "    return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
      "  File \"c:\\Users\\ineeji\\anaconda3\\envs\\v1\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\bagged_ensemble_model.py\", line 266, in _fit\n",
      "    self._fit_folds(\n",
      "  File \"c:\\Users\\ineeji\\anaconda3\\envs\\v1\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\bagged_ensemble_model.py\", line 571, in _fit_folds\n",
      "    fold_fitting_strategy: FoldFittingStrategy = fold_fitting_strategy_cls(**fold_fitting_strategy_args)\n",
      "  File \"c:\\Users\\ineeji\\anaconda3\\envs\\v1\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 476, in __init__\n",
      "    self.resources, self.batches, self.num_parallel_jobs = self._get_resource_suggestions(\n",
      "  File \"c:\\Users\\ineeji\\anaconda3\\envs\\v1\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 684, in _get_resource_suggestions\n",
      "    resources_info = resources_calculator.get_resources_per_job(**get_resources_per_job_args)\n",
      "  File \"c:\\Users\\ineeji\\anaconda3\\envs\\v1\\lib\\site-packages\\autogluon\\core\\ray\\resources_calculator.py\", line 56, in get_resources_per_job\n",
      "    assert cpu_per_job >= minimum_cpu_per_job, f\"The model requires minimum cpu {minimum_cpu_per_job}, but you only specified {cpu_per_job}\"\n",
      "AssertionError: The model requires minimum cpu 1, but you only specified 0\n",
      "Fitting model: RandomForestMSE_BAG_L1 ...\n",
      "\t-21.0755\t = Validation score   (-mean_absolute_error)\n",
      "\t16.24s\t = Training   runtime\n",
      "\t6.12s\t = Validation runtime\n",
      "Fitting model: CatBoost_BAG_L1 ...\n",
      "\tWarning: Exception caused CatBoost_BAG_L1 to fail during training... Skipping this model.\n",
      "\t\tThe model requires minimum cpu 1, but you only specified 0\n",
      "Detailed Traceback:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\ineeji\\anaconda3\\envs\\v1\\lib\\site-packages\\autogluon\\core\\trainer\\abstract_trainer.py\", line 1733, in _train_and_save\n",
      "    model = self._train_single(X, y, model, X_val, y_val, total_resources=total_resources, **model_fit_kwargs)\n",
      "  File \"c:\\Users\\ineeji\\anaconda3\\envs\\v1\\lib\\site-packages\\autogluon\\core\\trainer\\abstract_trainer.py\", line 1684, in _train_single\n",
      "    model = model.fit(X=X, y=y, X_val=X_val, y_val=y_val, total_resources=total_resources, **model_fit_kwargs)\n",
      "  File \"c:\\Users\\ineeji\\anaconda3\\envs\\v1\\lib\\site-packages\\autogluon\\core\\models\\abstract\\abstract_model.py\", line 829, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "  File \"c:\\Users\\ineeji\\anaconda3\\envs\\v1\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\stacker_ensemble_model.py\", line 169, in _fit\n",
      "    return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
      "  File \"c:\\Users\\ineeji\\anaconda3\\envs\\v1\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\bagged_ensemble_model.py\", line 266, in _fit\n",
      "    self._fit_folds(\n",
      "  File \"c:\\Users\\ineeji\\anaconda3\\envs\\v1\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\bagged_ensemble_model.py\", line 571, in _fit_folds\n",
      "    fold_fitting_strategy: FoldFittingStrategy = fold_fitting_strategy_cls(**fold_fitting_strategy_args)\n",
      "  File \"c:\\Users\\ineeji\\anaconda3\\envs\\v1\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 476, in __init__\n",
      "    self.resources, self.batches, self.num_parallel_jobs = self._get_resource_suggestions(\n",
      "  File \"c:\\Users\\ineeji\\anaconda3\\envs\\v1\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 684, in _get_resource_suggestions\n",
      "    resources_info = resources_calculator.get_resources_per_job(**get_resources_per_job_args)\n",
      "  File \"c:\\Users\\ineeji\\anaconda3\\envs\\v1\\lib\\site-packages\\autogluon\\core\\ray\\resources_calculator.py\", line 56, in get_resources_per_job\n",
      "    assert cpu_per_job >= minimum_cpu_per_job, f\"The model requires minimum cpu {minimum_cpu_per_job}, but you only specified {cpu_per_job}\"\n",
      "AssertionError: The model requires minimum cpu 1, but you only specified 0\n",
      "Fitting model: ExtraTreesMSE_BAG_L1 ...\n",
      "\t-23.8877\t = Validation score   (-mean_absolute_error)\n",
      "\t7.33s\t = Training   runtime\n",
      "\t5.89s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_BAG_L1 ...\n",
      "\tWarning: Exception caused NeuralNetFastAI_BAG_L1 to fail during training... Skipping this model.\n",
      "\t\tThe model requires minimum cpu 1, but you only specified 0\n",
      "Detailed Traceback:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\ineeji\\anaconda3\\envs\\v1\\lib\\site-packages\\autogluon\\core\\trainer\\abstract_trainer.py\", line 1733, in _train_and_save\n",
      "    model = self._train_single(X, y, model, X_val, y_val, total_resources=total_resources, **model_fit_kwargs)\n",
      "  File \"c:\\Users\\ineeji\\anaconda3\\envs\\v1\\lib\\site-packages\\autogluon\\core\\trainer\\abstract_trainer.py\", line 1684, in _train_single\n",
      "    model = model.fit(X=X, y=y, X_val=X_val, y_val=y_val, total_resources=total_resources, **model_fit_kwargs)\n",
      "  File \"c:\\Users\\ineeji\\anaconda3\\envs\\v1\\lib\\site-packages\\autogluon\\core\\models\\abstract\\abstract_model.py\", line 829, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "  File \"c:\\Users\\ineeji\\anaconda3\\envs\\v1\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\stacker_ensemble_model.py\", line 169, in _fit\n",
      "    return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
      "  File \"c:\\Users\\ineeji\\anaconda3\\envs\\v1\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\bagged_ensemble_model.py\", line 266, in _fit\n",
      "    self._fit_folds(\n",
      "  File \"c:\\Users\\ineeji\\anaconda3\\envs\\v1\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\bagged_ensemble_model.py\", line 571, in _fit_folds\n",
      "    fold_fitting_strategy: FoldFittingStrategy = fold_fitting_strategy_cls(**fold_fitting_strategy_args)\n",
      "  File \"c:\\Users\\ineeji\\anaconda3\\envs\\v1\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 476, in __init__\n",
      "    self.resources, self.batches, self.num_parallel_jobs = self._get_resource_suggestions(\n",
      "  File \"c:\\Users\\ineeji\\anaconda3\\envs\\v1\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 684, in _get_resource_suggestions\n",
      "    resources_info = resources_calculator.get_resources_per_job(**get_resources_per_job_args)\n",
      "  File \"c:\\Users\\ineeji\\anaconda3\\envs\\v1\\lib\\site-packages\\autogluon\\core\\ray\\resources_calculator.py\", line 56, in get_resources_per_job\n",
      "    assert cpu_per_job >= minimum_cpu_per_job, f\"The model requires minimum cpu {minimum_cpu_per_job}, but you only specified {cpu_per_job}\"\n",
      "AssertionError: The model requires minimum cpu 1, but you only specified 0\n",
      "Fitting model: XGBoost_BAG_L1 ...\n",
      "\tWarning: Exception caused XGBoost_BAG_L1 to fail during training... Skipping this model.\n",
      "\t\tThe model requires minimum cpu 1, but you only specified 0\n",
      "Detailed Traceback:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\ineeji\\anaconda3\\envs\\v1\\lib\\site-packages\\autogluon\\core\\trainer\\abstract_trainer.py\", line 1733, in _train_and_save\n",
      "    model = self._train_single(X, y, model, X_val, y_val, total_resources=total_resources, **model_fit_kwargs)\n",
      "  File \"c:\\Users\\ineeji\\anaconda3\\envs\\v1\\lib\\site-packages\\autogluon\\core\\trainer\\abstract_trainer.py\", line 1684, in _train_single\n",
      "    model = model.fit(X=X, y=y, X_val=X_val, y_val=y_val, total_resources=total_resources, **model_fit_kwargs)\n",
      "  File \"c:\\Users\\ineeji\\anaconda3\\envs\\v1\\lib\\site-packages\\autogluon\\core\\models\\abstract\\abstract_model.py\", line 829, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "  File \"c:\\Users\\ineeji\\anaconda3\\envs\\v1\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\stacker_ensemble_model.py\", line 169, in _fit\n",
      "    return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
      "  File \"c:\\Users\\ineeji\\anaconda3\\envs\\v1\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\bagged_ensemble_model.py\", line 266, in _fit\n",
      "    self._fit_folds(\n",
      "  File \"c:\\Users\\ineeji\\anaconda3\\envs\\v1\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\bagged_ensemble_model.py\", line 571, in _fit_folds\n",
      "    fold_fitting_strategy: FoldFittingStrategy = fold_fitting_strategy_cls(**fold_fitting_strategy_args)\n",
      "  File \"c:\\Users\\ineeji\\anaconda3\\envs\\v1\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 476, in __init__\n",
      "    self.resources, self.batches, self.num_parallel_jobs = self._get_resource_suggestions(\n",
      "  File \"c:\\Users\\ineeji\\anaconda3\\envs\\v1\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 684, in _get_resource_suggestions\n",
      "    resources_info = resources_calculator.get_resources_per_job(**get_resources_per_job_args)\n",
      "  File \"c:\\Users\\ineeji\\anaconda3\\envs\\v1\\lib\\site-packages\\autogluon\\core\\ray\\resources_calculator.py\", line 56, in get_resources_per_job\n",
      "    assert cpu_per_job >= minimum_cpu_per_job, f\"The model requires minimum cpu {minimum_cpu_per_job}, but you only specified {cpu_per_job}\"\n",
      "AssertionError: The model requires minimum cpu 1, but you only specified 0\n",
      "Fitting model: NeuralNetTorch_BAG_L1 ...\n",
      "\tWarning: Exception caused NeuralNetTorch_BAG_L1 to fail during training... Skipping this model.\n",
      "\t\tThe model requires minimum cpu 1, but you only specified 0\n",
      "Detailed Traceback:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\ineeji\\anaconda3\\envs\\v1\\lib\\site-packages\\autogluon\\core\\trainer\\abstract_trainer.py\", line 1733, in _train_and_save\n",
      "    model = self._train_single(X, y, model, X_val, y_val, total_resources=total_resources, **model_fit_kwargs)\n",
      "  File \"c:\\Users\\ineeji\\anaconda3\\envs\\v1\\lib\\site-packages\\autogluon\\core\\trainer\\abstract_trainer.py\", line 1684, in _train_single\n",
      "    model = model.fit(X=X, y=y, X_val=X_val, y_val=y_val, total_resources=total_resources, **model_fit_kwargs)\n",
      "  File \"c:\\Users\\ineeji\\anaconda3\\envs\\v1\\lib\\site-packages\\autogluon\\core\\models\\abstract\\abstract_model.py\", line 829, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "  File \"c:\\Users\\ineeji\\anaconda3\\envs\\v1\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\stacker_ensemble_model.py\", line 169, in _fit\n",
      "    return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
      "  File \"c:\\Users\\ineeji\\anaconda3\\envs\\v1\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\bagged_ensemble_model.py\", line 266, in _fit\n",
      "    self._fit_folds(\n",
      "  File \"c:\\Users\\ineeji\\anaconda3\\envs\\v1\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\bagged_ensemble_model.py\", line 571, in _fit_folds\n",
      "    fold_fitting_strategy: FoldFittingStrategy = fold_fitting_strategy_cls(**fold_fitting_strategy_args)\n",
      "  File \"c:\\Users\\ineeji\\anaconda3\\envs\\v1\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 476, in __init__\n",
      "    self.resources, self.batches, self.num_parallel_jobs = self._get_resource_suggestions(\n",
      "  File \"c:\\Users\\ineeji\\anaconda3\\envs\\v1\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 684, in _get_resource_suggestions\n",
      "    resources_info = resources_calculator.get_resources_per_job(**get_resources_per_job_args)\n",
      "  File \"c:\\Users\\ineeji\\anaconda3\\envs\\v1\\lib\\site-packages\\autogluon\\core\\ray\\resources_calculator.py\", line 56, in get_resources_per_job\n",
      "    assert cpu_per_job >= minimum_cpu_per_job, f\"The model requires minimum cpu {minimum_cpu_per_job}, but you only specified {cpu_per_job}\"\n",
      "AssertionError: The model requires minimum cpu 1, but you only specified 0\n",
      "Fitting model: LightGBMLarge_BAG_L1 ...\n",
      "\tWarning: Exception caused LightGBMLarge_BAG_L1 to fail during training... Skipping this model.\n",
      "\t\tThe model requires minimum cpu 1, but you only specified 0\n",
      "Detailed Traceback:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\ineeji\\anaconda3\\envs\\v1\\lib\\site-packages\\autogluon\\core\\trainer\\abstract_trainer.py\", line 1733, in _train_and_save\n",
      "    model = self._train_single(X, y, model, X_val, y_val, total_resources=total_resources, **model_fit_kwargs)\n",
      "  File \"c:\\Users\\ineeji\\anaconda3\\envs\\v1\\lib\\site-packages\\autogluon\\core\\trainer\\abstract_trainer.py\", line 1684, in _train_single\n",
      "    model = model.fit(X=X, y=y, X_val=X_val, y_val=y_val, total_resources=total_resources, **model_fit_kwargs)\n",
      "  File \"c:\\Users\\ineeji\\anaconda3\\envs\\v1\\lib\\site-packages\\autogluon\\core\\models\\abstract\\abstract_model.py\", line 829, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "  File \"c:\\Users\\ineeji\\anaconda3\\envs\\v1\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\stacker_ensemble_model.py\", line 169, in _fit\n",
      "    return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
      "  File \"c:\\Users\\ineeji\\anaconda3\\envs\\v1\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\bagged_ensemble_model.py\", line 266, in _fit\n",
      "    self._fit_folds(\n",
      "  File \"c:\\Users\\ineeji\\anaconda3\\envs\\v1\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\bagged_ensemble_model.py\", line 571, in _fit_folds\n",
      "    fold_fitting_strategy: FoldFittingStrategy = fold_fitting_strategy_cls(**fold_fitting_strategy_args)\n",
      "  File \"c:\\Users\\ineeji\\anaconda3\\envs\\v1\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 476, in __init__\n",
      "    self.resources, self.batches, self.num_parallel_jobs = self._get_resource_suggestions(\n",
      "  File \"c:\\Users\\ineeji\\anaconda3\\envs\\v1\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 684, in _get_resource_suggestions\n",
      "    resources_info = resources_calculator.get_resources_per_job(**get_resources_per_job_args)\n",
      "  File \"c:\\Users\\ineeji\\anaconda3\\envs\\v1\\lib\\site-packages\\autogluon\\core\\ray\\resources_calculator.py\", line 56, in get_resources_per_job\n",
      "    assert cpu_per_job >= minimum_cpu_per_job, f\"The model requires minimum cpu {minimum_cpu_per_job}, but you only specified {cpu_per_job}\"\n",
      "AssertionError: The model requires minimum cpu 1, but you only specified 0\n",
      "Fitting model: WeightedEnsemble_L2 ...\n",
      "\t-21.0707\t = Validation score   (-mean_absolute_error)\n",
      "\t1.84s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting 9 L2 models ...\n",
      "Fitting model: LightGBMXT_BAG_L2 ...\n",
      "\tWarning: Exception caused LightGBMXT_BAG_L2 to fail during training... Skipping this model.\n",
      "\t\tThe model requires minimum cpu 1, but you only specified 0\n",
      "Detailed Traceback:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\ineeji\\anaconda3\\envs\\v1\\lib\\site-packages\\autogluon\\core\\trainer\\abstract_trainer.py\", line 1733, in _train_and_save\n",
      "    model = self._train_single(X, y, model, X_val, y_val, total_resources=total_resources, **model_fit_kwargs)\n",
      "  File \"c:\\Users\\ineeji\\anaconda3\\envs\\v1\\lib\\site-packages\\autogluon\\core\\trainer\\abstract_trainer.py\", line 1684, in _train_single\n",
      "    model = model.fit(X=X, y=y, X_val=X_val, y_val=y_val, total_resources=total_resources, **model_fit_kwargs)\n",
      "  File \"c:\\Users\\ineeji\\anaconda3\\envs\\v1\\lib\\site-packages\\autogluon\\core\\models\\abstract\\abstract_model.py\", line 829, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "  File \"c:\\Users\\ineeji\\anaconda3\\envs\\v1\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\stacker_ensemble_model.py\", line 169, in _fit\n",
      "    return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
      "  File \"c:\\Users\\ineeji\\anaconda3\\envs\\v1\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\bagged_ensemble_model.py\", line 266, in _fit\n",
      "    self._fit_folds(\n",
      "  File \"c:\\Users\\ineeji\\anaconda3\\envs\\v1\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\bagged_ensemble_model.py\", line 571, in _fit_folds\n",
      "    fold_fitting_strategy: FoldFittingStrategy = fold_fitting_strategy_cls(**fold_fitting_strategy_args)\n",
      "  File \"c:\\Users\\ineeji\\anaconda3\\envs\\v1\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 476, in __init__\n",
      "    self.resources, self.batches, self.num_parallel_jobs = self._get_resource_suggestions(\n",
      "  File \"c:\\Users\\ineeji\\anaconda3\\envs\\v1\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 684, in _get_resource_suggestions\n",
      "    resources_info = resources_calculator.get_resources_per_job(**get_resources_per_job_args)\n",
      "  File \"c:\\Users\\ineeji\\anaconda3\\envs\\v1\\lib\\site-packages\\autogluon\\core\\ray\\resources_calculator.py\", line 56, in get_resources_per_job\n",
      "    assert cpu_per_job >= minimum_cpu_per_job, f\"The model requires minimum cpu {minimum_cpu_per_job}, but you only specified {cpu_per_job}\"\n",
      "AssertionError: The model requires minimum cpu 1, but you only specified 0\n",
      "Fitting model: LightGBM_BAG_L2 ...\n",
      "\tWarning: Exception caused LightGBM_BAG_L2 to fail during training... Skipping this model.\n",
      "\t\tThe model requires minimum cpu 1, but you only specified 0\n",
      "Detailed Traceback:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\ineeji\\anaconda3\\envs\\v1\\lib\\site-packages\\autogluon\\core\\trainer\\abstract_trainer.py\", line 1733, in _train_and_save\n",
      "    model = self._train_single(X, y, model, X_val, y_val, total_resources=total_resources, **model_fit_kwargs)\n",
      "  File \"c:\\Users\\ineeji\\anaconda3\\envs\\v1\\lib\\site-packages\\autogluon\\core\\trainer\\abstract_trainer.py\", line 1684, in _train_single\n",
      "    model = model.fit(X=X, y=y, X_val=X_val, y_val=y_val, total_resources=total_resources, **model_fit_kwargs)\n",
      "  File \"c:\\Users\\ineeji\\anaconda3\\envs\\v1\\lib\\site-packages\\autogluon\\core\\models\\abstract\\abstract_model.py\", line 829, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "  File \"c:\\Users\\ineeji\\anaconda3\\envs\\v1\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\stacker_ensemble_model.py\", line 169, in _fit\n",
      "    return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
      "  File \"c:\\Users\\ineeji\\anaconda3\\envs\\v1\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\bagged_ensemble_model.py\", line 266, in _fit\n",
      "    self._fit_folds(\n",
      "  File \"c:\\Users\\ineeji\\anaconda3\\envs\\v1\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\bagged_ensemble_model.py\", line 571, in _fit_folds\n",
      "    fold_fitting_strategy: FoldFittingStrategy = fold_fitting_strategy_cls(**fold_fitting_strategy_args)\n",
      "  File \"c:\\Users\\ineeji\\anaconda3\\envs\\v1\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 476, in __init__\n",
      "    self.resources, self.batches, self.num_parallel_jobs = self._get_resource_suggestions(\n",
      "  File \"c:\\Users\\ineeji\\anaconda3\\envs\\v1\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 684, in _get_resource_suggestions\n",
      "    resources_info = resources_calculator.get_resources_per_job(**get_resources_per_job_args)\n",
      "  File \"c:\\Users\\ineeji\\anaconda3\\envs\\v1\\lib\\site-packages\\autogluon\\core\\ray\\resources_calculator.py\", line 56, in get_resources_per_job\n",
      "    assert cpu_per_job >= minimum_cpu_per_job, f\"The model requires minimum cpu {minimum_cpu_per_job}, but you only specified {cpu_per_job}\"\n",
      "AssertionError: The model requires minimum cpu 1, but you only specified 0\n",
      "Fitting model: RandomForestMSE_BAG_L2 ...\n",
      "\t-18.1126\t = Validation score   (-mean_absolute_error)\n",
      "\t105.82s\t = Training   runtime\n",
      "\t6.0s\t = Validation runtime\n",
      "Fitting model: CatBoost_BAG_L2 ...\n",
      "\tWarning: Exception caused CatBoost_BAG_L2 to fail during training... Skipping this model.\n",
      "\t\tThe model requires minimum cpu 1, but you only specified 0\n",
      "Detailed Traceback:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\ineeji\\anaconda3\\envs\\v1\\lib\\site-packages\\autogluon\\core\\trainer\\abstract_trainer.py\", line 1733, in _train_and_save\n",
      "    model = self._train_single(X, y, model, X_val, y_val, total_resources=total_resources, **model_fit_kwargs)\n",
      "  File \"c:\\Users\\ineeji\\anaconda3\\envs\\v1\\lib\\site-packages\\autogluon\\core\\trainer\\abstract_trainer.py\", line 1684, in _train_single\n",
      "    model = model.fit(X=X, y=y, X_val=X_val, y_val=y_val, total_resources=total_resources, **model_fit_kwargs)\n",
      "  File \"c:\\Users\\ineeji\\anaconda3\\envs\\v1\\lib\\site-packages\\autogluon\\core\\models\\abstract\\abstract_model.py\", line 829, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "  File \"c:\\Users\\ineeji\\anaconda3\\envs\\v1\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\stacker_ensemble_model.py\", line 169, in _fit\n",
      "    return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
      "  File \"c:\\Users\\ineeji\\anaconda3\\envs\\v1\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\bagged_ensemble_model.py\", line 266, in _fit\n",
      "    self._fit_folds(\n",
      "  File \"c:\\Users\\ineeji\\anaconda3\\envs\\v1\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\bagged_ensemble_model.py\", line 571, in _fit_folds\n",
      "    fold_fitting_strategy: FoldFittingStrategy = fold_fitting_strategy_cls(**fold_fitting_strategy_args)\n",
      "  File \"c:\\Users\\ineeji\\anaconda3\\envs\\v1\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 476, in __init__\n",
      "    self.resources, self.batches, self.num_parallel_jobs = self._get_resource_suggestions(\n",
      "  File \"c:\\Users\\ineeji\\anaconda3\\envs\\v1\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 684, in _get_resource_suggestions\n",
      "    resources_info = resources_calculator.get_resources_per_job(**get_resources_per_job_args)\n",
      "  File \"c:\\Users\\ineeji\\anaconda3\\envs\\v1\\lib\\site-packages\\autogluon\\core\\ray\\resources_calculator.py\", line 56, in get_resources_per_job\n",
      "    assert cpu_per_job >= minimum_cpu_per_job, f\"The model requires minimum cpu {minimum_cpu_per_job}, but you only specified {cpu_per_job}\"\n",
      "AssertionError: The model requires minimum cpu 1, but you only specified 0\n",
      "Fitting model: ExtraTreesMSE_BAG_L2 ...\n",
      "\t-18.526\t = Validation score   (-mean_absolute_error)\n",
      "\t14.84s\t = Training   runtime\n",
      "\t4.81s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_BAG_L2 ...\n",
      "\tWarning: Exception caused NeuralNetFastAI_BAG_L2 to fail during training... Skipping this model.\n",
      "\t\tThe model requires minimum cpu 1, but you only specified 0\n",
      "Detailed Traceback:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\ineeji\\anaconda3\\envs\\v1\\lib\\site-packages\\autogluon\\core\\trainer\\abstract_trainer.py\", line 1733, in _train_and_save\n",
      "    model = self._train_single(X, y, model, X_val, y_val, total_resources=total_resources, **model_fit_kwargs)\n",
      "  File \"c:\\Users\\ineeji\\anaconda3\\envs\\v1\\lib\\site-packages\\autogluon\\core\\trainer\\abstract_trainer.py\", line 1684, in _train_single\n",
      "    model = model.fit(X=X, y=y, X_val=X_val, y_val=y_val, total_resources=total_resources, **model_fit_kwargs)\n",
      "  File \"c:\\Users\\ineeji\\anaconda3\\envs\\v1\\lib\\site-packages\\autogluon\\core\\models\\abstract\\abstract_model.py\", line 829, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "  File \"c:\\Users\\ineeji\\anaconda3\\envs\\v1\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\stacker_ensemble_model.py\", line 169, in _fit\n",
      "    return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
      "  File \"c:\\Users\\ineeji\\anaconda3\\envs\\v1\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\bagged_ensemble_model.py\", line 266, in _fit\n",
      "    self._fit_folds(\n",
      "  File \"c:\\Users\\ineeji\\anaconda3\\envs\\v1\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\bagged_ensemble_model.py\", line 571, in _fit_folds\n",
      "    fold_fitting_strategy: FoldFittingStrategy = fold_fitting_strategy_cls(**fold_fitting_strategy_args)\n",
      "  File \"c:\\Users\\ineeji\\anaconda3\\envs\\v1\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 476, in __init__\n",
      "    self.resources, self.batches, self.num_parallel_jobs = self._get_resource_suggestions(\n",
      "  File \"c:\\Users\\ineeji\\anaconda3\\envs\\v1\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 684, in _get_resource_suggestions\n",
      "    resources_info = resources_calculator.get_resources_per_job(**get_resources_per_job_args)\n",
      "  File \"c:\\Users\\ineeji\\anaconda3\\envs\\v1\\lib\\site-packages\\autogluon\\core\\ray\\resources_calculator.py\", line 56, in get_resources_per_job\n",
      "    assert cpu_per_job >= minimum_cpu_per_job, f\"The model requires minimum cpu {minimum_cpu_per_job}, but you only specified {cpu_per_job}\"\n",
      "AssertionError: The model requires minimum cpu 1, but you only specified 0\n",
      "Fitting model: XGBoost_BAG_L2 ...\n",
      "\tWarning: Exception caused XGBoost_BAG_L2 to fail during training... Skipping this model.\n",
      "\t\tThe model requires minimum cpu 1, but you only specified 0\n",
      "Detailed Traceback:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\ineeji\\anaconda3\\envs\\v1\\lib\\site-packages\\autogluon\\core\\trainer\\abstract_trainer.py\", line 1733, in _train_and_save\n",
      "    model = self._train_single(X, y, model, X_val, y_val, total_resources=total_resources, **model_fit_kwargs)\n",
      "  File \"c:\\Users\\ineeji\\anaconda3\\envs\\v1\\lib\\site-packages\\autogluon\\core\\trainer\\abstract_trainer.py\", line 1684, in _train_single\n",
      "    model = model.fit(X=X, y=y, X_val=X_val, y_val=y_val, total_resources=total_resources, **model_fit_kwargs)\n",
      "  File \"c:\\Users\\ineeji\\anaconda3\\envs\\v1\\lib\\site-packages\\autogluon\\core\\models\\abstract\\abstract_model.py\", line 829, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "  File \"c:\\Users\\ineeji\\anaconda3\\envs\\v1\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\stacker_ensemble_model.py\", line 169, in _fit\n",
      "    return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
      "  File \"c:\\Users\\ineeji\\anaconda3\\envs\\v1\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\bagged_ensemble_model.py\", line 266, in _fit\n",
      "    self._fit_folds(\n",
      "  File \"c:\\Users\\ineeji\\anaconda3\\envs\\v1\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\bagged_ensemble_model.py\", line 571, in _fit_folds\n",
      "    fold_fitting_strategy: FoldFittingStrategy = fold_fitting_strategy_cls(**fold_fitting_strategy_args)\n",
      "  File \"c:\\Users\\ineeji\\anaconda3\\envs\\v1\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 476, in __init__\n",
      "    self.resources, self.batches, self.num_parallel_jobs = self._get_resource_suggestions(\n",
      "  File \"c:\\Users\\ineeji\\anaconda3\\envs\\v1\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 684, in _get_resource_suggestions\n",
      "    resources_info = resources_calculator.get_resources_per_job(**get_resources_per_job_args)\n",
      "  File \"c:\\Users\\ineeji\\anaconda3\\envs\\v1\\lib\\site-packages\\autogluon\\core\\ray\\resources_calculator.py\", line 56, in get_resources_per_job\n",
      "    assert cpu_per_job >= minimum_cpu_per_job, f\"The model requires minimum cpu {minimum_cpu_per_job}, but you only specified {cpu_per_job}\"\n",
      "AssertionError: The model requires minimum cpu 1, but you only specified 0\n",
      "Fitting model: NeuralNetTorch_BAG_L2 ...\n",
      "\tWarning: Exception caused NeuralNetTorch_BAG_L2 to fail during training... Skipping this model.\n",
      "\t\tThe model requires minimum cpu 1, but you only specified 0\n",
      "Detailed Traceback:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\ineeji\\anaconda3\\envs\\v1\\lib\\site-packages\\autogluon\\core\\trainer\\abstract_trainer.py\", line 1733, in _train_and_save\n",
      "    model = self._train_single(X, y, model, X_val, y_val, total_resources=total_resources, **model_fit_kwargs)\n",
      "  File \"c:\\Users\\ineeji\\anaconda3\\envs\\v1\\lib\\site-packages\\autogluon\\core\\trainer\\abstract_trainer.py\", line 1684, in _train_single\n",
      "    model = model.fit(X=X, y=y, X_val=X_val, y_val=y_val, total_resources=total_resources, **model_fit_kwargs)\n",
      "  File \"c:\\Users\\ineeji\\anaconda3\\envs\\v1\\lib\\site-packages\\autogluon\\core\\models\\abstract\\abstract_model.py\", line 829, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "  File \"c:\\Users\\ineeji\\anaconda3\\envs\\v1\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\stacker_ensemble_model.py\", line 169, in _fit\n",
      "    return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
      "  File \"c:\\Users\\ineeji\\anaconda3\\envs\\v1\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\bagged_ensemble_model.py\", line 266, in _fit\n",
      "    self._fit_folds(\n",
      "  File \"c:\\Users\\ineeji\\anaconda3\\envs\\v1\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\bagged_ensemble_model.py\", line 571, in _fit_folds\n",
      "    fold_fitting_strategy: FoldFittingStrategy = fold_fitting_strategy_cls(**fold_fitting_strategy_args)\n",
      "  File \"c:\\Users\\ineeji\\anaconda3\\envs\\v1\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 476, in __init__\n",
      "    self.resources, self.batches, self.num_parallel_jobs = self._get_resource_suggestions(\n",
      "  File \"c:\\Users\\ineeji\\anaconda3\\envs\\v1\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 684, in _get_resource_suggestions\n",
      "    resources_info = resources_calculator.get_resources_per_job(**get_resources_per_job_args)\n",
      "  File \"c:\\Users\\ineeji\\anaconda3\\envs\\v1\\lib\\site-packages\\autogluon\\core\\ray\\resources_calculator.py\", line 56, in get_resources_per_job\n",
      "    assert cpu_per_job >= minimum_cpu_per_job, f\"The model requires minimum cpu {minimum_cpu_per_job}, but you only specified {cpu_per_job}\"\n",
      "AssertionError: The model requires minimum cpu 1, but you only specified 0\n",
      "Fitting model: LightGBMLarge_BAG_L2 ...\n",
      "\tWarning: Exception caused LightGBMLarge_BAG_L2 to fail during training... Skipping this model.\n",
      "\t\tThe model requires minimum cpu 1, but you only specified 0\n",
      "Detailed Traceback:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\ineeji\\anaconda3\\envs\\v1\\lib\\site-packages\\autogluon\\core\\trainer\\abstract_trainer.py\", line 1733, in _train_and_save\n",
      "    model = self._train_single(X, y, model, X_val, y_val, total_resources=total_resources, **model_fit_kwargs)\n",
      "  File \"c:\\Users\\ineeji\\anaconda3\\envs\\v1\\lib\\site-packages\\autogluon\\core\\trainer\\abstract_trainer.py\", line 1684, in _train_single\n",
      "    model = model.fit(X=X, y=y, X_val=X_val, y_val=y_val, total_resources=total_resources, **model_fit_kwargs)\n",
      "  File \"c:\\Users\\ineeji\\anaconda3\\envs\\v1\\lib\\site-packages\\autogluon\\core\\models\\abstract\\abstract_model.py\", line 829, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "  File \"c:\\Users\\ineeji\\anaconda3\\envs\\v1\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\stacker_ensemble_model.py\", line 169, in _fit\n",
      "    return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
      "  File \"c:\\Users\\ineeji\\anaconda3\\envs\\v1\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\bagged_ensemble_model.py\", line 266, in _fit\n",
      "    self._fit_folds(\n",
      "  File \"c:\\Users\\ineeji\\anaconda3\\envs\\v1\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\bagged_ensemble_model.py\", line 571, in _fit_folds\n",
      "    fold_fitting_strategy: FoldFittingStrategy = fold_fitting_strategy_cls(**fold_fitting_strategy_args)\n",
      "  File \"c:\\Users\\ineeji\\anaconda3\\envs\\v1\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 476, in __init__\n",
      "    self.resources, self.batches, self.num_parallel_jobs = self._get_resource_suggestions(\n",
      "  File \"c:\\Users\\ineeji\\anaconda3\\envs\\v1\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 684, in _get_resource_suggestions\n",
      "    resources_info = resources_calculator.get_resources_per_job(**get_resources_per_job_args)\n",
      "  File \"c:\\Users\\ineeji\\anaconda3\\envs\\v1\\lib\\site-packages\\autogluon\\core\\ray\\resources_calculator.py\", line 56, in get_resources_per_job\n",
      "    assert cpu_per_job >= minimum_cpu_per_job, f\"The model requires minimum cpu {minimum_cpu_per_job}, but you only specified {cpu_per_job}\"\n",
      "AssertionError: The model requires minimum cpu 1, but you only specified 0\n",
      "Fitting model: WeightedEnsemble_L3 ...\n",
      "\t-18.0822\t = Validation score   (-mean_absolute_error)\n",
      "\t1.31s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 174.44s ... Best model: \"WeightedEnsemble_L3\"\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels\\ag-20231017_073916\\\")\n"
     ]
    }
   ],
   "source": [
    "predictor2 = TabularPredictor(\n",
    "    label=label, problem_type='regression', eval_metric=eval_metric\n",
    ").fit(train_data, \n",
    "      presets='best_quality', \n",
    "      #num_stack_levels=3,\n",
    "      #excluded_model_types = excluded_model_types,\n",
    "      ag_args_fit={'num_gpus': 0}\n",
    "      #num_gpus=1\n",
    "      )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "17b82330",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>score_val</th>\n",
       "      <th>pred_time_val</th>\n",
       "      <th>fit_time</th>\n",
       "      <th>pred_time_val_marginal</th>\n",
       "      <th>fit_time_marginal</th>\n",
       "      <th>stack_level</th>\n",
       "      <th>can_infer</th>\n",
       "      <th>fit_order</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>WeightedEnsemble_L3</td>\n",
       "      <td>-18.082189</td>\n",
       "      <td>23.948082</td>\n",
       "      <td>145.954401</td>\n",
       "      <td>0.006502</td>\n",
       "      <td>1.310468</td>\n",
       "      <td>3</td>\n",
       "      <td>True</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>RandomForestMSE_BAG_L2</td>\n",
       "      <td>-18.112575</td>\n",
       "      <td>19.133026</td>\n",
       "      <td>129.804259</td>\n",
       "      <td>6.004931</td>\n",
       "      <td>105.820826</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ExtraTreesMSE_BAG_L2</td>\n",
       "      <td>-18.525953</td>\n",
       "      <td>17.936650</td>\n",
       "      <td>38.823107</td>\n",
       "      <td>4.808554</td>\n",
       "      <td>14.839675</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>WeightedEnsemble_L2</td>\n",
       "      <td>-21.070655</td>\n",
       "      <td>6.594833</td>\n",
       "      <td>18.301848</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.843698</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>RandomForestMSE_BAG_L1</td>\n",
       "      <td>-21.075547</td>\n",
       "      <td>6.120175</td>\n",
       "      <td>16.240772</td>\n",
       "      <td>6.120175</td>\n",
       "      <td>16.240772</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>ExtraTreesMSE_BAG_L1</td>\n",
       "      <td>-23.887711</td>\n",
       "      <td>5.891456</td>\n",
       "      <td>7.332445</td>\n",
       "      <td>5.891456</td>\n",
       "      <td>7.332445</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>KNeighborsDist_BAG_L1</td>\n",
       "      <td>-35.595110</td>\n",
       "      <td>0.474658</td>\n",
       "      <td>0.217378</td>\n",
       "      <td>0.474658</td>\n",
       "      <td>0.217378</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>KNeighborsUnif_BAG_L1</td>\n",
       "      <td>-41.395235</td>\n",
       "      <td>0.641806</td>\n",
       "      <td>0.192838</td>\n",
       "      <td>0.641806</td>\n",
       "      <td>0.192838</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    model  score_val  pred_time_val    fit_time  \\\n",
       "0     WeightedEnsemble_L3 -18.082189      23.948082  145.954401   \n",
       "1  RandomForestMSE_BAG_L2 -18.112575      19.133026  129.804259   \n",
       "2    ExtraTreesMSE_BAG_L2 -18.525953      17.936650   38.823107   \n",
       "3     WeightedEnsemble_L2 -21.070655       6.594833   18.301848   \n",
       "4  RandomForestMSE_BAG_L1 -21.075547       6.120175   16.240772   \n",
       "5    ExtraTreesMSE_BAG_L1 -23.887711       5.891456    7.332445   \n",
       "6   KNeighborsDist_BAG_L1 -35.595110       0.474658    0.217378   \n",
       "7   KNeighborsUnif_BAG_L1 -41.395235       0.641806    0.192838   \n",
       "\n",
       "   pred_time_val_marginal  fit_time_marginal  stack_level  can_infer  \\\n",
       "0                0.006502           1.310468            3       True   \n",
       "1                6.004931         105.820826            2       True   \n",
       "2                4.808554          14.839675            2       True   \n",
       "3                0.000000           1.843698            2       True   \n",
       "4                6.120175          16.240772            1       True   \n",
       "5                5.891456           7.332445            1       True   \n",
       "6                0.474658           0.217378            1       True   \n",
       "7                0.641806           0.192838            1       True   \n",
       "\n",
       "   fit_order  \n",
       "0          8  \n",
       "1          6  \n",
       "2          7  \n",
       "3          5  \n",
       "4          3  \n",
       "5          4  \n",
       "6          2  \n",
       "7          1  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictor2.leaderboard(silent = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3362c423-9a86-4a0e-90da-6e25387f2c04",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No path specified. Models will be saved in: \"AutogluonModels\\ag-20231016_051252\\\"\n",
      "Presets specified: ['best_quality']\n",
      "Stack configuration (auto_stack=True): num_stack_levels=1, num_bag_folds=8, num_bag_sets=1\n",
      "Warning: Training may take a very long time because `time_limit` was not specified and `train_data` is large (367441 samples, 22.05 MB).\n",
      "\tConsider setting `time_limit` to ensure training finishes within an expected duration or experiment with a small portion of `train_data` to identify an ideal `presets` and `hyperparameters` configuration.\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to \"AutogluonModels\\ag-20231016_051252\\\"\n",
      "AutoGluon Version:  0.8.2\n",
      "Python Version:     3.8.16\n",
      "Operating System:   Windows\n",
      "Platform Machine:   AMD64\n",
      "Platform Version:   10.0.22621\n",
      "Disk Space Avail:   18.98 GB / 511.09 GB (3.7%)\n",
      "Train Data Rows:    367441\n",
      "Train Data Columns: 8\n",
      "Label Column: CI_HOUR\n",
      "Preprocessing data ...\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    19373.79 MB\n",
      "\tTrain Data (Original)  Memory Usage: 19.11 MB (0.1% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 5 | ['WTI', 'DUBAI', 'BRENT', 'OIL', 'BDI_ADJ']\n",
      "\t\t('int', [])   : 3 | ['month', 'day', 'year']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 5 | ['WTI', 'DUBAI', 'BRENT', 'OIL', 'BDI_ADJ']\n",
      "\t\t('int', [])   : 3 | ['month', 'day', 'year']\n",
      "\t0.3s = Fit runtime\n",
      "\t8 features in original data used to generate 8 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 19.11 MB (0.1% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.4s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'mean_absolute_error'\n",
      "\tThis metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'NN_TORCH': {},\n",
      "\t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, 'GBMLarge'],\n",
      "\t'CAT': {},\n",
      "\t'XGB': {},\n",
      "\t'FASTAI': {},\n",
      "\t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'KNN': [{'weights': 'uniform', 'ag_args': {'name_suffix': 'Unif'}}, {'weights': 'distance', 'ag_args': {'name_suffix': 'Dist'}}],\n",
      "}\n",
      "AutoGluon will fit 2 stack levels (L1 to L2) ...\n",
      "Fitting 11 L1 models ...\n",
      "Fitting model: KNeighborsUnif_BAG_L1 ...\n",
      "Specified total num_gpus: 1, but only 0 are available. Will use 0 instead\n",
      "\t-23.5213\t = Validation score   (-mean_absolute_error)\n",
      "\t0.75s\t = Training   runtime\n",
      "\t1.33s\t = Validation runtime\n",
      "Fitting model: KNeighborsDist_BAG_L1 ...\n",
      "Specified total num_gpus: 1, but only 0 are available. Will use 0 instead\n",
      "\t-20.4797\t = Validation score   (-mean_absolute_error)\n",
      "\t0.77s\t = Training   runtime\n",
      "\t1.48s\t = Validation runtime\n",
      "Fitting model: LightGBMXT_BAG_L1 ...\n",
      "Specified total num_gpus: 1, but only 0 are available. Will use 0 instead\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t-31.3426\t = Validation score   (-mean_absolute_error)\n",
      "\t284.47s\t = Training   runtime\n",
      "\t1323.82s\t = Validation runtime\n",
      "Fitting model: LightGBM_BAG_L1 ...\n",
      "Specified total num_gpus: 1, but only 0 are available. Will use 0 instead\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t-12.1687\t = Validation score   (-mean_absolute_error)\n",
      "\t165.03s\t = Training   runtime\n",
      "\t909.4s\t = Validation runtime\n",
      "Fitting model: RandomForestMSE_BAG_L1 ...\n",
      "Specified total num_gpus: 1, but only 0 are available. Will use 0 instead\n",
      "\t-9.8355\t = Validation score   (-mean_absolute_error)\n",
      "\t64.37s\t = Training   runtime\n",
      "\t10.11s\t = Validation runtime\n",
      "Fitting model: CatBoost_BAG_L1 ...\n",
      "Specified total num_gpus: 1, but only 0 are available. Will use 0 instead\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t-22.0531\t = Validation score   (-mean_absolute_error)\n",
      "\t993.82s\t = Training   runtime\n",
      "\t0.81s\t = Validation runtime\n",
      "Fitting model: ExtraTreesMSE_BAG_L1 ...\n",
      "Specified total num_gpus: 1, but only 0 are available. Will use 0 instead\n",
      "\t-9.7798\t = Validation score   (-mean_absolute_error)\n",
      "\t28.32s\t = Training   runtime\n",
      "\t10.28s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_BAG_L1 ...\n",
      "Specified total num_gpus: 1, but only 0 are available. Will use 0 instead\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t-68.203\t = Validation score   (-mean_absolute_error)\n",
      "\t285.52s\t = Training   runtime\n",
      "\t2.91s\t = Validation runtime\n",
      "Fitting model: XGBoost_BAG_L1 ...\n",
      "Specified total num_gpus: 1, but only 0 are available. Will use 0 instead\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\tWarning: Exception caused XGBoost_BAG_L1 to fail during training... Skipping this model.\n",
      "\t\t\u001b[36mray::_ray_fit()\u001b[39m (pid=29716, ip=127.0.0.1)\n",
      "  File \"python\\ray\\_raylet.pyx\", line 857, in ray._raylet.execute_task\n",
      "  File \"python\\ray\\_raylet.pyx\", line 861, in ray._raylet.execute_task\n",
      "  File \"c:\\Users\\ineeji\\anaconda3\\envs\\v1\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 402, in _ray_fit\n",
      "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, **resources, **kwargs_fold)\n",
      "  File \"c:\\Users\\ineeji\\anaconda3\\envs\\v1\\lib\\site-packages\\autogluon\\core\\models\\abstract\\abstract_model.py\", line 829, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "  File \"c:\\Users\\ineeji\\anaconda3\\envs\\v1\\lib\\site-packages\\autogluon\\tabular\\models\\xgboost\\xgboost_model.py\", line 143, in _fit\n",
      "    self.params_trained[\"n_estimators\"] = bst.best_ntree_limit\n",
      "AttributeError: 'Booster' object has no attribute 'best_ntree_limit'\n",
      "Detailed Traceback:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\ineeji\\anaconda3\\envs\\v1\\lib\\site-packages\\autogluon\\core\\trainer\\abstract_trainer.py\", line 1733, in _train_and_save\n",
      "    model = self._train_single(X, y, model, X_val, y_val, total_resources=total_resources, **model_fit_kwargs)\n",
      "  File \"c:\\Users\\ineeji\\anaconda3\\envs\\v1\\lib\\site-packages\\autogluon\\core\\trainer\\abstract_trainer.py\", line 1684, in _train_single\n",
      "    model = model.fit(X=X, y=y, X_val=X_val, y_val=y_val, total_resources=total_resources, **model_fit_kwargs)\n",
      "  File \"c:\\Users\\ineeji\\anaconda3\\envs\\v1\\lib\\site-packages\\autogluon\\core\\models\\abstract\\abstract_model.py\", line 829, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "  File \"c:\\Users\\ineeji\\anaconda3\\envs\\v1\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\stacker_ensemble_model.py\", line 169, in _fit\n",
      "    return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
      "  File \"c:\\Users\\ineeji\\anaconda3\\envs\\v1\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\bagged_ensemble_model.py\", line 266, in _fit\n",
      "    self._fit_folds(\n",
      "  File \"c:\\Users\\ineeji\\anaconda3\\envs\\v1\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\bagged_ensemble_model.py\", line 592, in _fit_folds\n",
      "    fold_fitting_strategy.after_all_folds_scheduled()\n",
      "  File \"c:\\Users\\ineeji\\anaconda3\\envs\\v1\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 581, in after_all_folds_scheduled\n",
      "    raise processed_exception\n",
      "  File \"c:\\Users\\ineeji\\anaconda3\\envs\\v1\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 541, in after_all_folds_scheduled\n",
      "    fold_model, pred_proba, time_start_fit, time_end_fit, predict_time, predict_1_time = self.ray.get(finished)\n",
      "  File \"c:\\Users\\ineeji\\anaconda3\\envs\\v1\\lib\\site-packages\\ray\\_private\\client_mode_hook.py\", line 105, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"c:\\Users\\ineeji\\anaconda3\\envs\\v1\\lib\\site-packages\\ray\\_private\\worker.py\", line 2380, in get\n",
      "    raise value.as_instanceof_cause()\n",
      "ray.exceptions.RayTaskError(AttributeError): \u001b[36mray::_ray_fit()\u001b[39m (pid=29716, ip=127.0.0.1)\n",
      "  File \"python\\ray\\_raylet.pyx\", line 857, in ray._raylet.execute_task\n",
      "  File \"python\\ray\\_raylet.pyx\", line 861, in ray._raylet.execute_task\n",
      "  File \"c:\\Users\\ineeji\\anaconda3\\envs\\v1\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 402, in _ray_fit\n",
      "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, **resources, **kwargs_fold)\n",
      "  File \"c:\\Users\\ineeji\\anaconda3\\envs\\v1\\lib\\site-packages\\autogluon\\core\\models\\abstract\\abstract_model.py\", line 829, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "  File \"c:\\Users\\ineeji\\anaconda3\\envs\\v1\\lib\\site-packages\\autogluon\\tabular\\models\\xgboost\\xgboost_model.py\", line 143, in _fit\n",
      "    self.params_trained[\"n_estimators\"] = bst.best_ntree_limit\n",
      "AttributeError: 'Booster' object has no attribute 'best_ntree_limit'\n",
      "Fitting model: NeuralNetTorch_BAG_L1 ...\n",
      "Specified total num_gpus: 1, but only 0 are available. Will use 0 instead\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "2023-10-16 14:54:50,505\tERROR worker.py:399 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2023-10-16 14:54:50,508\tERROR worker.py:399 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2023-10-16 14:54:50,512\tERROR worker.py:399 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2023-10-16 14:54:50,513\tERROR worker.py:399 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2023-10-16 14:54:50,513\tERROR worker.py:399 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2023-10-16 14:54:50,521\tERROR worker.py:399 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2023-10-16 14:54:50,527\tERROR worker.py:399 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "\t-32.4729\t = Validation score   (-mean_absolute_error)\n",
      "\t2562.81s\t = Training   runtime\n",
      "\t1.0s\t = Validation runtime\n",
      "Fitting model: LightGBMLarge_BAG_L1 ...\n",
      "Specified total num_gpus: 1, but only 0 are available. Will use 0 instead\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t-9.1545\t = Validation score   (-mean_absolute_error)\n",
      "\t221.33s\t = Training   runtime\n",
      "\t1369.86s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ...\n",
      "\t-8.9227\t = Validation score   (-mean_absolute_error)\n",
      "\t5.3s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting 9 L2 models ...\n",
      "Fitting model: LightGBMXT_BAG_L2 ...\n",
      "Specified total num_gpus: 1, but only 0 are available. Will use 0 instead\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t-8.7403\t = Validation score   (-mean_absolute_error)\n",
      "\t261.83s\t = Training   runtime\n",
      "\t775.46s\t = Validation runtime\n",
      "Fitting model: LightGBM_BAG_L2 ...\n",
      "Specified total num_gpus: 1, but only 0 are available. Will use 0 instead\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t-7.7231\t = Validation score   (-mean_absolute_error)\n",
      "\t125.46s\t = Training   runtime\n",
      "\t95.54s\t = Validation runtime\n",
      "Fitting model: RandomForestMSE_BAG_L2 ...\n",
      "Specified total num_gpus: 1, but only 0 are available. Will use 0 instead\n",
      "\t-6.9051\t = Validation score   (-mean_absolute_error)\n",
      "\t334.85s\t = Training   runtime\n",
      "\t8.91s\t = Validation runtime\n",
      "Fitting model: CatBoost_BAG_L2 ...\n",
      "Specified total num_gpus: 1, but only 0 are available. Will use 0 instead\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t-7.5966\t = Validation score   (-mean_absolute_error)\n",
      "\t1159.83s\t = Training   runtime\n",
      "\t0.99s\t = Validation runtime\n",
      "Fitting model: ExtraTreesMSE_BAG_L2 ...\n",
      "Specified total num_gpus: 1, but only 0 are available. Will use 0 instead\n",
      "\t-7.0521\t = Validation score   (-mean_absolute_error)\n",
      "\t51.31s\t = Training   runtime\n",
      "\t8.11s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_BAG_L2 ...\n",
      "Specified total num_gpus: 1, but only 0 are available. Will use 0 instead\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t-8.6221\t = Validation score   (-mean_absolute_error)\n",
      "\t279.4s\t = Training   runtime\n",
      "\t3.02s\t = Validation runtime\n",
      "Fitting model: XGBoost_BAG_L2 ...\n",
      "Specified total num_gpus: 1, but only 0 are available. Will use 0 instead\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\tWarning: Exception caused XGBoost_BAG_L2 to fail during training... Skipping this model.\n",
      "\t\t\u001b[36mray::_ray_fit()\u001b[39m (pid=31136, ip=127.0.0.1)\n",
      "  File \"python\\ray\\_raylet.pyx\", line 857, in ray._raylet.execute_task\n",
      "  File \"python\\ray\\_raylet.pyx\", line 861, in ray._raylet.execute_task\n",
      "  File \"c:\\Users\\ineeji\\anaconda3\\envs\\v1\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 402, in _ray_fit\n",
      "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, **resources, **kwargs_fold)\n",
      "  File \"c:\\Users\\ineeji\\anaconda3\\envs\\v1\\lib\\site-packages\\autogluon\\core\\models\\abstract\\abstract_model.py\", line 829, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "  File \"c:\\Users\\ineeji\\anaconda3\\envs\\v1\\lib\\site-packages\\autogluon\\tabular\\models\\xgboost\\xgboost_model.py\", line 143, in _fit\n",
      "    self.params_trained[\"n_estimators\"] = bst.best_ntree_limit\n",
      "AttributeError: 'Booster' object has no attribute 'best_ntree_limit'\n",
      "Detailed Traceback:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\ineeji\\anaconda3\\envs\\v1\\lib\\site-packages\\autogluon\\core\\trainer\\abstract_trainer.py\", line 1733, in _train_and_save\n",
      "    model = self._train_single(X, y, model, X_val, y_val, total_resources=total_resources, **model_fit_kwargs)\n",
      "  File \"c:\\Users\\ineeji\\anaconda3\\envs\\v1\\lib\\site-packages\\autogluon\\core\\trainer\\abstract_trainer.py\", line 1684, in _train_single\n",
      "    model = model.fit(X=X, y=y, X_val=X_val, y_val=y_val, total_resources=total_resources, **model_fit_kwargs)\n",
      "  File \"c:\\Users\\ineeji\\anaconda3\\envs\\v1\\lib\\site-packages\\autogluon\\core\\models\\abstract\\abstract_model.py\", line 829, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "  File \"c:\\Users\\ineeji\\anaconda3\\envs\\v1\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\stacker_ensemble_model.py\", line 169, in _fit\n",
      "    return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
      "  File \"c:\\Users\\ineeji\\anaconda3\\envs\\v1\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\bagged_ensemble_model.py\", line 266, in _fit\n",
      "    self._fit_folds(\n",
      "  File \"c:\\Users\\ineeji\\anaconda3\\envs\\v1\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\bagged_ensemble_model.py\", line 592, in _fit_folds\n",
      "    fold_fitting_strategy.after_all_folds_scheduled()\n",
      "  File \"c:\\Users\\ineeji\\anaconda3\\envs\\v1\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 581, in after_all_folds_scheduled\n",
      "    raise processed_exception\n",
      "  File \"c:\\Users\\ineeji\\anaconda3\\envs\\v1\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 541, in after_all_folds_scheduled\n",
      "    fold_model, pred_proba, time_start_fit, time_end_fit, predict_time, predict_1_time = self.ray.get(finished)\n",
      "  File \"c:\\Users\\ineeji\\anaconda3\\envs\\v1\\lib\\site-packages\\ray\\_private\\client_mode_hook.py\", line 105, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"c:\\Users\\ineeji\\anaconda3\\envs\\v1\\lib\\site-packages\\ray\\_private\\worker.py\", line 2380, in get\n",
      "    raise value.as_instanceof_cause()\n",
      "ray.exceptions.RayTaskError(AttributeError): \u001b[36mray::_ray_fit()\u001b[39m (pid=31136, ip=127.0.0.1)\n",
      "  File \"python\\ray\\_raylet.pyx\", line 857, in ray._raylet.execute_task\n",
      "  File \"python\\ray\\_raylet.pyx\", line 861, in ray._raylet.execute_task\n",
      "  File \"c:\\Users\\ineeji\\anaconda3\\envs\\v1\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 402, in _ray_fit\n",
      "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, **resources, **kwargs_fold)\n",
      "  File \"c:\\Users\\ineeji\\anaconda3\\envs\\v1\\lib\\site-packages\\autogluon\\core\\models\\abstract\\abstract_model.py\", line 829, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "  File \"c:\\Users\\ineeji\\anaconda3\\envs\\v1\\lib\\site-packages\\autogluon\\tabular\\models\\xgboost\\xgboost_model.py\", line 143, in _fit\n",
      "    self.params_trained[\"n_estimators\"] = bst.best_ntree_limit\n",
      "AttributeError: 'Booster' object has no attribute 'best_ntree_limit'\n",
      "Fitting model: NeuralNetTorch_BAG_L2 ...\n",
      "Specified total num_gpus: 1, but only 0 are available. Will use 0 instead\n",
      "2023-10-16 16:24:02,791\tERROR worker.py:399 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2023-10-16 16:24:02,793\tERROR worker.py:399 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2023-10-16 16:24:02,796\tERROR worker.py:399 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2023-10-16 16:24:02,799\tERROR worker.py:399 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2023-10-16 16:24:02,801\tERROR worker.py:399 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2023-10-16 16:24:02,803\tERROR worker.py:399 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2023-10-16 16:24:02,806\tERROR worker.py:399 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t-8.1726\t = Validation score   (-mean_absolute_error)\n",
      "\t478.9s\t = Training   runtime\n",
      "\t1.72s\t = Validation runtime\n",
      "Fitting model: LightGBMLarge_BAG_L2 ...\n",
      "Specified total num_gpus: 1, but only 0 are available. Will use 0 instead\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t-7.245\t = Validation score   (-mean_absolute_error)\n",
      "\t265.35s\t = Training   runtime\n",
      "\t1033.99s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L3 ...\n",
      "\t-6.8124\t = Validation score   (-mean_absolute_error)\n",
      "\t4.46s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 8763.3s ... Best model: \"WeightedEnsemble_L3\"\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels\\ag-20231016_051252\\\")\n"
     ]
    }
   ],
   "source": [
    "predictor = TabularPredictor(\n",
    "    label=label, problem_type='regression', eval_metric=eval_metric\n",
    ").fit(train_data, \n",
    "      presets='best_quality', \n",
    "      #num_stack_levels=3,\n",
    "      #excluded_model_types = excluded_model_types,\n",
    "      num_gpus=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8fb35093-78cd-498a-ba39-05c7f092c27a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>score_val</th>\n",
       "      <th>pred_time_val</th>\n",
       "      <th>fit_time</th>\n",
       "      <th>pred_time_val_marginal</th>\n",
       "      <th>fit_time_marginal</th>\n",
       "      <th>stack_level</th>\n",
       "      <th>can_infer</th>\n",
       "      <th>fit_order</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>WeightedEnsemble_L3</td>\n",
       "      <td>-6.812446</td>\n",
       "      <td>4675.638708</td>\n",
       "      <td>5690.760465</td>\n",
       "      <td>0.004978</td>\n",
       "      <td>4.462162</td>\n",
       "      <td>3</td>\n",
       "      <td>True</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>RandomForestMSE_BAG_L2</td>\n",
       "      <td>-6.905120</td>\n",
       "      <td>3639.920054</td>\n",
       "      <td>4942.047835</td>\n",
       "      <td>8.908978</td>\n",
       "      <td>334.851027</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ExtraTreesMSE_BAG_L2</td>\n",
       "      <td>-7.052058</td>\n",
       "      <td>3639.118638</td>\n",
       "      <td>4658.510261</td>\n",
       "      <td>8.107562</td>\n",
       "      <td>51.313452</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>LightGBMLarge_BAG_L2</td>\n",
       "      <td>-7.244969</td>\n",
       "      <td>4665.000014</td>\n",
       "      <td>4872.546138</td>\n",
       "      <td>1033.988938</td>\n",
       "      <td>265.349329</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CatBoost_BAG_L2</td>\n",
       "      <td>-7.596639</td>\n",
       "      <td>3631.997084</td>\n",
       "      <td>5767.023896</td>\n",
       "      <td>0.986009</td>\n",
       "      <td>1159.827087</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>LightGBM_BAG_L2</td>\n",
       "      <td>-7.723093</td>\n",
       "      <td>3726.550966</td>\n",
       "      <td>4732.655613</td>\n",
       "      <td>95.539890</td>\n",
       "      <td>125.458805</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>NeuralNetTorch_BAG_L2</td>\n",
       "      <td>-8.172598</td>\n",
       "      <td>3632.735814</td>\n",
       "      <td>5086.097947</td>\n",
       "      <td>1.724738</td>\n",
       "      <td>478.901138</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>NeuralNetFastAI_BAG_L2</td>\n",
       "      <td>-8.622067</td>\n",
       "      <td>3634.029923</td>\n",
       "      <td>4886.596070</td>\n",
       "      <td>3.018848</td>\n",
       "      <td>279.399261</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>LightGBMXT_BAG_L2</td>\n",
       "      <td>-8.740319</td>\n",
       "      <td>4406.466877</td>\n",
       "      <td>4869.027779</td>\n",
       "      <td>775.455802</td>\n",
       "      <td>261.830970</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>WeightedEnsemble_L2</td>\n",
       "      <td>-8.922663</td>\n",
       "      <td>1390.256731</td>\n",
       "      <td>319.319569</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.295137</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>LightGBMLarge_BAG_L1</td>\n",
       "      <td>-9.154548</td>\n",
       "      <td>1369.864642</td>\n",
       "      <td>221.331852</td>\n",
       "      <td>1369.864642</td>\n",
       "      <td>221.331852</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>ExtraTreesMSE_BAG_L1</td>\n",
       "      <td>-9.779790</td>\n",
       "      <td>10.282452</td>\n",
       "      <td>28.324369</td>\n",
       "      <td>10.282452</td>\n",
       "      <td>28.324369</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>RandomForestMSE_BAG_L1</td>\n",
       "      <td>-9.835545</td>\n",
       "      <td>10.109636</td>\n",
       "      <td>64.368212</td>\n",
       "      <td>10.109636</td>\n",
       "      <td>64.368212</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>LightGBM_BAG_L1</td>\n",
       "      <td>-12.168678</td>\n",
       "      <td>909.400844</td>\n",
       "      <td>165.030807</td>\n",
       "      <td>909.400844</td>\n",
       "      <td>165.030807</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>KNeighborsDist_BAG_L1</td>\n",
       "      <td>-20.479712</td>\n",
       "      <td>1.477804</td>\n",
       "      <td>0.770112</td>\n",
       "      <td>1.477804</td>\n",
       "      <td>0.770112</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>CatBoost_BAG_L1</td>\n",
       "      <td>-22.053135</td>\n",
       "      <td>0.814843</td>\n",
       "      <td>993.819181</td>\n",
       "      <td>0.814843</td>\n",
       "      <td>993.819181</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>KNeighborsUnif_BAG_L1</td>\n",
       "      <td>-23.521270</td>\n",
       "      <td>1.334891</td>\n",
       "      <td>0.754417</td>\n",
       "      <td>1.334891</td>\n",
       "      <td>0.754417</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>LightGBMXT_BAG_L1</td>\n",
       "      <td>-31.342631</td>\n",
       "      <td>1323.816925</td>\n",
       "      <td>284.472183</td>\n",
       "      <td>1323.816925</td>\n",
       "      <td>284.472183</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>NeuralNetTorch_BAG_L1</td>\n",
       "      <td>-32.472859</td>\n",
       "      <td>1.001531</td>\n",
       "      <td>2562.805840</td>\n",
       "      <td>1.001531</td>\n",
       "      <td>2562.805840</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>NeuralNetFastAI_BAG_L1</td>\n",
       "      <td>-68.202994</td>\n",
       "      <td>2.907507</td>\n",
       "      <td>285.519836</td>\n",
       "      <td>2.907507</td>\n",
       "      <td>285.519836</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     model  score_val  pred_time_val     fit_time  \\\n",
       "0      WeightedEnsemble_L3  -6.812446    4675.638708  5690.760465   \n",
       "1   RandomForestMSE_BAG_L2  -6.905120    3639.920054  4942.047835   \n",
       "2     ExtraTreesMSE_BAG_L2  -7.052058    3639.118638  4658.510261   \n",
       "3     LightGBMLarge_BAG_L2  -7.244969    4665.000014  4872.546138   \n",
       "4          CatBoost_BAG_L2  -7.596639    3631.997084  5767.023896   \n",
       "5          LightGBM_BAG_L2  -7.723093    3726.550966  4732.655613   \n",
       "6    NeuralNetTorch_BAG_L2  -8.172598    3632.735814  5086.097947   \n",
       "7   NeuralNetFastAI_BAG_L2  -8.622067    3634.029923  4886.596070   \n",
       "8        LightGBMXT_BAG_L2  -8.740319    4406.466877  4869.027779   \n",
       "9      WeightedEnsemble_L2  -8.922663    1390.256731   319.319569   \n",
       "10    LightGBMLarge_BAG_L1  -9.154548    1369.864642   221.331852   \n",
       "11    ExtraTreesMSE_BAG_L1  -9.779790      10.282452    28.324369   \n",
       "12  RandomForestMSE_BAG_L1  -9.835545      10.109636    64.368212   \n",
       "13         LightGBM_BAG_L1 -12.168678     909.400844   165.030807   \n",
       "14   KNeighborsDist_BAG_L1 -20.479712       1.477804     0.770112   \n",
       "15         CatBoost_BAG_L1 -22.053135       0.814843   993.819181   \n",
       "16   KNeighborsUnif_BAG_L1 -23.521270       1.334891     0.754417   \n",
       "17       LightGBMXT_BAG_L1 -31.342631    1323.816925   284.472183   \n",
       "18   NeuralNetTorch_BAG_L1 -32.472859       1.001531  2562.805840   \n",
       "19  NeuralNetFastAI_BAG_L1 -68.202994       2.907507   285.519836   \n",
       "\n",
       "    pred_time_val_marginal  fit_time_marginal  stack_level  can_infer  \\\n",
       "0                 0.004978           4.462162            3       True   \n",
       "1                 8.908978         334.851027            2       True   \n",
       "2                 8.107562          51.313452            2       True   \n",
       "3              1033.988938         265.349329            2       True   \n",
       "4                 0.986009        1159.827087            2       True   \n",
       "5                95.539890         125.458805            2       True   \n",
       "6                 1.724738         478.901138            2       True   \n",
       "7                 3.018848         279.399261            2       True   \n",
       "8               775.455802         261.830970            2       True   \n",
       "9                 0.000000           5.295137            2       True   \n",
       "10             1369.864642         221.331852            1       True   \n",
       "11               10.282452          28.324369            1       True   \n",
       "12               10.109636          64.368212            1       True   \n",
       "13              909.400844         165.030807            1       True   \n",
       "14                1.477804           0.770112            1       True   \n",
       "15                0.814843         993.819181            1       True   \n",
       "16                1.334891           0.754417            1       True   \n",
       "17             1323.816925         284.472183            1       True   \n",
       "18                1.001531        2562.805840            1       True   \n",
       "19                2.907507         285.519836            1       True   \n",
       "\n",
       "    fit_order  \n",
       "0          20  \n",
       "1          14  \n",
       "2          16  \n",
       "3          19  \n",
       "4          15  \n",
       "5          13  \n",
       "6          18  \n",
       "7          17  \n",
       "8          12  \n",
       "9          11  \n",
       "10         10  \n",
       "11          7  \n",
       "12          5  \n",
       "13          4  \n",
       "14          2  \n",
       "15          6  \n",
       "16          1  \n",
       "17          3  \n",
       "18          9  \n",
       "19          8  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictor.leaderboard(silent = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9d65809b-75e1-4956-bf3b-db846c7a54ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing feature importance via permutation shuffling for 8 features using 5000 rows with 5 shuffle sets...\n",
      "\t1721.4s\t= Expected runtime (344.28s per shuffle set)\n",
      "\t756.12s\t= Actual runtime (Completed 5 of 5 shuffle sets)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>importance</th>\n",
       "      <th>stddev</th>\n",
       "      <th>p_value</th>\n",
       "      <th>n</th>\n",
       "      <th>p99_high</th>\n",
       "      <th>p99_low</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>month</th>\n",
       "      <td>940.737553</td>\n",
       "      <td>16.381477</td>\n",
       "      <td>1.102920e-08</td>\n",
       "      <td>5</td>\n",
       "      <td>974.467242</td>\n",
       "      <td>907.007865</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DUBAI</th>\n",
       "      <td>850.429598</td>\n",
       "      <td>11.924667</td>\n",
       "      <td>4.637661e-09</td>\n",
       "      <td>5</td>\n",
       "      <td>874.982653</td>\n",
       "      <td>825.876543</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WTI</th>\n",
       "      <td>841.952225</td>\n",
       "      <td>8.620641</td>\n",
       "      <td>1.318648e-09</td>\n",
       "      <td>5</td>\n",
       "      <td>859.702243</td>\n",
       "      <td>824.202206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BDI_ADJ</th>\n",
       "      <td>838.793221</td>\n",
       "      <td>6.990974</td>\n",
       "      <td>5.789914e-10</td>\n",
       "      <td>5</td>\n",
       "      <td>853.187733</td>\n",
       "      <td>824.398709</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>year</th>\n",
       "      <td>837.225778</td>\n",
       "      <td>10.454654</td>\n",
       "      <td>2.917153e-09</td>\n",
       "      <td>5</td>\n",
       "      <td>858.752055</td>\n",
       "      <td>815.699502</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BRENT</th>\n",
       "      <td>764.631709</td>\n",
       "      <td>4.940292</td>\n",
       "      <td>2.091021e-10</td>\n",
       "      <td>5</td>\n",
       "      <td>774.803838</td>\n",
       "      <td>754.459579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>OIL</th>\n",
       "      <td>693.891490</td>\n",
       "      <td>10.005778</td>\n",
       "      <td>5.186783e-09</td>\n",
       "      <td>5</td>\n",
       "      <td>714.493526</td>\n",
       "      <td>673.289454</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>day</th>\n",
       "      <td>184.866021</td>\n",
       "      <td>1.399382</td>\n",
       "      <td>3.939714e-10</td>\n",
       "      <td>5</td>\n",
       "      <td>187.747368</td>\n",
       "      <td>181.984674</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         importance     stddev       p_value  n    p99_high     p99_low\n",
       "month    940.737553  16.381477  1.102920e-08  5  974.467242  907.007865\n",
       "DUBAI    850.429598  11.924667  4.637661e-09  5  874.982653  825.876543\n",
       "WTI      841.952225   8.620641  1.318648e-09  5  859.702243  824.202206\n",
       "BDI_ADJ  838.793221   6.990974  5.789914e-10  5  853.187733  824.398709\n",
       "year     837.225778  10.454654  2.917153e-09  5  858.752055  815.699502\n",
       "BRENT    764.631709   4.940292  2.091021e-10  5  774.803838  754.459579\n",
       "OIL      693.891490  10.005778  5.186783e-09  5  714.493526  673.289454\n",
       "day      184.866021   1.399382  3.939714e-10  5  187.747368  181.984674"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictor.feature_importance(train_data) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6448c241-137e-4779-8688-6fec9d6723c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_to_use = predictor.get_model_best()\n",
    "model_pred = predictor.predict(test_data, model=model_to_use)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "09ef2538-5852-4784-ab89-cf0c40e9486e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  94.205536,  378.5741  ,    8.05019 , ...,    7.673829,\n",
       "          9.269344, 1161.8945  ], dtype=float32)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_y = np.where(model_pred < 0, 0, model_pred)\n",
    "pred_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e3282741-dfb6-4ba8-84f3-7c742e73e047",
   "metadata": {},
   "outputs": [],
   "source": [
    "submit = pd.read_csv('../open/sample_submission.csv')\n",
    "submit['CI_HOUR'] = pred_y\n",
    "submit.to_csv('../Sub/autogluon_1.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95d67d3a",
   "metadata": {},
   "source": [
    "# Sep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d9c952ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.read_csv('sample_submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f67fb372-f40f-46f5-a684-0c7e6fc7253d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No path specified. Models will be saved in: \"AutogluonModels\\ag-20231016_181113\\\"\n",
      "Presets specified: ['best_quality']\n",
      "Stack configuration (auto_stack=True): num_stack_levels=1, num_bag_folds=8, num_bag_sets=1\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to \"AutogluonModels\\ag-20231016_181113\\\"\n",
      "AutoGluon Version:  0.8.2\n",
      "Python Version:     3.8.16\n",
      "Operating System:   Windows\n",
      "Platform Machine:   AMD64\n",
      "Platform Version:   10.0.22621\n",
      "Disk Space Avail:   153.17 GB / 511.09 GB (30.0%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Data Rows:    25184\n",
      "Train Data Columns: 7\n",
      "Label Column: CI_HOUR\n",
      "Preprocessing data ...\n",
      "AutoGluon infers your prediction problem is: 'regression' (because dtype of label-column == float and many unique label-values observed).\n",
      "\tLabel info (max, min, mean, stddev): (2152.193889, 0.016388889, 104.15655, 213.23163)\n",
      "\tIf 'regression' is not the correct problem_type, please manually specify the problem_type parameter during predictor init (You may specify problem_type as one of: ['binary', 'multiclass', 'regression'])\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    18779.37 MB\n",
      "\tTrain Data (Original)  Memory Usage: 1.21 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 5 | ['WTI', 'DUBAI', 'BRENT', 'OIL', 'BDI_ADJ']\n",
      "\t\t('int', [])   : 2 | ['month', 'day']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 5 | ['WTI', 'DUBAI', 'BRENT', 'OIL', 'BDI_ADJ']\n",
      "\t\t('int', [])   : 2 | ['month', 'day']\n",
      "\t0.1s = Fit runtime\n",
      "\t7 features in original data used to generate 7 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 1.21 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.08s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'mean_absolute_error'\n",
      "\tThis metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'NN_TORCH': {},\n",
      "\t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, 'GBMLarge'],\n",
      "\t'CAT': {},\n",
      "\t'XGB': {},\n",
      "\t'FASTAI': {},\n",
      "\t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'KNN': [{'weights': 'uniform', 'ag_args': {'name_suffix': 'Unif'}}, {'weights': 'distance', 'ag_args': {'name_suffix': 'Dist'}}],\n",
      "}\n",
      "AutoGluon will fit 2 stack levels (L1 to L2) ...\n",
      "Fitting 11 L1 models ...\n",
      "Fitting model: KNeighborsUnif_BAG_L1 ...\n",
      "Specified total num_gpus: 1, but only 0 are available. Will use 0 instead\n",
      "\t-36.917\t = Validation score   (-mean_absolute_error)\n",
      "\t0.02s\t = Training   runtime\n",
      "\t0.07s\t = Validation runtime\n",
      "Fitting model: KNeighborsDist_BAG_L1 ...\n",
      "Specified total num_gpus: 1, but only 0 are available. Will use 0 instead\n",
      "\t-32.5196\t = Validation score   (-mean_absolute_error)\n",
      "\t0.03s\t = Training   runtime\n",
      "\t0.07s\t = Validation runtime\n",
      "Fitting model: LightGBMXT_BAG_L1 ...\n",
      "Specified total num_gpus: 1, but only 0 are available. Will use 0 instead\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t-19.4117\t = Validation score   (-mean_absolute_error)\n",
      "\t28.1s\t = Training   runtime\n",
      "\t85.18s\t = Validation runtime\n",
      "Fitting model: LightGBM_BAG_L1 ...\n",
      "Specified total num_gpus: 1, but only 0 are available. Will use 0 instead\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t-12.1351\t = Validation score   (-mean_absolute_error)\n",
      "\t25.41s\t = Training   runtime\n",
      "\t71.47s\t = Validation runtime\n",
      "Fitting model: RandomForestMSE_BAG_L1 ...\n",
      "Specified total num_gpus: 1, but only 0 are available. Will use 0 instead\n",
      "\t-12.3281\t = Validation score   (-mean_absolute_error)\n",
      "\t2.55s\t = Training   runtime\n",
      "\t0.62s\t = Validation runtime\n",
      "Fitting model: CatBoost_BAG_L1 ...\n",
      "Specified total num_gpus: 1, but only 0 are available. Will use 0 instead\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t-10.4691\t = Validation score   (-mean_absolute_error)\n",
      "\t259.3s\t = Training   runtime\n",
      "\t0.1s\t = Validation runtime\n",
      "Fitting model: ExtraTreesMSE_BAG_L1 ...\n",
      "Specified total num_gpus: 1, but only 0 are available. Will use 0 instead\n",
      "\t-12.1835\t = Validation score   (-mean_absolute_error)\n",
      "\t1.16s\t = Training   runtime\n",
      "\t0.6s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_BAG_L1 ...\n",
      "Specified total num_gpus: 1, but only 0 are available. Will use 0 instead\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t-53.2832\t = Validation score   (-mean_absolute_error)\n",
      "\t33.34s\t = Training   runtime\n",
      "\t0.36s\t = Validation runtime\n",
      "Fitting model: XGBoost_BAG_L1 ...\n",
      "Specified total num_gpus: 1, but only 0 are available. Will use 0 instead\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\tWarning: Exception caused XGBoost_BAG_L1 to fail during training... Skipping this model.\n",
      "\t\t\u001b[36mray::_ray_fit()\u001b[39m (pid=33380, ip=127.0.0.1)\n",
      "  File \"python\\ray\\_raylet.pyx\", line 857, in ray._raylet.execute_task\n",
      "  File \"python\\ray\\_raylet.pyx\", line 861, in ray._raylet.execute_task\n",
      "  File \"c:\\Users\\ineeji\\anaconda3\\envs\\v1\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 402, in _ray_fit\n",
      "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, **resources, **kwargs_fold)\n",
      "  File \"c:\\Users\\ineeji\\anaconda3\\envs\\v1\\lib\\site-packages\\autogluon\\core\\models\\abstract\\abstract_model.py\", line 829, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "  File \"c:\\Users\\ineeji\\anaconda3\\envs\\v1\\lib\\site-packages\\autogluon\\tabular\\models\\xgboost\\xgboost_model.py\", line 143, in _fit\n",
      "    self.params_trained[\"n_estimators\"] = bst.best_ntree_limit\n",
      "AttributeError: 'Booster' object has no attribute 'best_ntree_limit'\n",
      "Detailed Traceback:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\ineeji\\anaconda3\\envs\\v1\\lib\\site-packages\\autogluon\\core\\trainer\\abstract_trainer.py\", line 1733, in _train_and_save\n",
      "    model = self._train_single(X, y, model, X_val, y_val, total_resources=total_resources, **model_fit_kwargs)\n",
      "  File \"c:\\Users\\ineeji\\anaconda3\\envs\\v1\\lib\\site-packages\\autogluon\\core\\trainer\\abstract_trainer.py\", line 1684, in _train_single\n",
      "    model = model.fit(X=X, y=y, X_val=X_val, y_val=y_val, total_resources=total_resources, **model_fit_kwargs)\n",
      "  File \"c:\\Users\\ineeji\\anaconda3\\envs\\v1\\lib\\site-packages\\autogluon\\core\\models\\abstract\\abstract_model.py\", line 829, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "  File \"c:\\Users\\ineeji\\anaconda3\\envs\\v1\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\stacker_ensemble_model.py\", line 169, in _fit\n",
      "    return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
      "  File \"c:\\Users\\ineeji\\anaconda3\\envs\\v1\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\bagged_ensemble_model.py\", line 266, in _fit\n",
      "    self._fit_folds(\n",
      "  File \"c:\\Users\\ineeji\\anaconda3\\envs\\v1\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\bagged_ensemble_model.py\", line 592, in _fit_folds\n",
      "    fold_fitting_strategy.after_all_folds_scheduled()\n",
      "  File \"c:\\Users\\ineeji\\anaconda3\\envs\\v1\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 581, in after_all_folds_scheduled\n",
      "    raise processed_exception\n",
      "  File \"c:\\Users\\ineeji\\anaconda3\\envs\\v1\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 541, in after_all_folds_scheduled\n",
      "    fold_model, pred_proba, time_start_fit, time_end_fit, predict_time, predict_1_time = self.ray.get(finished)\n",
      "  File \"c:\\Users\\ineeji\\anaconda3\\envs\\v1\\lib\\site-packages\\ray\\_private\\client_mode_hook.py\", line 105, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"c:\\Users\\ineeji\\anaconda3\\envs\\v1\\lib\\site-packages\\ray\\_private\\worker.py\", line 2380, in get\n",
      "    raise value.as_instanceof_cause()\n",
      "ray.exceptions.RayTaskError(AttributeError): \u001b[36mray::_ray_fit()\u001b[39m (pid=33380, ip=127.0.0.1)\n",
      "  File \"python\\ray\\_raylet.pyx\", line 857, in ray._raylet.execute_task\n",
      "  File \"python\\ray\\_raylet.pyx\", line 861, in ray._raylet.execute_task\n",
      "  File \"c:\\Users\\ineeji\\anaconda3\\envs\\v1\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 402, in _ray_fit\n",
      "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, **resources, **kwargs_fold)\n",
      "  File \"c:\\Users\\ineeji\\anaconda3\\envs\\v1\\lib\\site-packages\\autogluon\\core\\models\\abstract\\abstract_model.py\", line 829, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "  File \"c:\\Users\\ineeji\\anaconda3\\envs\\v1\\lib\\site-packages\\autogluon\\tabular\\models\\xgboost\\xgboost_model.py\", line 143, in _fit\n",
      "    self.params_trained[\"n_estimators\"] = bst.best_ntree_limit\n",
      "AttributeError: 'Booster' object has no attribute 'best_ntree_limit'\n",
      "Fitting model: NeuralNetTorch_BAG_L1 ...\n",
      "Specified total num_gpus: 1, but only 0 are available. Will use 0 instead\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "2023-10-17 03:17:55,702\tERROR worker.py:399 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2023-10-17 03:17:55,702\tERROR worker.py:399 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2023-10-17 03:17:55,721\tERROR worker.py:399 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2023-10-17 03:17:55,725\tERROR worker.py:399 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2023-10-17 03:17:55,736\tERROR worker.py:399 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2023-10-17 03:17:55,736\tERROR worker.py:399 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2023-10-17 03:17:55,743\tERROR worker.py:399 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "\t-24.0541\t = Validation score   (-mean_absolute_error)\n",
      "\t288.85s\t = Training   runtime\n",
      "\t0.09s\t = Validation runtime\n",
      "Fitting model: LightGBMLarge_BAG_L1 ...\n",
      "Specified total num_gpus: 1, but only 0 are available. Will use 0 instead\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t-12.3003\t = Validation score   (-mean_absolute_error)\n",
      "\t37.89s\t = Training   runtime\n",
      "\t36.35s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ...\n",
      "\t-10.4105\t = Validation score   (-mean_absolute_error)\n",
      "\t0.36s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting 9 L2 models ...\n",
      "Fitting model: LightGBMXT_BAG_L2 ...\n",
      "Specified total num_gpus: 1, but only 0 are available. Will use 0 instead\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t-10.6417\t = Validation score   (-mean_absolute_error)\n",
      "\t33.12s\t = Training   runtime\n",
      "\t75.72s\t = Validation runtime\n",
      "Fitting model: LightGBM_BAG_L2 ...\n",
      "Specified total num_gpus: 1, but only 0 are available. Will use 0 instead\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t-10.453\t = Validation score   (-mean_absolute_error)\n",
      "\t3.19s\t = Training   runtime\n",
      "\t0.21s\t = Validation runtime\n",
      "Fitting model: RandomForestMSE_BAG_L2 ...\n",
      "Specified total num_gpus: 1, but only 0 are available. Will use 0 instead\n",
      "\t-7.8851\t = Validation score   (-mean_absolute_error)\n",
      "\t19.58s\t = Training   runtime\n",
      "\t0.86s\t = Validation runtime\n",
      "Fitting model: CatBoost_BAG_L2 ...\n",
      "Specified total num_gpus: 1, but only 0 are available. Will use 0 instead\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t-8.989\t = Validation score   (-mean_absolute_error)\n",
      "\t320.46s\t = Training   runtime\n",
      "\t0.08s\t = Validation runtime\n",
      "Fitting model: ExtraTreesMSE_BAG_L2 ...\n",
      "Specified total num_gpus: 1, but only 0 are available. Will use 0 instead\n",
      "\t-7.7234\t = Validation score   (-mean_absolute_error)\n",
      "\t3.8s\t = Training   runtime\n",
      "\t0.83s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_BAG_L2 ...\n",
      "Specified total num_gpus: 1, but only 0 are available. Will use 0 instead\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t-10.7457\t = Validation score   (-mean_absolute_error)\n",
      "\t33.72s\t = Training   runtime\n",
      "\t0.35s\t = Validation runtime\n",
      "Fitting model: XGBoost_BAG_L2 ...\n",
      "Specified total num_gpus: 1, but only 0 are available. Will use 0 instead\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\tWarning: Exception caused XGBoost_BAG_L2 to fail during training... Skipping this model.\n",
      "\t\t\u001b[36mray::_ray_fit()\u001b[39m (pid=17404, ip=127.0.0.1)\n",
      "  File \"python\\ray\\_raylet.pyx\", line 857, in ray._raylet.execute_task\n",
      "  File \"python\\ray\\_raylet.pyx\", line 861, in ray._raylet.execute_task\n",
      "  File \"c:\\Users\\ineeji\\anaconda3\\envs\\v1\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 402, in _ray_fit\n",
      "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, **resources, **kwargs_fold)\n",
      "  File \"c:\\Users\\ineeji\\anaconda3\\envs\\v1\\lib\\site-packages\\autogluon\\core\\models\\abstract\\abstract_model.py\", line 829, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "  File \"c:\\Users\\ineeji\\anaconda3\\envs\\v1\\lib\\site-packages\\autogluon\\tabular\\models\\xgboost\\xgboost_model.py\", line 143, in _fit\n",
      "    self.params_trained[\"n_estimators\"] = bst.best_ntree_limit\n",
      "AttributeError: 'Booster' object has no attribute 'best_ntree_limit'\n",
      "Detailed Traceback:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\ineeji\\anaconda3\\envs\\v1\\lib\\site-packages\\autogluon\\core\\trainer\\abstract_trainer.py\", line 1733, in _train_and_save\n",
      "    model = self._train_single(X, y, model, X_val, y_val, total_resources=total_resources, **model_fit_kwargs)\n",
      "  File \"c:\\Users\\ineeji\\anaconda3\\envs\\v1\\lib\\site-packages\\autogluon\\core\\trainer\\abstract_trainer.py\", line 1684, in _train_single\n",
      "    model = model.fit(X=X, y=y, X_val=X_val, y_val=y_val, total_resources=total_resources, **model_fit_kwargs)\n",
      "  File \"c:\\Users\\ineeji\\anaconda3\\envs\\v1\\lib\\site-packages\\autogluon\\core\\models\\abstract\\abstract_model.py\", line 829, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "  File \"c:\\Users\\ineeji\\anaconda3\\envs\\v1\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\stacker_ensemble_model.py\", line 169, in _fit\n",
      "    return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
      "  File \"c:\\Users\\ineeji\\anaconda3\\envs\\v1\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\bagged_ensemble_model.py\", line 266, in _fit\n",
      "    self._fit_folds(\n",
      "  File \"c:\\Users\\ineeji\\anaconda3\\envs\\v1\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\bagged_ensemble_model.py\", line 592, in _fit_folds\n",
      "    fold_fitting_strategy.after_all_folds_scheduled()\n",
      "  File \"c:\\Users\\ineeji\\anaconda3\\envs\\v1\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 581, in after_all_folds_scheduled\n",
      "    raise processed_exception\n",
      "  File \"c:\\Users\\ineeji\\anaconda3\\envs\\v1\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 541, in after_all_folds_scheduled\n",
      "    fold_model, pred_proba, time_start_fit, time_end_fit, predict_time, predict_1_time = self.ray.get(finished)\n",
      "  File \"c:\\Users\\ineeji\\anaconda3\\envs\\v1\\lib\\site-packages\\ray\\_private\\client_mode_hook.py\", line 105, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"c:\\Users\\ineeji\\anaconda3\\envs\\v1\\lib\\site-packages\\ray\\_private\\worker.py\", line 2380, in get\n",
      "    raise value.as_instanceof_cause()\n",
      "ray.exceptions.RayTaskError(AttributeError): \u001b[36mray::_ray_fit()\u001b[39m (pid=17404, ip=127.0.0.1)\n",
      "  File \"python\\ray\\_raylet.pyx\", line 857, in ray._raylet.execute_task\n",
      "  File \"python\\ray\\_raylet.pyx\", line 861, in ray._raylet.execute_task\n",
      "  File \"c:\\Users\\ineeji\\anaconda3\\envs\\v1\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 402, in _ray_fit\n",
      "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, **resources, **kwargs_fold)\n",
      "  File \"c:\\Users\\ineeji\\anaconda3\\envs\\v1\\lib\\site-packages\\autogluon\\core\\models\\abstract\\abstract_model.py\", line 829, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "  File \"c:\\Users\\ineeji\\anaconda3\\envs\\v1\\lib\\site-packages\\autogluon\\tabular\\models\\xgboost\\xgboost_model.py\", line 143, in _fit\n",
      "    self.params_trained[\"n_estimators\"] = bst.best_ntree_limit\n",
      "AttributeError: 'Booster' object has no attribute 'best_ntree_limit'\n",
      "Fitting model: NeuralNetTorch_BAG_L2 ...\n",
      "Specified total num_gpus: 1, but only 0 are available. Will use 0 instead\n",
      "2023-10-17 03:31:00,058\tERROR worker.py:399 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2023-10-17 03:31:00,058\tERROR worker.py:399 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2023-10-17 03:31:00,058\tERROR worker.py:399 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2023-10-17 03:31:00,058\tERROR worker.py:399 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2023-10-17 03:31:00,075\tERROR worker.py:399 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2023-10-17 03:31:00,080\tERROR worker.py:399 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2023-10-17 03:31:00,083\tERROR worker.py:399 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t-11.6709\t = Validation score   (-mean_absolute_error)\n",
      "\t56.68s\t = Training   runtime\n",
      "\t0.17s\t = Validation runtime\n",
      "Fitting model: LightGBMLarge_BAG_L2 ...\n",
      "Specified total num_gpus: 1, but only 0 are available. Will use 0 instead\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t-8.388\t = Validation score   (-mean_absolute_error)\n",
      "\t70.62s\t = Training   runtime\n",
      "\t52.58s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L3 ...\n",
      "\t-7.655\t = Validation score   (-mean_absolute_error)\n",
      "\t0.33s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 1330.91s ... Best model: \"WeightedEnsemble_L3\"\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels\\ag-20231016_181113\\\")\n",
      "No path specified. Models will be saved in: \"AutogluonModels\\ag-20231016_183530\\\"\n",
      "Presets specified: ['best_quality']\n",
      "Stack configuration (auto_stack=True): num_stack_levels=1, num_bag_folds=8, num_bag_sets=1\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to \"AutogluonModels\\ag-20231016_183530\\\"\n",
      "AutoGluon Version:  0.8.2\n",
      "Python Version:     3.8.16\n",
      "Operating System:   Windows\n",
      "Platform Machine:   AMD64\n",
      "Platform Version:   10.0.22621\n",
      "Disk Space Avail:   149.70 GB / 511.09 GB (29.3%)\n",
      "Train Data Rows:    23892\n",
      "Train Data Columns: 7\n",
      "Label Column: CI_HOUR\n",
      "Preprocessing data ...\n",
      "AutoGluon infers your prediction problem is: 'regression' (because dtype of label-column == float and many unique label-values observed).\n",
      "\tLabel info (max, min, mean, stddev): (2158.901944, 0.027777778, 93.07473, 203.93113)\n",
      "\tIf 'regression' is not the correct problem_type, please manually specify the problem_type parameter during predictor init (You may specify problem_type as one of: ['binary', 'multiclass', 'regression'])\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    19378.24 MB\n",
      "\tTrain Data (Original)  Memory Usage: 1.15 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 5 | ['WTI', 'DUBAI', 'BRENT', 'OIL', 'BDI_ADJ']\n",
      "\t\t('int', [])   : 2 | ['month', 'day']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 5 | ['WTI', 'DUBAI', 'BRENT', 'OIL', 'BDI_ADJ']\n",
      "\t\t('int', [])   : 2 | ['month', 'day']\n",
      "\t0.1s = Fit runtime\n",
      "\t7 features in original data used to generate 7 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 1.15 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.07s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'mean_absolute_error'\n",
      "\tThis metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'NN_TORCH': {},\n",
      "\t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, 'GBMLarge'],\n",
      "\t'CAT': {},\n",
      "\t'XGB': {},\n",
      "\t'FASTAI': {},\n",
      "\t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'KNN': [{'weights': 'uniform', 'ag_args': {'name_suffix': 'Unif'}}, {'weights': 'distance', 'ag_args': {'name_suffix': 'Dist'}}],\n",
      "}\n",
      "AutoGluon will fit 2 stack levels (L1 to L2) ...\n",
      "Fitting 11 L1 models ...\n",
      "Fitting model: KNeighborsUnif_BAG_L1 ...\n",
      "Specified total num_gpus: 1, but only 0 are available. Will use 0 instead\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020\n",
      "2020\n",
      "2020\n",
      "2020\n",
      "2020\n",
      "25184\n",
      "25184\n",
      "25184\n",
      "25184\n",
      "25184\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\t-36.8161\t = Validation score   (-mean_absolute_error)\n",
      "\t0.03s\t = Training   runtime\n",
      "\t0.06s\t = Validation runtime\n",
      "Fitting model: KNeighborsDist_BAG_L1 ...\n",
      "Specified total num_gpus: 1, but only 0 are available. Will use 0 instead\n",
      "\t-32.0095\t = Validation score   (-mean_absolute_error)\n",
      "\t0.02s\t = Training   runtime\n",
      "\t0.07s\t = Validation runtime\n",
      "Fitting model: LightGBMXT_BAG_L1 ...\n",
      "Specified total num_gpus: 1, but only 0 are available. Will use 0 instead\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t-16.0199\t = Validation score   (-mean_absolute_error)\n",
      "\t28.58s\t = Training   runtime\n",
      "\t79.07s\t = Validation runtime\n",
      "Fitting model: LightGBM_BAG_L1 ...\n",
      "Specified total num_gpus: 1, but only 0 are available. Will use 0 instead\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t-11.6047\t = Validation score   (-mean_absolute_error)\n",
      "\t24.32s\t = Training   runtime\n",
      "\t68.78s\t = Validation runtime\n",
      "Fitting model: RandomForestMSE_BAG_L1 ...\n",
      "Specified total num_gpus: 1, but only 0 are available. Will use 0 instead\n",
      "\t-12.8836\t = Validation score   (-mean_absolute_error)\n",
      "\t2.26s\t = Training   runtime\n",
      "\t0.57s\t = Validation runtime\n",
      "Fitting model: CatBoost_BAG_L1 ...\n",
      "Specified total num_gpus: 1, but only 0 are available. Will use 0 instead\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t-10.3036\t = Validation score   (-mean_absolute_error)\n",
      "\t258.65s\t = Training   runtime\n",
      "\t0.09s\t = Validation runtime\n",
      "Fitting model: ExtraTreesMSE_BAG_L1 ...\n",
      "Specified total num_gpus: 1, but only 0 are available. Will use 0 instead\n",
      "\t-12.4474\t = Validation score   (-mean_absolute_error)\n",
      "\t0.75s\t = Training   runtime\n",
      "\t0.61s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_BAG_L1 ...\n",
      "Specified total num_gpus: 1, but only 0 are available. Will use 0 instead\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t-39.6986\t = Validation score   (-mean_absolute_error)\n",
      "\t31.79s\t = Training   runtime\n",
      "\t0.34s\t = Validation runtime\n",
      "Fitting model: XGBoost_BAG_L1 ...\n",
      "Specified total num_gpus: 1, but only 0 are available. Will use 0 instead\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\tWarning: Exception caused XGBoost_BAG_L1 to fail during training... Skipping this model.\n",
      "\t\t\u001b[36mray::_ray_fit()\u001b[39m (pid=34068, ip=127.0.0.1)\n",
      "  File \"python\\ray\\_raylet.pyx\", line 857, in ray._raylet.execute_task\n",
      "  File \"python\\ray\\_raylet.pyx\", line 861, in ray._raylet.execute_task\n",
      "  File \"c:\\Users\\ineeji\\anaconda3\\envs\\v1\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 402, in _ray_fit\n",
      "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, **resources, **kwargs_fold)\n",
      "  File \"c:\\Users\\ineeji\\anaconda3\\envs\\v1\\lib\\site-packages\\autogluon\\core\\models\\abstract\\abstract_model.py\", line 829, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "  File \"c:\\Users\\ineeji\\anaconda3\\envs\\v1\\lib\\site-packages\\autogluon\\tabular\\models\\xgboost\\xgboost_model.py\", line 143, in _fit\n",
      "    self.params_trained[\"n_estimators\"] = bst.best_ntree_limit\n",
      "AttributeError: 'Booster' object has no attribute 'best_ntree_limit'\n",
      "Detailed Traceback:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\ineeji\\anaconda3\\envs\\v1\\lib\\site-packages\\autogluon\\core\\trainer\\abstract_trainer.py\", line 1733, in _train_and_save\n",
      "    model = self._train_single(X, y, model, X_val, y_val, total_resources=total_resources, **model_fit_kwargs)\n",
      "  File \"c:\\Users\\ineeji\\anaconda3\\envs\\v1\\lib\\site-packages\\autogluon\\core\\trainer\\abstract_trainer.py\", line 1684, in _train_single\n",
      "    model = model.fit(X=X, y=y, X_val=X_val, y_val=y_val, total_resources=total_resources, **model_fit_kwargs)\n",
      "  File \"c:\\Users\\ineeji\\anaconda3\\envs\\v1\\lib\\site-packages\\autogluon\\core\\models\\abstract\\abstract_model.py\", line 829, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "  File \"c:\\Users\\ineeji\\anaconda3\\envs\\v1\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\stacker_ensemble_model.py\", line 169, in _fit\n",
      "    return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
      "  File \"c:\\Users\\ineeji\\anaconda3\\envs\\v1\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\bagged_ensemble_model.py\", line 266, in _fit\n",
      "    self._fit_folds(\n",
      "  File \"c:\\Users\\ineeji\\anaconda3\\envs\\v1\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\bagged_ensemble_model.py\", line 592, in _fit_folds\n",
      "    fold_fitting_strategy.after_all_folds_scheduled()\n",
      "  File \"c:\\Users\\ineeji\\anaconda3\\envs\\v1\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 581, in after_all_folds_scheduled\n",
      "    raise processed_exception\n",
      "  File \"c:\\Users\\ineeji\\anaconda3\\envs\\v1\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 541, in after_all_folds_scheduled\n",
      "    fold_model, pred_proba, time_start_fit, time_end_fit, predict_time, predict_1_time = self.ray.get(finished)\n",
      "  File \"c:\\Users\\ineeji\\anaconda3\\envs\\v1\\lib\\site-packages\\ray\\_private\\client_mode_hook.py\", line 105, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"c:\\Users\\ineeji\\anaconda3\\envs\\v1\\lib\\site-packages\\ray\\_private\\worker.py\", line 2380, in get\n",
      "    raise value.as_instanceof_cause()\n",
      "ray.exceptions.RayTaskError(AttributeError): \u001b[36mray::_ray_fit()\u001b[39m (pid=34068, ip=127.0.0.1)\n",
      "  File \"python\\ray\\_raylet.pyx\", line 857, in ray._raylet.execute_task\n",
      "  File \"python\\ray\\_raylet.pyx\", line 861, in ray._raylet.execute_task\n",
      "  File \"c:\\Users\\ineeji\\anaconda3\\envs\\v1\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 402, in _ray_fit\n",
      "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, **resources, **kwargs_fold)\n",
      "  File \"c:\\Users\\ineeji\\anaconda3\\envs\\v1\\lib\\site-packages\\autogluon\\core\\models\\abstract\\abstract_model.py\", line 829, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "  File \"c:\\Users\\ineeji\\anaconda3\\envs\\v1\\lib\\site-packages\\autogluon\\tabular\\models\\xgboost\\xgboost_model.py\", line 143, in _fit\n",
      "    self.params_trained[\"n_estimators\"] = bst.best_ntree_limit\n",
      "AttributeError: 'Booster' object has no attribute 'best_ntree_limit'\n",
      "Fitting model: NeuralNetTorch_BAG_L1 ...\n",
      "Specified total num_gpus: 1, but only 0 are available. Will use 0 instead\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "2023-10-17 03:42:07,258\tERROR worker.py:399 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2023-10-17 03:42:07,263\tERROR worker.py:399 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2023-10-17 03:42:07,267\tERROR worker.py:399 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2023-10-17 03:42:07,273\tERROR worker.py:399 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2023-10-17 03:42:07,279\tERROR worker.py:399 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2023-10-17 03:42:07,296\tERROR worker.py:399 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2023-10-17 03:42:07,298\tERROR worker.py:399 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "\t-20.937\t = Validation score   (-mean_absolute_error)\n",
      "\t210.52s\t = Training   runtime\n",
      "\t0.07s\t = Validation runtime\n",
      "Fitting model: LightGBMLarge_BAG_L1 ...\n",
      "Specified total num_gpus: 1, but only 0 are available. Will use 0 instead\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t-12.8466\t = Validation score   (-mean_absolute_error)\n",
      "\t43.48s\t = Training   runtime\n",
      "\t48.11s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ...\n",
      "\t-10.2339\t = Validation score   (-mean_absolute_error)\n",
      "\t0.37s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting 9 L2 models ...\n",
      "Fitting model: LightGBMXT_BAG_L2 ...\n",
      "Specified total num_gpus: 1, but only 0 are available. Will use 0 instead\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t-10.1563\t = Validation score   (-mean_absolute_error)\n",
      "\t29.45s\t = Training   runtime\n",
      "\t57.26s\t = Validation runtime\n",
      "Fitting model: LightGBM_BAG_L2 ...\n",
      "Specified total num_gpus: 1, but only 0 are available. Will use 0 instead\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t-9.9784\t = Validation score   (-mean_absolute_error)\n",
      "\t19.59s\t = Training   runtime\n",
      "\t2.89s\t = Validation runtime\n",
      "Fitting model: RandomForestMSE_BAG_L2 ...\n",
      "Specified total num_gpus: 1, but only 0 are available. Will use 0 instead\n",
      "\t-7.6327\t = Validation score   (-mean_absolute_error)\n",
      "\t17.05s\t = Training   runtime\n",
      "\t0.84s\t = Validation runtime\n",
      "Fitting model: CatBoost_BAG_L2 ...\n",
      "Specified total num_gpus: 1, but only 0 are available. Will use 0 instead\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t-8.6777\t = Validation score   (-mean_absolute_error)\n",
      "\t316.47s\t = Training   runtime\n",
      "\t0.07s\t = Validation runtime\n",
      "Fitting model: ExtraTreesMSE_BAG_L2 ...\n",
      "Specified total num_gpus: 1, but only 0 are available. Will use 0 instead\n",
      "\t-7.5293\t = Validation score   (-mean_absolute_error)\n",
      "\t3.46s\t = Training   runtime\n",
      "\t0.82s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_BAG_L2 ...\n",
      "Specified total num_gpus: 1, but only 0 are available. Will use 0 instead\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t-10.6451\t = Validation score   (-mean_absolute_error)\n",
      "\t32.25s\t = Training   runtime\n",
      "\t0.36s\t = Validation runtime\n",
      "Fitting model: XGBoost_BAG_L2 ...\n",
      "Specified total num_gpus: 1, but only 0 are available. Will use 0 instead\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\tWarning: Exception caused XGBoost_BAG_L2 to fail during training... Skipping this model.\n",
      "\t\t\u001b[36mray::_ray_fit()\u001b[39m (pid=28228, ip=127.0.0.1)\n",
      "  File \"python\\ray\\_raylet.pyx\", line 857, in ray._raylet.execute_task\n",
      "  File \"python\\ray\\_raylet.pyx\", line 861, in ray._raylet.execute_task\n",
      "  File \"c:\\Users\\ineeji\\anaconda3\\envs\\v1\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 402, in _ray_fit\n",
      "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, **resources, **kwargs_fold)\n",
      "  File \"c:\\Users\\ineeji\\anaconda3\\envs\\v1\\lib\\site-packages\\autogluon\\core\\models\\abstract\\abstract_model.py\", line 829, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "  File \"c:\\Users\\ineeji\\anaconda3\\envs\\v1\\lib\\site-packages\\autogluon\\tabular\\models\\xgboost\\xgboost_model.py\", line 143, in _fit\n",
      "    self.params_trained[\"n_estimators\"] = bst.best_ntree_limit\n",
      "AttributeError: 'Booster' object has no attribute 'best_ntree_limit'\n",
      "Detailed Traceback:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\ineeji\\anaconda3\\envs\\v1\\lib\\site-packages\\autogluon\\core\\trainer\\abstract_trainer.py\", line 1733, in _train_and_save\n",
      "    model = self._train_single(X, y, model, X_val, y_val, total_resources=total_resources, **model_fit_kwargs)\n",
      "  File \"c:\\Users\\ineeji\\anaconda3\\envs\\v1\\lib\\site-packages\\autogluon\\core\\trainer\\abstract_trainer.py\", line 1684, in _train_single\n",
      "    model = model.fit(X=X, y=y, X_val=X_val, y_val=y_val, total_resources=total_resources, **model_fit_kwargs)\n",
      "  File \"c:\\Users\\ineeji\\anaconda3\\envs\\v1\\lib\\site-packages\\autogluon\\core\\models\\abstract\\abstract_model.py\", line 829, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "  File \"c:\\Users\\ineeji\\anaconda3\\envs\\v1\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\stacker_ensemble_model.py\", line 169, in _fit\n",
      "    return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
      "  File \"c:\\Users\\ineeji\\anaconda3\\envs\\v1\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\bagged_ensemble_model.py\", line 266, in _fit\n",
      "    self._fit_folds(\n",
      "  File \"c:\\Users\\ineeji\\anaconda3\\envs\\v1\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\bagged_ensemble_model.py\", line 592, in _fit_folds\n",
      "    fold_fitting_strategy.after_all_folds_scheduled()\n",
      "  File \"c:\\Users\\ineeji\\anaconda3\\envs\\v1\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 581, in after_all_folds_scheduled\n",
      "    raise processed_exception\n",
      "  File \"c:\\Users\\ineeji\\anaconda3\\envs\\v1\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 541, in after_all_folds_scheduled\n",
      "    fold_model, pred_proba, time_start_fit, time_end_fit, predict_time, predict_1_time = self.ray.get(finished)\n",
      "  File \"c:\\Users\\ineeji\\anaconda3\\envs\\v1\\lib\\site-packages\\ray\\_private\\client_mode_hook.py\", line 105, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"c:\\Users\\ineeji\\anaconda3\\envs\\v1\\lib\\site-packages\\ray\\_private\\worker.py\", line 2380, in get\n",
      "    raise value.as_instanceof_cause()\n",
      "ray.exceptions.RayTaskError(AttributeError): \u001b[36mray::_ray_fit()\u001b[39m (pid=28228, ip=127.0.0.1)\n",
      "  File \"python\\ray\\_raylet.pyx\", line 857, in ray._raylet.execute_task\n",
      "  File \"python\\ray\\_raylet.pyx\", line 861, in ray._raylet.execute_task\n",
      "  File \"c:\\Users\\ineeji\\anaconda3\\envs\\v1\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 402, in _ray_fit\n",
      "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, **resources, **kwargs_fold)\n",
      "  File \"c:\\Users\\ineeji\\anaconda3\\envs\\v1\\lib\\site-packages\\autogluon\\core\\models\\abstract\\abstract_model.py\", line 829, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "  File \"c:\\Users\\ineeji\\anaconda3\\envs\\v1\\lib\\site-packages\\autogluon\\tabular\\models\\xgboost\\xgboost_model.py\", line 143, in _fit\n",
      "    self.params_trained[\"n_estimators\"] = bst.best_ntree_limit\n",
      "AttributeError: 'Booster' object has no attribute 'best_ntree_limit'\n",
      "Fitting model: NeuralNetTorch_BAG_L2 ...\n",
      "Specified total num_gpus: 1, but only 0 are available. Will use 0 instead\n",
      "2023-10-17 03:54:10,234\tERROR worker.py:399 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2023-10-17 03:54:10,234\tERROR worker.py:399 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2023-10-17 03:54:10,234\tERROR worker.py:399 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2023-10-17 03:54:10,267\tERROR worker.py:399 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2023-10-17 03:54:10,270\tERROR worker.py:399 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2023-10-17 03:54:10,273\tERROR worker.py:399 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2023-10-17 03:54:10,273\tERROR worker.py:399 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t-11.316\t = Validation score   (-mean_absolute_error)\n",
      "\t48.57s\t = Training   runtime\n",
      "\t0.17s\t = Validation runtime\n",
      "Fitting model: LightGBMLarge_BAG_L2 ...\n",
      "Specified total num_gpus: 1, but only 0 are available. Will use 0 instead\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t-8.2933\t = Validation score   (-mean_absolute_error)\n",
      "\t69.36s\t = Training   runtime\n",
      "\t47.56s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L3 ...\n",
      "\t-7.4725\t = Validation score   (-mean_absolute_error)\n",
      "\t0.34s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 1253.82s ... Best model: \"WeightedEnsemble_L3\"\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels\\ag-20231016_183530\\\")\n",
      "No path specified. Models will be saved in: \"AutogluonModels\\ag-20231016_185829\\\"\n",
      "Presets specified: ['best_quality']\n",
      "Stack configuration (auto_stack=True): num_stack_levels=1, num_bag_folds=8, num_bag_sets=1\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to \"AutogluonModels\\ag-20231016_185829\\\"\n",
      "AutoGluon Version:  0.8.2\n",
      "Python Version:     3.8.16\n",
      "Operating System:   Windows\n",
      "Platform Machine:   AMD64\n",
      "Platform Version:   10.0.22621\n",
      "Disk Space Avail:   146.13 GB / 511.09 GB (28.6%)\n",
      "Train Data Rows:    43318\n",
      "Train Data Columns: 7\n",
      "Label Column: CI_HOUR\n",
      "Preprocessing data ...\n",
      "AutoGluon infers your prediction problem is: 'regression' (because dtype of label-column == float and many unique label-values observed).\n",
      "\tLabel info (max, min, mean, stddev): (2158.4675, 0.380833333, 112.53597, 223.90738)\n",
      "\tIf 'regression' is not the correct problem_type, please manually specify the problem_type parameter during predictor init (You may specify problem_type as one of: ['binary', 'multiclass', 'regression'])\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    19194.5 MB\n",
      "\tTrain Data (Original)  Memory Usage: 2.08 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 5 | ['WTI', 'DUBAI', 'BRENT', 'OIL', 'BDI_ADJ']\n",
      "\t\t('int', [])   : 2 | ['month', 'day']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 5 | ['WTI', 'DUBAI', 'BRENT', 'OIL', 'BDI_ADJ']\n",
      "\t\t('int', [])   : 2 | ['month', 'day']\n",
      "\t0.1s = Fit runtime\n",
      "\t7 features in original data used to generate 7 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 2.08 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.09s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'mean_absolute_error'\n",
      "\tThis metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'NN_TORCH': {},\n",
      "\t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, 'GBMLarge'],\n",
      "\t'CAT': {},\n",
      "\t'XGB': {},\n",
      "\t'FASTAI': {},\n",
      "\t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'KNN': [{'weights': 'uniform', 'ag_args': {'name_suffix': 'Unif'}}, {'weights': 'distance', 'ag_args': {'name_suffix': 'Dist'}}],\n",
      "}\n",
      "AutoGluon will fit 2 stack levels (L1 to L2) ...\n",
      "Fitting 11 L1 models ...\n",
      "Fitting model: KNeighborsUnif_BAG_L1 ...\n",
      "Specified total num_gpus: 1, but only 0 are available. Will use 0 instead\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019\n",
      "2019\n",
      "2019\n",
      "2019\n",
      "2019\n",
      "23892\n",
      "23892\n",
      "23892\n",
      "23892\n",
      "23892\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\t-37.4332\t = Validation score   (-mean_absolute_error)\n",
      "\t0.05s\t = Training   runtime\n",
      "\t0.09s\t = Validation runtime\n",
      "Fitting model: KNeighborsDist_BAG_L1 ...\n",
      "Specified total num_gpus: 1, but only 0 are available. Will use 0 instead\n",
      "\t-31.8715\t = Validation score   (-mean_absolute_error)\n",
      "\t0.03s\t = Training   runtime\n",
      "\t0.13s\t = Validation runtime\n",
      "Fitting model: LightGBMXT_BAG_L1 ...\n",
      "Specified total num_gpus: 1, but only 0 are available. Will use 0 instead\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t-18.2987\t = Validation score   (-mean_absolute_error)\n",
      "\t37.37s\t = Training   runtime\n",
      "\t148.39s\t = Validation runtime\n",
      "Fitting model: LightGBM_BAG_L1 ...\n",
      "Specified total num_gpus: 1, but only 0 are available. Will use 0 instead\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t-10.8411\t = Validation score   (-mean_absolute_error)\n",
      "\t30.07s\t = Training   runtime\n",
      "\t122.79s\t = Validation runtime\n",
      "Fitting model: RandomForestMSE_BAG_L1 ...\n",
      "Specified total num_gpus: 1, but only 0 are available. Will use 0 instead\n",
      "\t-11.4499\t = Validation score   (-mean_absolute_error)\n",
      "\t3.2s\t = Training   runtime\n",
      "\t1.03s\t = Validation runtime\n",
      "Fitting model: CatBoost_BAG_L1 ...\n",
      "Specified total num_gpus: 1, but only 0 are available. Will use 0 instead\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t-9.8927\t = Validation score   (-mean_absolute_error)\n",
      "\t295.19s\t = Training   runtime\n",
      "\t0.1s\t = Validation runtime\n",
      "Fitting model: ExtraTreesMSE_BAG_L1 ...\n",
      "Specified total num_gpus: 1, but only 0 are available. Will use 0 instead\n",
      "\t-11.2975\t = Validation score   (-mean_absolute_error)\n",
      "\t1.62s\t = Training   runtime\n",
      "\t1.04s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_BAG_L1 ...\n",
      "Specified total num_gpus: 1, but only 0 are available. Will use 0 instead\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t-54.5669\t = Validation score   (-mean_absolute_error)\n",
      "\t54.75s\t = Training   runtime\n",
      "\t0.55s\t = Validation runtime\n",
      "Fitting model: XGBoost_BAG_L1 ...\n",
      "Specified total num_gpus: 1, but only 0 are available. Will use 0 instead\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\tWarning: Exception caused XGBoost_BAG_L1 to fail during training... Skipping this model.\n",
      "\t\t\u001b[36mray::_ray_fit()\u001b[39m (pid=32088, ip=127.0.0.1)\n",
      "  File \"python\\ray\\_raylet.pyx\", line 857, in ray._raylet.execute_task\n",
      "  File \"python\\ray\\_raylet.pyx\", line 861, in ray._raylet.execute_task\n",
      "  File \"c:\\Users\\ineeji\\anaconda3\\envs\\v1\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 402, in _ray_fit\n",
      "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, **resources, **kwargs_fold)\n",
      "  File \"c:\\Users\\ineeji\\anaconda3\\envs\\v1\\lib\\site-packages\\autogluon\\core\\models\\abstract\\abstract_model.py\", line 829, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "  File \"c:\\Users\\ineeji\\anaconda3\\envs\\v1\\lib\\site-packages\\autogluon\\tabular\\models\\xgboost\\xgboost_model.py\", line 143, in _fit\n",
      "    self.params_trained[\"n_estimators\"] = bst.best_ntree_limit\n",
      "AttributeError: 'Booster' object has no attribute 'best_ntree_limit'\n",
      "Detailed Traceback:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\ineeji\\anaconda3\\envs\\v1\\lib\\site-packages\\autogluon\\core\\trainer\\abstract_trainer.py\", line 1733, in _train_and_save\n",
      "    model = self._train_single(X, y, model, X_val, y_val, total_resources=total_resources, **model_fit_kwargs)\n",
      "  File \"c:\\Users\\ineeji\\anaconda3\\envs\\v1\\lib\\site-packages\\autogluon\\core\\trainer\\abstract_trainer.py\", line 1684, in _train_single\n",
      "    model = model.fit(X=X, y=y, X_val=X_val, y_val=y_val, total_resources=total_resources, **model_fit_kwargs)\n",
      "  File \"c:\\Users\\ineeji\\anaconda3\\envs\\v1\\lib\\site-packages\\autogluon\\core\\models\\abstract\\abstract_model.py\", line 829, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "  File \"c:\\Users\\ineeji\\anaconda3\\envs\\v1\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\stacker_ensemble_model.py\", line 169, in _fit\n",
      "    return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
      "  File \"c:\\Users\\ineeji\\anaconda3\\envs\\v1\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\bagged_ensemble_model.py\", line 266, in _fit\n",
      "    self._fit_folds(\n",
      "  File \"c:\\Users\\ineeji\\anaconda3\\envs\\v1\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\bagged_ensemble_model.py\", line 592, in _fit_folds\n",
      "    fold_fitting_strategy.after_all_folds_scheduled()\n",
      "  File \"c:\\Users\\ineeji\\anaconda3\\envs\\v1\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 581, in after_all_folds_scheduled\n",
      "    raise processed_exception\n",
      "  File \"c:\\Users\\ineeji\\anaconda3\\envs\\v1\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 541, in after_all_folds_scheduled\n",
      "    fold_model, pred_proba, time_start_fit, time_end_fit, predict_time, predict_1_time = self.ray.get(finished)\n",
      "  File \"c:\\Users\\ineeji\\anaconda3\\envs\\v1\\lib\\site-packages\\ray\\_private\\client_mode_hook.py\", line 105, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"c:\\Users\\ineeji\\anaconda3\\envs\\v1\\lib\\site-packages\\ray\\_private\\worker.py\", line 2380, in get\n",
      "    raise value.as_instanceof_cause()\n",
      "ray.exceptions.RayTaskError(AttributeError): \u001b[36mray::_ray_fit()\u001b[39m (pid=32088, ip=127.0.0.1)\n",
      "  File \"python\\ray\\_raylet.pyx\", line 857, in ray._raylet.execute_task\n",
      "  File \"python\\ray\\_raylet.pyx\", line 861, in ray._raylet.execute_task\n",
      "  File \"c:\\Users\\ineeji\\anaconda3\\envs\\v1\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 402, in _ray_fit\n",
      "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, **resources, **kwargs_fold)\n",
      "  File \"c:\\Users\\ineeji\\anaconda3\\envs\\v1\\lib\\site-packages\\autogluon\\core\\models\\abstract\\abstract_model.py\", line 829, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "  File \"c:\\Users\\ineeji\\anaconda3\\envs\\v1\\lib\\site-packages\\autogluon\\tabular\\models\\xgboost\\xgboost_model.py\", line 143, in _fit\n",
      "    self.params_trained[\"n_estimators\"] = bst.best_ntree_limit\n",
      "AttributeError: 'Booster' object has no attribute 'best_ntree_limit'\n",
      "Fitting model: NeuralNetTorch_BAG_L1 ...\n",
      "Specified total num_gpus: 1, but only 0 are available. Will use 0 instead\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "2023-10-17 04:06:48,391\tERROR worker.py:399 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2023-10-17 04:06:48,399\tERROR worker.py:399 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2023-10-17 04:06:48,405\tERROR worker.py:399 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2023-10-17 04:06:48,406\tERROR worker.py:399 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2023-10-17 04:06:48,406\tERROR worker.py:399 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2023-10-17 04:06:48,416\tERROR worker.py:399 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2023-10-17 04:06:48,418\tERROR worker.py:399 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "\t-19.1954\t = Validation score   (-mean_absolute_error)\n",
      "\t357.55s\t = Training   runtime\n",
      "\t0.13s\t = Validation runtime\n",
      "Fitting model: LightGBMLarge_BAG_L1 ...\n",
      "Specified total num_gpus: 1, but only 0 are available. Will use 0 instead\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t-11.0335\t = Validation score   (-mean_absolute_error)\n",
      "\t52.56s\t = Training   runtime\n",
      "\t142.11s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ...\n",
      "\t-9.733\t = Validation score   (-mean_absolute_error)\n",
      "\t0.55s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting 9 L2 models ...\n",
      "Fitting model: LightGBMXT_BAG_L2 ...\n",
      "Specified total num_gpus: 1, but only 0 are available. Will use 0 instead\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t-9.6517\t = Validation score   (-mean_absolute_error)\n",
      "\t42.66s\t = Training   runtime\n",
      "\t125.98s\t = Validation runtime\n",
      "Fitting model: LightGBM_BAG_L2 ...\n",
      "Specified total num_gpus: 1, but only 0 are available. Will use 0 instead\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t-8.7638\t = Validation score   (-mean_absolute_error)\n",
      "\t32.8s\t = Training   runtime\n",
      "\t38.96s\t = Validation runtime\n",
      "Fitting model: RandomForestMSE_BAG_L2 ...\n",
      "Specified total num_gpus: 1, but only 0 are available. Will use 0 instead\n",
      "\t-6.8432\t = Validation score   (-mean_absolute_error)\n",
      "\t31.54s\t = Training   runtime\n",
      "\t1.48s\t = Validation runtime\n",
      "Fitting model: CatBoost_BAG_L2 ...\n",
      "Specified total num_gpus: 1, but only 0 are available. Will use 0 instead\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t-8.0784\t = Validation score   (-mean_absolute_error)\n",
      "\t360.67s\t = Training   runtime\n",
      "\t0.12s\t = Validation runtime\n",
      "Fitting model: ExtraTreesMSE_BAG_L2 ...\n",
      "Specified total num_gpus: 1, but only 0 are available. Will use 0 instead\n",
      "\t-6.7194\t = Validation score   (-mean_absolute_error)\n",
      "\t5.54s\t = Training   runtime\n",
      "\t1.47s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_BAG_L2 ...\n",
      "Specified total num_gpus: 1, but only 0 are available. Will use 0 instead\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t-10.2564\t = Validation score   (-mean_absolute_error)\n",
      "\t55.46s\t = Training   runtime\n",
      "\t0.58s\t = Validation runtime\n",
      "Fitting model: XGBoost_BAG_L2 ...\n",
      "Specified total num_gpus: 1, but only 0 are available. Will use 0 instead\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\tWarning: Exception caused XGBoost_BAG_L2 to fail during training... Skipping this model.\n",
      "\t\t\u001b[36mray::_ray_fit()\u001b[39m (pid=36280, ip=127.0.0.1)\n",
      "  File \"python\\ray\\_raylet.pyx\", line 857, in ray._raylet.execute_task\n",
      "  File \"python\\ray\\_raylet.pyx\", line 861, in ray._raylet.execute_task\n",
      "  File \"c:\\Users\\ineeji\\anaconda3\\envs\\v1\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 402, in _ray_fit\n",
      "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, **resources, **kwargs_fold)\n",
      "  File \"c:\\Users\\ineeji\\anaconda3\\envs\\v1\\lib\\site-packages\\autogluon\\core\\models\\abstract\\abstract_model.py\", line 829, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "  File \"c:\\Users\\ineeji\\anaconda3\\envs\\v1\\lib\\site-packages\\autogluon\\tabular\\models\\xgboost\\xgboost_model.py\", line 143, in _fit\n",
      "    self.params_trained[\"n_estimators\"] = bst.best_ntree_limit\n",
      "AttributeError: 'Booster' object has no attribute 'best_ntree_limit'\n",
      "Detailed Traceback:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\ineeji\\anaconda3\\envs\\v1\\lib\\site-packages\\autogluon\\core\\trainer\\abstract_trainer.py\", line 1733, in _train_and_save\n",
      "    model = self._train_single(X, y, model, X_val, y_val, total_resources=total_resources, **model_fit_kwargs)\n",
      "  File \"c:\\Users\\ineeji\\anaconda3\\envs\\v1\\lib\\site-packages\\autogluon\\core\\trainer\\abstract_trainer.py\", line 1684, in _train_single\n",
      "    model = model.fit(X=X, y=y, X_val=X_val, y_val=y_val, total_resources=total_resources, **model_fit_kwargs)\n",
      "  File \"c:\\Users\\ineeji\\anaconda3\\envs\\v1\\lib\\site-packages\\autogluon\\core\\models\\abstract\\abstract_model.py\", line 829, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "  File \"c:\\Users\\ineeji\\anaconda3\\envs\\v1\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\stacker_ensemble_model.py\", line 169, in _fit\n",
      "    return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
      "  File \"c:\\Users\\ineeji\\anaconda3\\envs\\v1\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\bagged_ensemble_model.py\", line 266, in _fit\n",
      "    self._fit_folds(\n",
      "  File \"c:\\Users\\ineeji\\anaconda3\\envs\\v1\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\bagged_ensemble_model.py\", line 592, in _fit_folds\n",
      "    fold_fitting_strategy.after_all_folds_scheduled()\n",
      "  File \"c:\\Users\\ineeji\\anaconda3\\envs\\v1\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 581, in after_all_folds_scheduled\n",
      "    raise processed_exception\n",
      "  File \"c:\\Users\\ineeji\\anaconda3\\envs\\v1\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 541, in after_all_folds_scheduled\n",
      "    fold_model, pred_proba, time_start_fit, time_end_fit, predict_time, predict_1_time = self.ray.get(finished)\n",
      "  File \"c:\\Users\\ineeji\\anaconda3\\envs\\v1\\lib\\site-packages\\ray\\_private\\client_mode_hook.py\", line 105, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"c:\\Users\\ineeji\\anaconda3\\envs\\v1\\lib\\site-packages\\ray\\_private\\worker.py\", line 2380, in get\n",
      "    raise value.as_instanceof_cause()\n",
      "ray.exceptions.RayTaskError(AttributeError): \u001b[36mray::_ray_fit()\u001b[39m (pid=36280, ip=127.0.0.1)\n",
      "  File \"python\\ray\\_raylet.pyx\", line 857, in ray._raylet.execute_task\n",
      "  File \"python\\ray\\_raylet.pyx\", line 861, in ray._raylet.execute_task\n",
      "  File \"c:\\Users\\ineeji\\anaconda3\\envs\\v1\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 402, in _ray_fit\n",
      "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, **resources, **kwargs_fold)\n",
      "  File \"c:\\Users\\ineeji\\anaconda3\\envs\\v1\\lib\\site-packages\\autogluon\\core\\models\\abstract\\abstract_model.py\", line 829, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "  File \"c:\\Users\\ineeji\\anaconda3\\envs\\v1\\lib\\site-packages\\autogluon\\tabular\\models\\xgboost\\xgboost_model.py\", line 143, in _fit\n",
      "    self.params_trained[\"n_estimators\"] = bst.best_ntree_limit\n",
      "AttributeError: 'Booster' object has no attribute 'best_ntree_limit'\n",
      "Fitting model: NeuralNetTorch_BAG_L2 ...\n",
      "Specified total num_gpus: 1, but only 0 are available. Will use 0 instead\n",
      "2023-10-17 04:24:47,565\tERROR worker.py:399 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2023-10-17 04:24:47,569\tERROR worker.py:399 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2023-10-17 04:24:47,581\tERROR worker.py:399 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2023-10-17 04:24:47,583\tERROR worker.py:399 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2023-10-17 04:24:47,586\tERROR worker.py:399 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2023-10-17 04:24:47,588\tERROR worker.py:399 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2023-10-17 04:24:47,591\tERROR worker.py:399 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t-11.0637\t = Validation score   (-mean_absolute_error)\n",
      "\t62.22s\t = Training   runtime\n",
      "\t0.32s\t = Validation runtime\n",
      "Fitting model: LightGBMLarge_BAG_L2 ...\n",
      "Specified total num_gpus: 1, but only 0 are available. Will use 0 instead\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t-7.5413\t = Validation score   (-mean_absolute_error)\n",
      "\t77.07s\t = Training   runtime\n",
      "\t73.6s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L3 ...\n",
      "\t-6.6994\t = Validation score   (-mean_absolute_error)\n",
      "\t0.47s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 1732.82s ... Best model: \"WeightedEnsemble_L3\"\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels\\ag-20231016_185829\\\")\n",
      "No path specified. Models will be saved in: \"AutogluonModels\\ag-20231016_193102\\\"\n",
      "Presets specified: ['best_quality']\n",
      "Stack configuration (auto_stack=True): num_stack_levels=1, num_bag_folds=8, num_bag_sets=1\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to \"AutogluonModels\\ag-20231016_193102\\\"\n",
      "AutoGluon Version:  0.8.2\n",
      "Python Version:     3.8.16\n",
      "Operating System:   Windows\n",
      "Platform Machine:   AMD64\n",
      "Platform Version:   10.0.22621\n",
      "Disk Space Avail:   142.02 GB / 511.09 GB (27.8%)\n",
      "Train Data Rows:    13452\n",
      "Train Data Columns: 7\n",
      "Label Column: CI_HOUR\n",
      "Preprocessing data ...\n",
      "AutoGluon infers your prediction problem is: 'regression' (because dtype of label-column == float and many unique label-values observed).\n",
      "\tLabel info (max, min, mean, stddev): (2159.130556, 0.0225, 115.68402, 226.00542)\n",
      "\tIf 'regression' is not the correct problem_type, please manually specify the problem_type parameter during predictor init (You may specify problem_type as one of: ['binary', 'multiclass', 'regression'])\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    19242.22 MB\n",
      "\tTrain Data (Original)  Memory Usage: 0.65 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 5 | ['WTI', 'DUBAI', 'BRENT', 'OIL', 'BDI_ADJ']\n",
      "\t\t('int', [])   : 2 | ['month', 'day']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 5 | ['WTI', 'DUBAI', 'BRENT', 'OIL', 'BDI_ADJ']\n",
      "\t\t('int', [])   : 2 | ['month', 'day']\n",
      "\t0.0s = Fit runtime\n",
      "\t7 features in original data used to generate 7 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 0.65 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.07s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'mean_absolute_error'\n",
      "\tThis metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'NN_TORCH': {},\n",
      "\t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, 'GBMLarge'],\n",
      "\t'CAT': {},\n",
      "\t'XGB': {},\n",
      "\t'FASTAI': {},\n",
      "\t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'KNN': [{'weights': 'uniform', 'ag_args': {'name_suffix': 'Unif'}}, {'weights': 'distance', 'ag_args': {'name_suffix': 'Dist'}}],\n",
      "}\n",
      "AutoGluon will fit 2 stack levels (L1 to L2) ...\n",
      "Fitting 11 L1 models ...\n",
      "Fitting model: KNeighborsUnif_BAG_L1 ...\n",
      "Specified total num_gpus: 1, but only 0 are available. Will use 0 instead\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022\n",
      "2022\n",
      "2022\n",
      "2022\n",
      "2022\n",
      "43318\n",
      "43318\n",
      "43318\n",
      "43318\n",
      "43318\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\t-46.4223\t = Validation score   (-mean_absolute_error)\n",
      "\t0.01s\t = Training   runtime\n",
      "\t0.04s\t = Validation runtime\n",
      "Fitting model: KNeighborsDist_BAG_L1 ...\n",
      "Specified total num_gpus: 1, but only 0 are available. Will use 0 instead\n",
      "\t-40.6739\t = Validation score   (-mean_absolute_error)\n",
      "\t0.01s\t = Training   runtime\n",
      "\t0.04s\t = Validation runtime\n",
      "Fitting model: LightGBMXT_BAG_L1 ...\n",
      "Specified total num_gpus: 1, but only 0 are available. Will use 0 instead\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t-19.0195\t = Validation score   (-mean_absolute_error)\n",
      "\t22.4s\t = Training   runtime\n",
      "\t43.23s\t = Validation runtime\n",
      "Fitting model: LightGBM_BAG_L1 ...\n",
      "Specified total num_gpus: 1, but only 0 are available. Will use 0 instead\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t-13.7381\t = Validation score   (-mean_absolute_error)\n",
      "\t22.71s\t = Training   runtime\n",
      "\t40.75s\t = Validation runtime\n",
      "Fitting model: RandomForestMSE_BAG_L1 ...\n",
      "Specified total num_gpus: 1, but only 0 are available. Will use 0 instead\n",
      "\t-16.0803\t = Validation score   (-mean_absolute_error)\n",
      "\t1.38s\t = Training   runtime\n",
      "\t0.33s\t = Validation runtime\n",
      "Fitting model: CatBoost_BAG_L1 ...\n",
      "Specified total num_gpus: 1, but only 0 are available. Will use 0 instead\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t-11.9663\t = Validation score   (-mean_absolute_error)\n",
      "\t236.38s\t = Training   runtime\n",
      "\t0.06s\t = Validation runtime\n",
      "Fitting model: ExtraTreesMSE_BAG_L1 ...\n",
      "Specified total num_gpus: 1, but only 0 are available. Will use 0 instead\n",
      "\t-15.3037\t = Validation score   (-mean_absolute_error)\n",
      "\t0.72s\t = Training   runtime\n",
      "\t0.39s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_BAG_L1 ...\n",
      "Specified total num_gpus: 1, but only 0 are available. Will use 0 instead\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t-47.5625\t = Validation score   (-mean_absolute_error)\n",
      "\t19.71s\t = Training   runtime\n",
      "\t0.23s\t = Validation runtime\n",
      "Fitting model: XGBoost_BAG_L1 ...\n",
      "Specified total num_gpus: 1, but only 0 are available. Will use 0 instead\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\tWarning: Exception caused XGBoost_BAG_L1 to fail during training... Skipping this model.\n",
      "\t\t\u001b[36mray::_ray_fit()\u001b[39m (pid=9636, ip=127.0.0.1)\n",
      "  File \"python\\ray\\_raylet.pyx\", line 857, in ray._raylet.execute_task\n",
      "  File \"python\\ray\\_raylet.pyx\", line 861, in ray._raylet.execute_task\n",
      "  File \"c:\\Users\\ineeji\\anaconda3\\envs\\v1\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 402, in _ray_fit\n",
      "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, **resources, **kwargs_fold)\n",
      "  File \"c:\\Users\\ineeji\\anaconda3\\envs\\v1\\lib\\site-packages\\autogluon\\core\\models\\abstract\\abstract_model.py\", line 829, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "  File \"c:\\Users\\ineeji\\anaconda3\\envs\\v1\\lib\\site-packages\\autogluon\\tabular\\models\\xgboost\\xgboost_model.py\", line 143, in _fit\n",
      "    self.params_trained[\"n_estimators\"] = bst.best_ntree_limit\n",
      "AttributeError: 'Booster' object has no attribute 'best_ntree_limit'\n",
      "Detailed Traceback:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\ineeji\\anaconda3\\envs\\v1\\lib\\site-packages\\autogluon\\core\\trainer\\abstract_trainer.py\", line 1733, in _train_and_save\n",
      "    model = self._train_single(X, y, model, X_val, y_val, total_resources=total_resources, **model_fit_kwargs)\n",
      "  File \"c:\\Users\\ineeji\\anaconda3\\envs\\v1\\lib\\site-packages\\autogluon\\core\\trainer\\abstract_trainer.py\", line 1684, in _train_single\n",
      "    model = model.fit(X=X, y=y, X_val=X_val, y_val=y_val, total_resources=total_resources, **model_fit_kwargs)\n",
      "  File \"c:\\Users\\ineeji\\anaconda3\\envs\\v1\\lib\\site-packages\\autogluon\\core\\models\\abstract\\abstract_model.py\", line 829, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "  File \"c:\\Users\\ineeji\\anaconda3\\envs\\v1\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\stacker_ensemble_model.py\", line 169, in _fit\n",
      "    return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
      "  File \"c:\\Users\\ineeji\\anaconda3\\envs\\v1\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\bagged_ensemble_model.py\", line 266, in _fit\n",
      "    self._fit_folds(\n",
      "  File \"c:\\Users\\ineeji\\anaconda3\\envs\\v1\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\bagged_ensemble_model.py\", line 592, in _fit_folds\n",
      "    fold_fitting_strategy.after_all_folds_scheduled()\n",
      "  File \"c:\\Users\\ineeji\\anaconda3\\envs\\v1\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 581, in after_all_folds_scheduled\n",
      "    raise processed_exception\n",
      "  File \"c:\\Users\\ineeji\\anaconda3\\envs\\v1\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 541, in after_all_folds_scheduled\n",
      "    fold_model, pred_proba, time_start_fit, time_end_fit, predict_time, predict_1_time = self.ray.get(finished)\n",
      "  File \"c:\\Users\\ineeji\\anaconda3\\envs\\v1\\lib\\site-packages\\ray\\_private\\client_mode_hook.py\", line 105, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"c:\\Users\\ineeji\\anaconda3\\envs\\v1\\lib\\site-packages\\ray\\_private\\worker.py\", line 2380, in get\n",
      "    raise value.as_instanceof_cause()\n",
      "ray.exceptions.RayTaskError(AttributeError): \u001b[36mray::_ray_fit()\u001b[39m (pid=9636, ip=127.0.0.1)\n",
      "  File \"python\\ray\\_raylet.pyx\", line 857, in ray._raylet.execute_task\n",
      "  File \"python\\ray\\_raylet.pyx\", line 861, in ray._raylet.execute_task\n",
      "  File \"c:\\Users\\ineeji\\anaconda3\\envs\\v1\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 402, in _ray_fit\n",
      "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, **resources, **kwargs_fold)\n",
      "  File \"c:\\Users\\ineeji\\anaconda3\\envs\\v1\\lib\\site-packages\\autogluon\\core\\models\\abstract\\abstract_model.py\", line 829, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "  File \"c:\\Users\\ineeji\\anaconda3\\envs\\v1\\lib\\site-packages\\autogluon\\tabular\\models\\xgboost\\xgboost_model.py\", line 143, in _fit\n",
      "    self.params_trained[\"n_estimators\"] = bst.best_ntree_limit\n",
      "AttributeError: 'Booster' object has no attribute 'best_ntree_limit'\n",
      "Fitting model: NeuralNetTorch_BAG_L1 ...\n",
      "Specified total num_gpus: 1, but only 0 are available. Will use 0 instead\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "2023-10-17 04:36:43,702\tERROR worker.py:399 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2023-10-17 04:36:43,706\tERROR worker.py:399 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2023-10-17 04:36:43,712\tERROR worker.py:399 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2023-10-17 04:36:43,719\tERROR worker.py:399 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2023-10-17 04:36:43,724\tERROR worker.py:399 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2023-10-17 04:36:43,726\tERROR worker.py:399 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2023-10-17 04:36:43,730\tERROR worker.py:399 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "\t-27.3936\t = Validation score   (-mean_absolute_error)\n",
      "\t131.42s\t = Training   runtime\n",
      "\t0.07s\t = Validation runtime\n",
      "Fitting model: LightGBMLarge_BAG_L1 ...\n",
      "Specified total num_gpus: 1, but only 0 are available. Will use 0 instead\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t-15.3061\t = Validation score   (-mean_absolute_error)\n",
      "\t28.09s\t = Training   runtime\n",
      "\t14.85s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ...\n",
      "\t-11.9068\t = Validation score   (-mean_absolute_error)\n",
      "\t0.29s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting 9 L2 models ...\n",
      "Fitting model: LightGBMXT_BAG_L2 ...\n",
      "Specified total num_gpus: 1, but only 0 are available. Will use 0 instead\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t-11.9988\t = Validation score   (-mean_absolute_error)\n",
      "\t23.2s\t = Training   runtime\n",
      "\t27.92s\t = Validation runtime\n",
      "Fitting model: LightGBM_BAG_L2 ...\n",
      "Specified total num_gpus: 1, but only 0 are available. Will use 0 instead\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t-11.4436\t = Validation score   (-mean_absolute_error)\n",
      "\t18.95s\t = Training   runtime\n",
      "\t2.23s\t = Validation runtime\n",
      "Fitting model: RandomForestMSE_BAG_L2 ...\n",
      "Specified total num_gpus: 1, but only 0 are available. Will use 0 instead\n",
      "\t-9.6699\t = Validation score   (-mean_absolute_error)\n",
      "\t9.8s\t = Training   runtime\n",
      "\t0.45s\t = Validation runtime\n",
      "Fitting model: CatBoost_BAG_L2 ...\n",
      "Specified total num_gpus: 1, but only 0 are available. Will use 0 instead\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t-10.2542\t = Validation score   (-mean_absolute_error)\n",
      "\t291.47s\t = Training   runtime\n",
      "\t0.07s\t = Validation runtime\n",
      "Fitting model: ExtraTreesMSE_BAG_L2 ...\n",
      "Specified total num_gpus: 1, but only 0 are available. Will use 0 instead\n",
      "\t-9.526\t = Validation score   (-mean_absolute_error)\n",
      "\t2.07s\t = Training   runtime\n",
      "\t0.45s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_BAG_L2 ...\n",
      "Specified total num_gpus: 1, but only 0 are available. Will use 0 instead\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t-12.0661\t = Validation score   (-mean_absolute_error)\n",
      "\t19.85s\t = Training   runtime\n",
      "\t0.22s\t = Validation runtime\n",
      "Fitting model: XGBoost_BAG_L2 ...\n",
      "Specified total num_gpus: 1, but only 0 are available. Will use 0 instead\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\tWarning: Exception caused XGBoost_BAG_L2 to fail during training... Skipping this model.\n",
      "\t\t\u001b[36mray::_ray_fit()\u001b[39m (pid=37204, ip=127.0.0.1)\n",
      "  File \"python\\ray\\_raylet.pyx\", line 857, in ray._raylet.execute_task\n",
      "  File \"python\\ray\\_raylet.pyx\", line 861, in ray._raylet.execute_task\n",
      "  File \"c:\\Users\\ineeji\\anaconda3\\envs\\v1\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 402, in _ray_fit\n",
      "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, **resources, **kwargs_fold)\n",
      "  File \"c:\\Users\\ineeji\\anaconda3\\envs\\v1\\lib\\site-packages\\autogluon\\core\\models\\abstract\\abstract_model.py\", line 829, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "  File \"c:\\Users\\ineeji\\anaconda3\\envs\\v1\\lib\\site-packages\\autogluon\\tabular\\models\\xgboost\\xgboost_model.py\", line 143, in _fit\n",
      "    self.params_trained[\"n_estimators\"] = bst.best_ntree_limit\n",
      "AttributeError: 'Booster' object has no attribute 'best_ntree_limit'\n",
      "Detailed Traceback:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\ineeji\\anaconda3\\envs\\v1\\lib\\site-packages\\autogluon\\core\\trainer\\abstract_trainer.py\", line 1733, in _train_and_save\n",
      "    model = self._train_single(X, y, model, X_val, y_val, total_resources=total_resources, **model_fit_kwargs)\n",
      "  File \"c:\\Users\\ineeji\\anaconda3\\envs\\v1\\lib\\site-packages\\autogluon\\core\\trainer\\abstract_trainer.py\", line 1684, in _train_single\n",
      "    model = model.fit(X=X, y=y, X_val=X_val, y_val=y_val, total_resources=total_resources, **model_fit_kwargs)\n",
      "  File \"c:\\Users\\ineeji\\anaconda3\\envs\\v1\\lib\\site-packages\\autogluon\\core\\models\\abstract\\abstract_model.py\", line 829, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "  File \"c:\\Users\\ineeji\\anaconda3\\envs\\v1\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\stacker_ensemble_model.py\", line 169, in _fit\n",
      "    return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
      "  File \"c:\\Users\\ineeji\\anaconda3\\envs\\v1\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\bagged_ensemble_model.py\", line 266, in _fit\n",
      "    self._fit_folds(\n",
      "  File \"c:\\Users\\ineeji\\anaconda3\\envs\\v1\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\bagged_ensemble_model.py\", line 592, in _fit_folds\n",
      "    fold_fitting_strategy.after_all_folds_scheduled()\n",
      "  File \"c:\\Users\\ineeji\\anaconda3\\envs\\v1\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 581, in after_all_folds_scheduled\n",
      "    raise processed_exception\n",
      "  File \"c:\\Users\\ineeji\\anaconda3\\envs\\v1\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 541, in after_all_folds_scheduled\n",
      "    fold_model, pred_proba, time_start_fit, time_end_fit, predict_time, predict_1_time = self.ray.get(finished)\n",
      "  File \"c:\\Users\\ineeji\\anaconda3\\envs\\v1\\lib\\site-packages\\ray\\_private\\client_mode_hook.py\", line 105, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"c:\\Users\\ineeji\\anaconda3\\envs\\v1\\lib\\site-packages\\ray\\_private\\worker.py\", line 2380, in get\n",
      "    raise value.as_instanceof_cause()\n",
      "ray.exceptions.RayTaskError(AttributeError): \u001b[36mray::_ray_fit()\u001b[39m (pid=37204, ip=127.0.0.1)\n",
      "  File \"python\\ray\\_raylet.pyx\", line 857, in ray._raylet.execute_task\n",
      "  File \"python\\ray\\_raylet.pyx\", line 861, in ray._raylet.execute_task\n",
      "  File \"c:\\Users\\ineeji\\anaconda3\\envs\\v1\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 402, in _ray_fit\n",
      "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, **resources, **kwargs_fold)\n",
      "  File \"c:\\Users\\ineeji\\anaconda3\\envs\\v1\\lib\\site-packages\\autogluon\\core\\models\\abstract\\abstract_model.py\", line 829, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "  File \"c:\\Users\\ineeji\\anaconda3\\envs\\v1\\lib\\site-packages\\autogluon\\tabular\\models\\xgboost\\xgboost_model.py\", line 143, in _fit\n",
      "    self.params_trained[\"n_estimators\"] = bst.best_ntree_limit\n",
      "AttributeError: 'Booster' object has no attribute 'best_ntree_limit'\n",
      "Fitting model: NeuralNetTorch_BAG_L2 ...\n",
      "Specified total num_gpus: 1, but only 0 are available. Will use 0 instead\n",
      "2023-10-17 04:46:57,990\tERROR worker.py:399 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2023-10-17 04:46:57,994\tERROR worker.py:399 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2023-10-17 04:46:57,994\tERROR worker.py:399 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2023-10-17 04:46:58,000\tERROR worker.py:399 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2023-10-17 04:46:58,003\tERROR worker.py:399 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2023-10-17 04:46:58,007\tERROR worker.py:399 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2023-10-17 04:46:58,010\tERROR worker.py:399 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t-12.6574\t = Validation score   (-mean_absolute_error)\n",
      "\t39.46s\t = Training   runtime\n",
      "\t0.17s\t = Validation runtime\n",
      "Fitting model: LightGBMLarge_BAG_L2 ...\n",
      "Specified total num_gpus: 1, but only 0 are available. Will use 0 instead\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t-10.2884\t = Validation score   (-mean_absolute_error)\n",
      "\t69.23s\t = Training   runtime\n",
      "\t44.48s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L3 ...\n",
      "\t-9.421\t = Validation score   (-mean_absolute_error)\n",
      "\t0.3s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 1082.46s ... Best model: \"WeightedEnsemble_L3\"\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels\\ag-20231016_193102\\\")\n",
      "No path specified. Models will be saved in: \"AutogluonModels\\ag-20231016_195041\\\"\n",
      "Presets specified: ['best_quality']\n",
      "Stack configuration (auto_stack=True): num_stack_levels=1, num_bag_folds=8, num_bag_sets=1\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to \"AutogluonModels\\ag-20231016_195041\\\"\n",
      "AutoGluon Version:  0.8.2\n",
      "Python Version:     3.8.16\n",
      "Operating System:   Windows\n",
      "Platform Machine:   AMD64\n",
      "Platform Version:   10.0.22621\n",
      "Disk Space Avail:   139.17 GB / 511.09 GB (27.2%)\n",
      "Train Data Rows:    26192\n",
      "Train Data Columns: 7\n",
      "Label Column: CI_HOUR\n",
      "Preprocessing data ...\n",
      "AutoGluon infers your prediction problem is: 'regression' (because dtype of label-column == float and many unique label-values observed).\n",
      "\tLabel info (max, min, mean, stddev): (2151.602778, 0.014166667, 92.91803, 193.81611)\n",
      "\tIf 'regression' is not the correct problem_type, please manually specify the problem_type parameter during predictor init (You may specify problem_type as one of: ['binary', 'multiclass', 'regression'])\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    19239.26 MB\n",
      "\tTrain Data (Original)  Memory Usage: 1.26 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 5 | ['WTI', 'DUBAI', 'BRENT', 'OIL', 'BDI_ADJ']\n",
      "\t\t('int', [])   : 2 | ['month', 'day']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 5 | ['WTI', 'DUBAI', 'BRENT', 'OIL', 'BDI_ADJ']\n",
      "\t\t('int', [])   : 2 | ['month', 'day']\n",
      "\t0.1s = Fit runtime\n",
      "\t7 features in original data used to generate 7 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 1.26 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.09s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'mean_absolute_error'\n",
      "\tThis metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'NN_TORCH': {},\n",
      "\t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, 'GBMLarge'],\n",
      "\t'CAT': {},\n",
      "\t'XGB': {},\n",
      "\t'FASTAI': {},\n",
      "\t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'KNN': [{'weights': 'uniform', 'ag_args': {'name_suffix': 'Unif'}}, {'weights': 'distance', 'ag_args': {'name_suffix': 'Dist'}}],\n",
      "}\n",
      "AutoGluon will fit 2 stack levels (L1 to L2) ...\n",
      "Fitting 11 L1 models ...\n",
      "Fitting model: KNeighborsUnif_BAG_L1 ...\n",
      "Specified total num_gpus: 1, but only 0 are available. Will use 0 instead\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2015\n",
      "2015\n",
      "2015\n",
      "2015\n",
      "2015\n",
      "13452\n",
      "13452\n",
      "13452\n",
      "13452\n",
      "13452\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\t-33.4269\t = Validation score   (-mean_absolute_error)\n",
      "\t0.03s\t = Training   runtime\n",
      "\t0.07s\t = Validation runtime\n",
      "Fitting model: KNeighborsDist_BAG_L1 ...\n",
      "Specified total num_gpus: 1, but only 0 are available. Will use 0 instead\n",
      "\t-29.5734\t = Validation score   (-mean_absolute_error)\n",
      "\t0.03s\t = Training   runtime\n",
      "\t0.06s\t = Validation runtime\n",
      "Fitting model: LightGBMXT_BAG_L1 ...\n",
      "Specified total num_gpus: 1, but only 0 are available. Will use 0 instead\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t-17.1654\t = Validation score   (-mean_absolute_error)\n",
      "\t28.53s\t = Training   runtime\n",
      "\t87.45s\t = Validation runtime\n",
      "Fitting model: LightGBM_BAG_L1 ...\n",
      "Specified total num_gpus: 1, but only 0 are available. Will use 0 instead\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t-11.6091\t = Validation score   (-mean_absolute_error)\n",
      "\t25.54s\t = Training   runtime\n",
      "\t72.33s\t = Validation runtime\n",
      "Fitting model: RandomForestMSE_BAG_L1 ...\n",
      "Specified total num_gpus: 1, but only 0 are available. Will use 0 instead\n",
      "\t-12.3593\t = Validation score   (-mean_absolute_error)\n",
      "\t2.39s\t = Training   runtime\n",
      "\t0.63s\t = Validation runtime\n",
      "Fitting model: CatBoost_BAG_L1 ...\n",
      "Specified total num_gpus: 1, but only 0 are available. Will use 0 instead\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t-10.3239\t = Validation score   (-mean_absolute_error)\n",
      "\t260.92s\t = Training   runtime\n",
      "\t0.09s\t = Validation runtime\n",
      "Fitting model: ExtraTreesMSE_BAG_L1 ...\n",
      "Specified total num_gpus: 1, but only 0 are available. Will use 0 instead\n",
      "\t-12.1344\t = Validation score   (-mean_absolute_error)\n",
      "\t1.09s\t = Training   runtime\n",
      "\t0.63s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_BAG_L1 ...\n",
      "Specified total num_gpus: 1, but only 0 are available. Will use 0 instead\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t-52.3637\t = Validation score   (-mean_absolute_error)\n",
      "\t34.11s\t = Training   runtime\n",
      "\t0.33s\t = Validation runtime\n",
      "Fitting model: XGBoost_BAG_L1 ...\n",
      "Specified total num_gpus: 1, but only 0 are available. Will use 0 instead\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\tWarning: Exception caused XGBoost_BAG_L1 to fail during training... Skipping this model.\n",
      "\t\t\u001b[36mray::_ray_fit()\u001b[39m (pid=30824, ip=127.0.0.1)\n",
      "  File \"python\\ray\\_raylet.pyx\", line 857, in ray._raylet.execute_task\n",
      "  File \"python\\ray\\_raylet.pyx\", line 861, in ray._raylet.execute_task\n",
      "  File \"c:\\Users\\ineeji\\anaconda3\\envs\\v1\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 402, in _ray_fit\n",
      "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, **resources, **kwargs_fold)\n",
      "  File \"c:\\Users\\ineeji\\anaconda3\\envs\\v1\\lib\\site-packages\\autogluon\\core\\models\\abstract\\abstract_model.py\", line 829, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "  File \"c:\\Users\\ineeji\\anaconda3\\envs\\v1\\lib\\site-packages\\autogluon\\tabular\\models\\xgboost\\xgboost_model.py\", line 143, in _fit\n",
      "    self.params_trained[\"n_estimators\"] = bst.best_ntree_limit\n",
      "AttributeError: 'Booster' object has no attribute 'best_ntree_limit'\n",
      "Detailed Traceback:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\ineeji\\anaconda3\\envs\\v1\\lib\\site-packages\\autogluon\\core\\trainer\\abstract_trainer.py\", line 1733, in _train_and_save\n",
      "    model = self._train_single(X, y, model, X_val, y_val, total_resources=total_resources, **model_fit_kwargs)\n",
      "  File \"c:\\Users\\ineeji\\anaconda3\\envs\\v1\\lib\\site-packages\\autogluon\\core\\trainer\\abstract_trainer.py\", line 1684, in _train_single\n",
      "    model = model.fit(X=X, y=y, X_val=X_val, y_val=y_val, total_resources=total_resources, **model_fit_kwargs)\n",
      "  File \"c:\\Users\\ineeji\\anaconda3\\envs\\v1\\lib\\site-packages\\autogluon\\core\\models\\abstract\\abstract_model.py\", line 829, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "  File \"c:\\Users\\ineeji\\anaconda3\\envs\\v1\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\stacker_ensemble_model.py\", line 169, in _fit\n",
      "    return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
      "  File \"c:\\Users\\ineeji\\anaconda3\\envs\\v1\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\bagged_ensemble_model.py\", line 266, in _fit\n",
      "    self._fit_folds(\n",
      "  File \"c:\\Users\\ineeji\\anaconda3\\envs\\v1\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\bagged_ensemble_model.py\", line 592, in _fit_folds\n",
      "    fold_fitting_strategy.after_all_folds_scheduled()\n",
      "  File \"c:\\Users\\ineeji\\anaconda3\\envs\\v1\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 581, in after_all_folds_scheduled\n",
      "    raise processed_exception\n",
      "  File \"c:\\Users\\ineeji\\anaconda3\\envs\\v1\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 541, in after_all_folds_scheduled\n",
      "    fold_model, pred_proba, time_start_fit, time_end_fit, predict_time, predict_1_time = self.ray.get(finished)\n",
      "  File \"c:\\Users\\ineeji\\anaconda3\\envs\\v1\\lib\\site-packages\\ray\\_private\\client_mode_hook.py\", line 105, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"c:\\Users\\ineeji\\anaconda3\\envs\\v1\\lib\\site-packages\\ray\\_private\\worker.py\", line 2380, in get\n",
      "    raise value.as_instanceof_cause()\n",
      "ray.exceptions.RayTaskError(AttributeError): \u001b[36mray::_ray_fit()\u001b[39m (pid=30824, ip=127.0.0.1)\n",
      "  File \"python\\ray\\_raylet.pyx\", line 857, in ray._raylet.execute_task\n",
      "  File \"python\\ray\\_raylet.pyx\", line 861, in ray._raylet.execute_task\n",
      "  File \"c:\\Users\\ineeji\\anaconda3\\envs\\v1\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 402, in _ray_fit\n",
      "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, **resources, **kwargs_fold)\n",
      "  File \"c:\\Users\\ineeji\\anaconda3\\envs\\v1\\lib\\site-packages\\autogluon\\core\\models\\abstract\\abstract_model.py\", line 829, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "  File \"c:\\Users\\ineeji\\anaconda3\\envs\\v1\\lib\\site-packages\\autogluon\\tabular\\models\\xgboost\\xgboost_model.py\", line 143, in _fit\n",
      "    self.params_trained[\"n_estimators\"] = bst.best_ntree_limit\n",
      "AttributeError: 'Booster' object has no attribute 'best_ntree_limit'\n",
      "Fitting model: NeuralNetTorch_BAG_L1 ...\n",
      "Specified total num_gpus: 1, but only 0 are available. Will use 0 instead\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "2023-10-17 04:57:26,949\tERROR worker.py:399 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2023-10-17 04:57:26,949\tERROR worker.py:399 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2023-10-17 04:57:26,955\tERROR worker.py:399 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2023-10-17 04:57:26,960\tERROR worker.py:399 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2023-10-17 04:57:26,965\tERROR worker.py:399 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2023-10-17 04:57:26,969\tERROR worker.py:399 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2023-10-17 04:57:26,971\tERROR worker.py:399 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "\t-21.9189\t = Validation score   (-mean_absolute_error)\n",
      "\t259.64s\t = Training   runtime\n",
      "\t0.1s\t = Validation runtime\n",
      "Fitting model: LightGBMLarge_BAG_L1 ...\n",
      "Specified total num_gpus: 1, but only 0 are available. Will use 0 instead\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t-12.2759\t = Validation score   (-mean_absolute_error)\n",
      "\t33.61s\t = Training   runtime\n",
      "\t56.6s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ...\n",
      "\t-10.2931\t = Validation score   (-mean_absolute_error)\n",
      "\t0.4s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting 9 L2 models ...\n",
      "Fitting model: LightGBMXT_BAG_L2 ...\n",
      "Specified total num_gpus: 1, but only 0 are available. Will use 0 instead\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t-10.3566\t = Validation score   (-mean_absolute_error)\n",
      "\t33.15s\t = Training   runtime\n",
      "\t77.51s\t = Validation runtime\n",
      "Fitting model: LightGBM_BAG_L2 ...\n",
      "Specified total num_gpus: 1, but only 0 are available. Will use 0 instead\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t-9.802\t = Validation score   (-mean_absolute_error)\n",
      "\t21.12s\t = Training   runtime\n",
      "\t3.17s\t = Validation runtime\n",
      "Fitting model: RandomForestMSE_BAG_L2 ...\n",
      "Specified total num_gpus: 1, but only 0 are available. Will use 0 instead\n",
      "\t-7.5827\t = Validation score   (-mean_absolute_error)\n",
      "\t19.68s\t = Training   runtime\n",
      "\t0.93s\t = Validation runtime\n",
      "Fitting model: CatBoost_BAG_L2 ...\n",
      "Specified total num_gpus: 1, but only 0 are available. Will use 0 instead\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t-8.5496\t = Validation score   (-mean_absolute_error)\n",
      "\t320.63s\t = Training   runtime\n",
      "\t0.07s\t = Validation runtime\n",
      "Fitting model: ExtraTreesMSE_BAG_L2 ...\n",
      "Specified total num_gpus: 1, but only 0 are available. Will use 0 instead\n",
      "\t-7.359\t = Validation score   (-mean_absolute_error)\n",
      "\t3.98s\t = Training   runtime\n",
      "\t0.9s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_BAG_L2 ...\n",
      "Specified total num_gpus: 1, but only 0 are available. Will use 0 instead\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t-10.6213\t = Validation score   (-mean_absolute_error)\n",
      "\t34.99s\t = Training   runtime\n",
      "\t0.35s\t = Validation runtime\n",
      "Fitting model: XGBoost_BAG_L2 ...\n",
      "Specified total num_gpus: 1, but only 0 are available. Will use 0 instead\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\tWarning: Exception caused XGBoost_BAG_L2 to fail during training... Skipping this model.\n",
      "\t\t\u001b[36mray::_ray_fit()\u001b[39m (pid=32516, ip=127.0.0.1)\n",
      "  File \"python\\ray\\_raylet.pyx\", line 857, in ray._raylet.execute_task\n",
      "  File \"python\\ray\\_raylet.pyx\", line 861, in ray._raylet.execute_task\n",
      "  File \"c:\\Users\\ineeji\\anaconda3\\envs\\v1\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 402, in _ray_fit\n",
      "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, **resources, **kwargs_fold)\n",
      "  File \"c:\\Users\\ineeji\\anaconda3\\envs\\v1\\lib\\site-packages\\autogluon\\core\\models\\abstract\\abstract_model.py\", line 829, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "  File \"c:\\Users\\ineeji\\anaconda3\\envs\\v1\\lib\\site-packages\\autogluon\\tabular\\models\\xgboost\\xgboost_model.py\", line 143, in _fit\n",
      "    self.params_trained[\"n_estimators\"] = bst.best_ntree_limit\n",
      "AttributeError: 'Booster' object has no attribute 'best_ntree_limit'\n",
      "Detailed Traceback:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\ineeji\\anaconda3\\envs\\v1\\lib\\site-packages\\autogluon\\core\\trainer\\abstract_trainer.py\", line 1733, in _train_and_save\n",
      "    model = self._train_single(X, y, model, X_val, y_val, total_resources=total_resources, **model_fit_kwargs)\n",
      "  File \"c:\\Users\\ineeji\\anaconda3\\envs\\v1\\lib\\site-packages\\autogluon\\core\\trainer\\abstract_trainer.py\", line 1684, in _train_single\n",
      "    model = model.fit(X=X, y=y, X_val=X_val, y_val=y_val, total_resources=total_resources, **model_fit_kwargs)\n",
      "  File \"c:\\Users\\ineeji\\anaconda3\\envs\\v1\\lib\\site-packages\\autogluon\\core\\models\\abstract\\abstract_model.py\", line 829, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "  File \"c:\\Users\\ineeji\\anaconda3\\envs\\v1\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\stacker_ensemble_model.py\", line 169, in _fit\n",
      "    return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
      "  File \"c:\\Users\\ineeji\\anaconda3\\envs\\v1\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\bagged_ensemble_model.py\", line 266, in _fit\n",
      "    self._fit_folds(\n",
      "  File \"c:\\Users\\ineeji\\anaconda3\\envs\\v1\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\bagged_ensemble_model.py\", line 592, in _fit_folds\n",
      "    fold_fitting_strategy.after_all_folds_scheduled()\n",
      "  File \"c:\\Users\\ineeji\\anaconda3\\envs\\v1\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 581, in after_all_folds_scheduled\n",
      "    raise processed_exception\n",
      "  File \"c:\\Users\\ineeji\\anaconda3\\envs\\v1\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 541, in after_all_folds_scheduled\n",
      "    fold_model, pred_proba, time_start_fit, time_end_fit, predict_time, predict_1_time = self.ray.get(finished)\n",
      "  File \"c:\\Users\\ineeji\\anaconda3\\envs\\v1\\lib\\site-packages\\ray\\_private\\client_mode_hook.py\", line 105, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"c:\\Users\\ineeji\\anaconda3\\envs\\v1\\lib\\site-packages\\ray\\_private\\worker.py\", line 2380, in get\n",
      "    raise value.as_instanceof_cause()\n",
      "ray.exceptions.RayTaskError(AttributeError): \u001b[36mray::_ray_fit()\u001b[39m (pid=32516, ip=127.0.0.1)\n",
      "  File \"python\\ray\\_raylet.pyx\", line 857, in ray._raylet.execute_task\n",
      "  File \"python\\ray\\_raylet.pyx\", line 861, in ray._raylet.execute_task\n",
      "  File \"c:\\Users\\ineeji\\anaconda3\\envs\\v1\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 402, in _ray_fit\n",
      "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, **resources, **kwargs_fold)\n",
      "  File \"c:\\Users\\ineeji\\anaconda3\\envs\\v1\\lib\\site-packages\\autogluon\\core\\models\\abstract\\abstract_model.py\", line 829, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "  File \"c:\\Users\\ineeji\\anaconda3\\envs\\v1\\lib\\site-packages\\autogluon\\tabular\\models\\xgboost\\xgboost_model.py\", line 143, in _fit\n",
      "    self.params_trained[\"n_estimators\"] = bst.best_ntree_limit\n",
      "AttributeError: 'Booster' object has no attribute 'best_ntree_limit'\n",
      "Fitting model: NeuralNetTorch_BAG_L2 ...\n",
      "Specified total num_gpus: 1, but only 0 are available. Will use 0 instead\n",
      "2023-10-17 05:10:23,883\tERROR worker.py:399 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2023-10-17 05:10:23,898\tERROR worker.py:399 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2023-10-17 05:10:23,902\tERROR worker.py:399 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2023-10-17 05:10:23,903\tERROR worker.py:399 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2023-10-17 05:10:23,903\tERROR worker.py:399 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2023-10-17 05:10:23,903\tERROR worker.py:399 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2023-10-17 05:10:23,903\tERROR worker.py:399 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t-11.3711\t = Validation score   (-mean_absolute_error)\n",
      "\t57.62s\t = Training   runtime\n",
      "\t0.22s\t = Validation runtime\n",
      "Fitting model: LightGBMLarge_BAG_L2 ...\n",
      "Specified total num_gpus: 1, but only 0 are available. Will use 0 instead\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t-7.9956\t = Validation score   (-mean_absolute_error)\n",
      "\t73.03s\t = Training   runtime\n",
      "\t52.78s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L3 ...\n",
      "\t-7.3137\t = Validation score   (-mean_absolute_error)\n",
      "\t0.38s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 1328.75s ... Best model: \"WeightedEnsemble_L3\"\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels\\ag-20231016_195041\\\")\n",
      "No path specified. Models will be saved in: \"AutogluonModels\\ag-20231016_201454\\\"\n",
      "Presets specified: ['best_quality']\n",
      "Stack configuration (auto_stack=True): num_stack_levels=1, num_bag_folds=8, num_bag_sets=1\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to \"AutogluonModels\\ag-20231016_201454\\\"\n",
      "AutoGluon Version:  0.8.2\n",
      "Python Version:     3.8.16\n",
      "Operating System:   Windows\n",
      "Platform Machine:   AMD64\n",
      "Platform Version:   10.0.22621\n",
      "Disk Space Avail:   135.75 GB / 511.09 GB (26.6%)\n",
      "Train Data Rows:    20486\n",
      "Train Data Columns: 7\n",
      "Label Column: CI_HOUR\n",
      "Preprocessing data ...\n",
      "AutoGluon infers your prediction problem is: 'regression' (because dtype of label-column == float and many unique label-values observed).\n",
      "\tLabel info (max, min, mean, stddev): (2153.450556, 0.002777778, 101.37468, 212.57066)\n",
      "\tIf 'regression' is not the correct problem_type, please manually specify the problem_type parameter during predictor init (You may specify problem_type as one of: ['binary', 'multiclass', 'regression'])\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    19075.35 MB\n",
      "\tTrain Data (Original)  Memory Usage: 0.98 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 5 | ['WTI', 'DUBAI', 'BRENT', 'OIL', 'BDI_ADJ']\n",
      "\t\t('int', [])   : 2 | ['month', 'day']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 5 | ['WTI', 'DUBAI', 'BRENT', 'OIL', 'BDI_ADJ']\n",
      "\t\t('int', [])   : 2 | ['month', 'day']\n",
      "\t0.0s = Fit runtime\n",
      "\t7 features in original data used to generate 7 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 0.98 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.07s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'mean_absolute_error'\n",
      "\tThis metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'NN_TORCH': {},\n",
      "\t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, 'GBMLarge'],\n",
      "\t'CAT': {},\n",
      "\t'XGB': {},\n",
      "\t'FASTAI': {},\n",
      "\t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'KNN': [{'weights': 'uniform', 'ag_args': {'name_suffix': 'Unif'}}, {'weights': 'distance', 'ag_args': {'name_suffix': 'Dist'}}],\n",
      "}\n",
      "AutoGluon will fit 2 stack levels (L1 to L2) ...\n",
      "Fitting 11 L1 models ...\n",
      "Fitting model: KNeighborsUnif_BAG_L1 ...\n",
      "Specified total num_gpus: 1, but only 0 are available. Will use 0 instead\n",
      "\t-40.022\t = Validation score   (-mean_absolute_error)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018\n",
      "2018\n",
      "2018\n",
      "2018\n",
      "2018\n",
      "26192\n",
      "26192\n",
      "26192\n",
      "26192\n",
      "26192\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\t0.03s\t = Training   runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Fitting model: KNeighborsDist_BAG_L1 ...\n",
      "Specified total num_gpus: 1, but only 0 are available. Will use 0 instead\n",
      "\t-34.9839\t = Validation score   (-mean_absolute_error)\n",
      "\t0.04s\t = Training   runtime\n",
      "\t0.05s\t = Validation runtime\n",
      "Fitting model: LightGBMXT_BAG_L1 ...\n",
      "Specified total num_gpus: 1, but only 0 are available. Will use 0 instead\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t-21.6088\t = Validation score   (-mean_absolute_error)\n",
      "\t25.59s\t = Training   runtime\n",
      "\t62.91s\t = Validation runtime\n",
      "Fitting model: LightGBM_BAG_L1 ...\n",
      "Specified total num_gpus: 1, but only 0 are available. Will use 0 instead\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t-12.8288\t = Validation score   (-mean_absolute_error)\n",
      "\t23.79s\t = Training   runtime\n",
      "\t58.62s\t = Validation runtime\n",
      "Fitting model: RandomForestMSE_BAG_L1 ...\n",
      "Specified total num_gpus: 1, but only 0 are available. Will use 0 instead\n",
      "\t-14.0034\t = Validation score   (-mean_absolute_error)\n",
      "\t2.05s\t = Training   runtime\n",
      "\t0.53s\t = Validation runtime\n",
      "Fitting model: CatBoost_BAG_L1 ...\n",
      "Specified total num_gpus: 1, but only 0 are available. Will use 0 instead\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t-11.4947\t = Validation score   (-mean_absolute_error)\n",
      "\t249.13s\t = Training   runtime\n",
      "\t0.12s\t = Validation runtime\n",
      "Fitting model: ExtraTreesMSE_BAG_L1 ...\n",
      "Specified total num_gpus: 1, but only 0 are available. Will use 0 instead\n",
      "\t-13.6891\t = Validation score   (-mean_absolute_error)\n",
      "\t0.87s\t = Training   runtime\n",
      "\t0.55s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_BAG_L1 ...\n",
      "Specified total num_gpus: 1, but only 0 are available. Will use 0 instead\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t-51.0767\t = Validation score   (-mean_absolute_error)\n",
      "\t27.86s\t = Training   runtime\n",
      "\t0.27s\t = Validation runtime\n",
      "Fitting model: XGBoost_BAG_L1 ...\n",
      "Specified total num_gpus: 1, but only 0 are available. Will use 0 instead\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\tWarning: Exception caused XGBoost_BAG_L1 to fail during training... Skipping this model.\n",
      "\t\t\u001b[36mray::_ray_fit()\u001b[39m (pid=28856, ip=127.0.0.1)\n",
      "  File \"python\\ray\\_raylet.pyx\", line 857, in ray._raylet.execute_task\n",
      "  File \"python\\ray\\_raylet.pyx\", line 861, in ray._raylet.execute_task\n",
      "  File \"c:\\Users\\ineeji\\anaconda3\\envs\\v1\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 402, in _ray_fit\n",
      "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, **resources, **kwargs_fold)\n",
      "  File \"c:\\Users\\ineeji\\anaconda3\\envs\\v1\\lib\\site-packages\\autogluon\\core\\models\\abstract\\abstract_model.py\", line 829, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "  File \"c:\\Users\\ineeji\\anaconda3\\envs\\v1\\lib\\site-packages\\autogluon\\tabular\\models\\xgboost\\xgboost_model.py\", line 143, in _fit\n",
      "    self.params_trained[\"n_estimators\"] = bst.best_ntree_limit\n",
      "AttributeError: 'Booster' object has no attribute 'best_ntree_limit'\n",
      "Detailed Traceback:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\ineeji\\anaconda3\\envs\\v1\\lib\\site-packages\\autogluon\\core\\trainer\\abstract_trainer.py\", line 1733, in _train_and_save\n",
      "    model = self._train_single(X, y, model, X_val, y_val, total_resources=total_resources, **model_fit_kwargs)\n",
      "  File \"c:\\Users\\ineeji\\anaconda3\\envs\\v1\\lib\\site-packages\\autogluon\\core\\trainer\\abstract_trainer.py\", line 1684, in _train_single\n",
      "    model = model.fit(X=X, y=y, X_val=X_val, y_val=y_val, total_resources=total_resources, **model_fit_kwargs)\n",
      "  File \"c:\\Users\\ineeji\\anaconda3\\envs\\v1\\lib\\site-packages\\autogluon\\core\\models\\abstract\\abstract_model.py\", line 829, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "  File \"c:\\Users\\ineeji\\anaconda3\\envs\\v1\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\stacker_ensemble_model.py\", line 169, in _fit\n",
      "    return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
      "  File \"c:\\Users\\ineeji\\anaconda3\\envs\\v1\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\bagged_ensemble_model.py\", line 266, in _fit\n",
      "    self._fit_folds(\n",
      "  File \"c:\\Users\\ineeji\\anaconda3\\envs\\v1\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\bagged_ensemble_model.py\", line 592, in _fit_folds\n",
      "    fold_fitting_strategy.after_all_folds_scheduled()\n",
      "  File \"c:\\Users\\ineeji\\anaconda3\\envs\\v1\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 581, in after_all_folds_scheduled\n",
      "    raise processed_exception\n",
      "  File \"c:\\Users\\ineeji\\anaconda3\\envs\\v1\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 541, in after_all_folds_scheduled\n",
      "    fold_model, pred_proba, time_start_fit, time_end_fit, predict_time, predict_1_time = self.ray.get(finished)\n",
      "  File \"c:\\Users\\ineeji\\anaconda3\\envs\\v1\\lib\\site-packages\\ray\\_private\\client_mode_hook.py\", line 105, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"c:\\Users\\ineeji\\anaconda3\\envs\\v1\\lib\\site-packages\\ray\\_private\\worker.py\", line 2380, in get\n",
      "    raise value.as_instanceof_cause()\n",
      "ray.exceptions.RayTaskError(AttributeError): \u001b[36mray::_ray_fit()\u001b[39m (pid=28856, ip=127.0.0.1)\n",
      "  File \"python\\ray\\_raylet.pyx\", line 857, in ray._raylet.execute_task\n",
      "  File \"python\\ray\\_raylet.pyx\", line 861, in ray._raylet.execute_task\n",
      "  File \"c:\\Users\\ineeji\\anaconda3\\envs\\v1\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 402, in _ray_fit\n",
      "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, **resources, **kwargs_fold)\n",
      "  File \"c:\\Users\\ineeji\\anaconda3\\envs\\v1\\lib\\site-packages\\autogluon\\core\\models\\abstract\\abstract_model.py\", line 829, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "  File \"c:\\Users\\ineeji\\anaconda3\\envs\\v1\\lib\\site-packages\\autogluon\\tabular\\models\\xgboost\\xgboost_model.py\", line 143, in _fit\n",
      "    self.params_trained[\"n_estimators\"] = bst.best_ntree_limit\n",
      "AttributeError: 'Booster' object has no attribute 'best_ntree_limit'\n",
      "Fitting model: NeuralNetTorch_BAG_L1 ...\n",
      "Specified total num_gpus: 1, but only 0 are available. Will use 0 instead\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "2023-10-17 05:21:06,717\tERROR worker.py:399 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2023-10-17 05:21:06,724\tERROR worker.py:399 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2023-10-17 05:21:06,725\tERROR worker.py:399 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2023-10-17 05:21:06,737\tERROR worker.py:399 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2023-10-17 05:21:06,741\tERROR worker.py:399 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2023-10-17 05:21:06,741\tERROR worker.py:399 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2023-10-17 05:21:06,746\tERROR worker.py:399 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "\t-24.218\t = Validation score   (-mean_absolute_error)\n",
      "\t199.78s\t = Training   runtime\n",
      "\t0.08s\t = Validation runtime\n",
      "Fitting model: LightGBMLarge_BAG_L1 ...\n",
      "Specified total num_gpus: 1, but only 0 are available. Will use 0 instead\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t-13.888\t = Validation score   (-mean_absolute_error)\n",
      "\t39.19s\t = Training   runtime\n",
      "\t33.07s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ...\n",
      "\t-11.4484\t = Validation score   (-mean_absolute_error)\n",
      "\t0.36s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting 9 L2 models ...\n",
      "Fitting model: LightGBMXT_BAG_L2 ...\n",
      "Specified total num_gpus: 1, but only 0 are available. Will use 0 instead\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t-11.73\t = Validation score   (-mean_absolute_error)\n",
      "\t31.4s\t = Training   runtime\n",
      "\t61.14s\t = Validation runtime\n",
      "Fitting model: LightGBM_BAG_L2 ...\n",
      "Specified total num_gpus: 1, but only 0 are available. Will use 0 instead\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t-11.481\t = Validation score   (-mean_absolute_error)\n",
      "\t2.79s\t = Training   runtime\n",
      "\t0.11s\t = Validation runtime\n",
      "Fitting model: RandomForestMSE_BAG_L2 ...\n",
      "Specified total num_gpus: 1, but only 0 are available. Will use 0 instead\n",
      "\t-8.8827\t = Validation score   (-mean_absolute_error)\n",
      "\t15.71s\t = Training   runtime\n",
      "\t0.77s\t = Validation runtime\n",
      "Fitting model: CatBoost_BAG_L2 ...\n",
      "Specified total num_gpus: 1, but only 0 are available. Will use 0 instead\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t-9.9211\t = Validation score   (-mean_absolute_error)\n",
      "\t307.4s\t = Training   runtime\n",
      "\t0.11s\t = Validation runtime\n",
      "Fitting model: ExtraTreesMSE_BAG_L2 ...\n",
      "Specified total num_gpus: 1, but only 0 are available. Will use 0 instead\n",
      "\t-8.7177\t = Validation score   (-mean_absolute_error)\n",
      "\t3.16s\t = Training   runtime\n",
      "\t0.75s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_BAG_L2 ...\n",
      "Specified total num_gpus: 1, but only 0 are available. Will use 0 instead\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t-12.0929\t = Validation score   (-mean_absolute_error)\n",
      "\t28.53s\t = Training   runtime\n",
      "\t0.31s\t = Validation runtime\n",
      "Fitting model: XGBoost_BAG_L2 ...\n",
      "Specified total num_gpus: 1, but only 0 are available. Will use 0 instead\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\tWarning: Exception caused XGBoost_BAG_L2 to fail during training... Skipping this model.\n",
      "\t\t\u001b[36mray::_ray_fit()\u001b[39m (pid=37168, ip=127.0.0.1)\n",
      "  File \"python\\ray\\_raylet.pyx\", line 857, in ray._raylet.execute_task\n",
      "  File \"python\\ray\\_raylet.pyx\", line 861, in ray._raylet.execute_task\n",
      "  File \"c:\\Users\\ineeji\\anaconda3\\envs\\v1\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 402, in _ray_fit\n",
      "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, **resources, **kwargs_fold)\n",
      "  File \"c:\\Users\\ineeji\\anaconda3\\envs\\v1\\lib\\site-packages\\autogluon\\core\\models\\abstract\\abstract_model.py\", line 829, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "  File \"c:\\Users\\ineeji\\anaconda3\\envs\\v1\\lib\\site-packages\\autogluon\\tabular\\models\\xgboost\\xgboost_model.py\", line 143, in _fit\n",
      "    self.params_trained[\"n_estimators\"] = bst.best_ntree_limit\n",
      "AttributeError: 'Booster' object has no attribute 'best_ntree_limit'\n",
      "Detailed Traceback:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\ineeji\\anaconda3\\envs\\v1\\lib\\site-packages\\autogluon\\core\\trainer\\abstract_trainer.py\", line 1733, in _train_and_save\n",
      "    model = self._train_single(X, y, model, X_val, y_val, total_resources=total_resources, **model_fit_kwargs)\n",
      "  File \"c:\\Users\\ineeji\\anaconda3\\envs\\v1\\lib\\site-packages\\autogluon\\core\\trainer\\abstract_trainer.py\", line 1684, in _train_single\n",
      "    model = model.fit(X=X, y=y, X_val=X_val, y_val=y_val, total_resources=total_resources, **model_fit_kwargs)\n",
      "  File \"c:\\Users\\ineeji\\anaconda3\\envs\\v1\\lib\\site-packages\\autogluon\\core\\models\\abstract\\abstract_model.py\", line 829, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "  File \"c:\\Users\\ineeji\\anaconda3\\envs\\v1\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\stacker_ensemble_model.py\", line 169, in _fit\n",
      "    return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
      "  File \"c:\\Users\\ineeji\\anaconda3\\envs\\v1\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\bagged_ensemble_model.py\", line 266, in _fit\n",
      "    self._fit_folds(\n",
      "  File \"c:\\Users\\ineeji\\anaconda3\\envs\\v1\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\bagged_ensemble_model.py\", line 592, in _fit_folds\n",
      "    fold_fitting_strategy.after_all_folds_scheduled()\n",
      "  File \"c:\\Users\\ineeji\\anaconda3\\envs\\v1\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 581, in after_all_folds_scheduled\n",
      "    raise processed_exception\n",
      "  File \"c:\\Users\\ineeji\\anaconda3\\envs\\v1\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 541, in after_all_folds_scheduled\n",
      "    fold_model, pred_proba, time_start_fit, time_end_fit, predict_time, predict_1_time = self.ray.get(finished)\n",
      "  File \"c:\\Users\\ineeji\\anaconda3\\envs\\v1\\lib\\site-packages\\ray\\_private\\client_mode_hook.py\", line 105, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"c:\\Users\\ineeji\\anaconda3\\envs\\v1\\lib\\site-packages\\ray\\_private\\worker.py\", line 2380, in get\n",
      "    raise value.as_instanceof_cause()\n",
      "ray.exceptions.RayTaskError(AttributeError): \u001b[36mray::_ray_fit()\u001b[39m (pid=37168, ip=127.0.0.1)\n",
      "  File \"python\\ray\\_raylet.pyx\", line 857, in ray._raylet.execute_task\n",
      "  File \"python\\ray\\_raylet.pyx\", line 861, in ray._raylet.execute_task\n",
      "  File \"c:\\Users\\ineeji\\anaconda3\\envs\\v1\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 402, in _ray_fit\n",
      "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, **resources, **kwargs_fold)\n",
      "  File \"c:\\Users\\ineeji\\anaconda3\\envs\\v1\\lib\\site-packages\\autogluon\\core\\models\\abstract\\abstract_model.py\", line 829, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "  File \"c:\\Users\\ineeji\\anaconda3\\envs\\v1\\lib\\site-packages\\autogluon\\tabular\\models\\xgboost\\xgboost_model.py\", line 143, in _fit\n",
      "    self.params_trained[\"n_estimators\"] = bst.best_ntree_limit\n",
      "AttributeError: 'Booster' object has no attribute 'best_ntree_limit'\n",
      "Fitting model: NeuralNetTorch_BAG_L2 ...\n",
      "Specified total num_gpus: 1, but only 0 are available. Will use 0 instead\n",
      "2023-10-17 05:32:15,351\tERROR worker.py:399 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2023-10-17 05:32:15,353\tERROR worker.py:399 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2023-10-17 05:32:15,358\tERROR worker.py:399 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2023-10-17 05:32:15,360\tERROR worker.py:399 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2023-10-17 05:32:15,364\tERROR worker.py:399 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2023-10-17 05:32:15,367\tERROR worker.py:399 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2023-10-17 05:32:15,367\tERROR worker.py:399 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t-12.398\t = Validation score   (-mean_absolute_error)\n",
      "\t54.56s\t = Training   runtime\n",
      "\t0.15s\t = Validation runtime\n",
      "Fitting model: LightGBMLarge_BAG_L2 ...\n",
      "Specified total num_gpus: 1, but only 0 are available. Will use 0 instead\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t-9.5504\t = Validation score   (-mean_absolute_error)\n",
      "\t70.08s\t = Training   runtime\n",
      "\t55.31s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L3 ...\n",
      "\t-8.6692\t = Validation score   (-mean_absolute_error)\n",
      "\t0.33s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 1184.79s ... Best model: \"WeightedEnsemble_L3\"\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels\\ag-20231016_201454\\\")\n",
      "No path specified. Models will be saved in: \"AutogluonModels\\ag-20231016_203642\\\"\n",
      "Presets specified: ['best_quality']\n",
      "Stack configuration (auto_stack=True): num_stack_levels=1, num_bag_folds=8, num_bag_sets=1\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to \"AutogluonModels\\ag-20231016_203642\\\"\n",
      "AutoGluon Version:  0.8.2\n",
      "Python Version:     3.8.16\n",
      "Operating System:   Windows\n",
      "Platform Machine:   AMD64\n",
      "Platform Version:   10.0.22621\n",
      "Disk Space Avail:   131.92 GB / 511.09 GB (25.8%)\n",
      "Train Data Rows:    23785\n",
      "Train Data Columns: 7\n",
      "Label Column: CI_HOUR\n",
      "Preprocessing data ...\n",
      "AutoGluon infers your prediction problem is: 'regression' (because dtype of label-column == float and many unique label-values observed).\n",
      "\tLabel info (max, min, mean, stddev): (2140.12, 0.023611111, 94.72007, 196.2466)\n",
      "\tIf 'regression' is not the correct problem_type, please manually specify the problem_type parameter during predictor init (You may specify problem_type as one of: ['binary', 'multiclass', 'regression'])\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    19200.88 MB\n",
      "\tTrain Data (Original)  Memory Usage: 1.14 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 5 | ['WTI', 'DUBAI', 'BRENT', 'OIL', 'BDI_ADJ']\n",
      "\t\t('int', [])   : 2 | ['month', 'day']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 5 | ['WTI', 'DUBAI', 'BRENT', 'OIL', 'BDI_ADJ']\n",
      "\t\t('int', [])   : 2 | ['month', 'day']\n",
      "\t0.0s = Fit runtime\n",
      "\t7 features in original data used to generate 7 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 1.14 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.07s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'mean_absolute_error'\n",
      "\tThis metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'NN_TORCH': {},\n",
      "\t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, 'GBMLarge'],\n",
      "\t'CAT': {},\n",
      "\t'XGB': {},\n",
      "\t'FASTAI': {},\n",
      "\t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'KNN': [{'weights': 'uniform', 'ag_args': {'name_suffix': 'Unif'}}, {'weights': 'distance', 'ag_args': {'name_suffix': 'Dist'}}],\n",
      "}\n",
      "AutoGluon will fit 2 stack levels (L1 to L2) ...\n",
      "Fitting 11 L1 models ...\n",
      "Fitting model: KNeighborsUnif_BAG_L1 ...\n",
      "Specified total num_gpus: 1, but only 0 are available. Will use 0 instead\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2016\n",
      "2016\n",
      "2016\n",
      "2016\n",
      "2016\n",
      "20486\n",
      "20486\n",
      "20486\n",
      "20486\n",
      "20486\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\t-34.6147\t = Validation score   (-mean_absolute_error)\n",
      "\t0.02s\t = Training   runtime\n",
      "\t0.07s\t = Validation runtime\n",
      "Fitting model: KNeighborsDist_BAG_L1 ...\n",
      "Specified total num_gpus: 1, but only 0 are available. Will use 0 instead\n",
      "\t-30.2534\t = Validation score   (-mean_absolute_error)\n",
      "\t0.02s\t = Training   runtime\n",
      "\t0.05s\t = Validation runtime\n",
      "Fitting model: LightGBMXT_BAG_L1 ...\n",
      "Specified total num_gpus: 1, but only 0 are available. Will use 0 instead\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t-19.0805\t = Validation score   (-mean_absolute_error)\n",
      "\t26.65s\t = Training   runtime\n",
      "\t78.67s\t = Validation runtime\n",
      "Fitting model: LightGBM_BAG_L1 ...\n",
      "Specified total num_gpus: 1, but only 0 are available. Will use 0 instead\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t-12.0091\t = Validation score   (-mean_absolute_error)\n",
      "\t25.1s\t = Training   runtime\n",
      "\t70.45s\t = Validation runtime\n",
      "Fitting model: RandomForestMSE_BAG_L1 ...\n",
      "Specified total num_gpus: 1, but only 0 are available. Will use 0 instead\n",
      "\t-12.5257\t = Validation score   (-mean_absolute_error)\n",
      "\t2.35s\t = Training   runtime\n",
      "\t0.6s\t = Validation runtime\n",
      "Fitting model: CatBoost_BAG_L1 ...\n",
      "Specified total num_gpus: 1, but only 0 are available. Will use 0 instead\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t-10.8632\t = Validation score   (-mean_absolute_error)\n",
      "\t259.22s\t = Training   runtime\n",
      "\t0.1s\t = Validation runtime\n",
      "Fitting model: ExtraTreesMSE_BAG_L1 ...\n",
      "Specified total num_gpus: 1, but only 0 are available. Will use 0 instead\n",
      "\t-12.2812\t = Validation score   (-mean_absolute_error)\n",
      "\t0.85s\t = Training   runtime\n",
      "\t0.6s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_BAG_L1 ...\n",
      "Specified total num_gpus: 1, but only 0 are available. Will use 0 instead\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t-49.5578\t = Validation score   (-mean_absolute_error)\n",
      "\t31.57s\t = Training   runtime\n",
      "\t0.4s\t = Validation runtime\n",
      "Fitting model: XGBoost_BAG_L1 ...\n",
      "Specified total num_gpus: 1, but only 0 are available. Will use 0 instead\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\tWarning: Exception caused XGBoost_BAG_L1 to fail during training... Skipping this model.\n",
      "\t\t\u001b[36mray::_ray_fit()\u001b[39m (pid=35868, ip=127.0.0.1)\n",
      "  File \"python\\ray\\_raylet.pyx\", line 857, in ray._raylet.execute_task\n",
      "  File \"python\\ray\\_raylet.pyx\", line 861, in ray._raylet.execute_task\n",
      "  File \"c:\\Users\\ineeji\\anaconda3\\envs\\v1\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 402, in _ray_fit\n",
      "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, **resources, **kwargs_fold)\n",
      "  File \"c:\\Users\\ineeji\\anaconda3\\envs\\v1\\lib\\site-packages\\autogluon\\core\\models\\abstract\\abstract_model.py\", line 829, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "  File \"c:\\Users\\ineeji\\anaconda3\\envs\\v1\\lib\\site-packages\\autogluon\\tabular\\models\\xgboost\\xgboost_model.py\", line 143, in _fit\n",
      "    self.params_trained[\"n_estimators\"] = bst.best_ntree_limit\n",
      "AttributeError: 'Booster' object has no attribute 'best_ntree_limit'\n",
      "Detailed Traceback:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\ineeji\\anaconda3\\envs\\v1\\lib\\site-packages\\autogluon\\core\\trainer\\abstract_trainer.py\", line 1733, in _train_and_save\n",
      "    model = self._train_single(X, y, model, X_val, y_val, total_resources=total_resources, **model_fit_kwargs)\n",
      "  File \"c:\\Users\\ineeji\\anaconda3\\envs\\v1\\lib\\site-packages\\autogluon\\core\\trainer\\abstract_trainer.py\", line 1684, in _train_single\n",
      "    model = model.fit(X=X, y=y, X_val=X_val, y_val=y_val, total_resources=total_resources, **model_fit_kwargs)\n",
      "  File \"c:\\Users\\ineeji\\anaconda3\\envs\\v1\\lib\\site-packages\\autogluon\\core\\models\\abstract\\abstract_model.py\", line 829, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "  File \"c:\\Users\\ineeji\\anaconda3\\envs\\v1\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\stacker_ensemble_model.py\", line 169, in _fit\n",
      "    return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
      "  File \"c:\\Users\\ineeji\\anaconda3\\envs\\v1\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\bagged_ensemble_model.py\", line 266, in _fit\n",
      "    self._fit_folds(\n",
      "  File \"c:\\Users\\ineeji\\anaconda3\\envs\\v1\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\bagged_ensemble_model.py\", line 592, in _fit_folds\n",
      "    fold_fitting_strategy.after_all_folds_scheduled()\n",
      "  File \"c:\\Users\\ineeji\\anaconda3\\envs\\v1\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 581, in after_all_folds_scheduled\n",
      "    raise processed_exception\n",
      "  File \"c:\\Users\\ineeji\\anaconda3\\envs\\v1\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 541, in after_all_folds_scheduled\n",
      "    fold_model, pred_proba, time_start_fit, time_end_fit, predict_time, predict_1_time = self.ray.get(finished)\n",
      "  File \"c:\\Users\\ineeji\\anaconda3\\envs\\v1\\lib\\site-packages\\ray\\_private\\client_mode_hook.py\", line 105, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"c:\\Users\\ineeji\\anaconda3\\envs\\v1\\lib\\site-packages\\ray\\_private\\worker.py\", line 2380, in get\n",
      "    raise value.as_instanceof_cause()\n",
      "ray.exceptions.RayTaskError(AttributeError): \u001b[36mray::_ray_fit()\u001b[39m (pid=35868, ip=127.0.0.1)\n",
      "  File \"python\\ray\\_raylet.pyx\", line 857, in ray._raylet.execute_task\n",
      "  File \"python\\ray\\_raylet.pyx\", line 861, in ray._raylet.execute_task\n",
      "  File \"c:\\Users\\ineeji\\anaconda3\\envs\\v1\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 402, in _ray_fit\n",
      "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, **resources, **kwargs_fold)\n",
      "  File \"c:\\Users\\ineeji\\anaconda3\\envs\\v1\\lib\\site-packages\\autogluon\\core\\models\\abstract\\abstract_model.py\", line 829, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "  File \"c:\\Users\\ineeji\\anaconda3\\envs\\v1\\lib\\site-packages\\autogluon\\tabular\\models\\xgboost\\xgboost_model.py\", line 143, in _fit\n",
      "    self.params_trained[\"n_estimators\"] = bst.best_ntree_limit\n",
      "AttributeError: 'Booster' object has no attribute 'best_ntree_limit'\n",
      "Fitting model: NeuralNetTorch_BAG_L1 ...\n",
      "Specified total num_gpus: 1, but only 0 are available. Will use 0 instead\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "2023-10-17 05:43:18,407\tERROR worker.py:399 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2023-10-17 05:43:18,408\tERROR worker.py:399 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2023-10-17 05:43:18,414\tERROR worker.py:399 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2023-10-17 05:43:18,418\tERROR worker.py:399 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2023-10-17 05:43:18,425\tERROR worker.py:399 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2023-10-17 05:43:18,430\tERROR worker.py:399 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2023-10-17 05:43:18,432\tERROR worker.py:399 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "\t-21.2185\t = Validation score   (-mean_absolute_error)\n",
      "\t235.6s\t = Training   runtime\n",
      "\t0.07s\t = Validation runtime\n",
      "Fitting model: LightGBMLarge_BAG_L1 ...\n",
      "Specified total num_gpus: 1, but only 0 are available. Will use 0 instead\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t-12.586\t = Validation score   (-mean_absolute_error)\n",
      "\t36.66s\t = Training   runtime\n",
      "\t43.99s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ...\n",
      "\t-10.6913\t = Validation score   (-mean_absolute_error)\n",
      "\t0.38s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting 9 L2 models ...\n",
      "Fitting model: LightGBMXT_BAG_L2 ...\n",
      "Specified total num_gpus: 1, but only 0 are available. Will use 0 instead\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t-11.1769\t = Validation score   (-mean_absolute_error)\n",
      "\t28.46s\t = Training   runtime\n",
      "\t47.84s\t = Validation runtime\n",
      "Fitting model: LightGBM_BAG_L2 ...\n",
      "Specified total num_gpus: 1, but only 0 are available. Will use 0 instead\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t-10.7798\t = Validation score   (-mean_absolute_error)\n",
      "\t2.72s\t = Training   runtime\n",
      "\t0.07s\t = Validation runtime\n",
      "Fitting model: RandomForestMSE_BAG_L2 ...\n",
      "Specified total num_gpus: 1, but only 0 are available. Will use 0 instead\n",
      "\t-8.1055\t = Validation score   (-mean_absolute_error)\n",
      "\t18.17s\t = Training   runtime\n",
      "\t0.85s\t = Validation runtime\n",
      "Fitting model: CatBoost_BAG_L2 ...\n",
      "Specified total num_gpus: 1, but only 0 are available. Will use 0 instead\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t-9.3802\t = Validation score   (-mean_absolute_error)\n",
      "\t300.56s\t = Training   runtime\n",
      "\t0.05s\t = Validation runtime\n",
      "Fitting model: ExtraTreesMSE_BAG_L2 ...\n",
      "Specified total num_gpus: 1, but only 0 are available. Will use 0 instead\n",
      "\t-7.9287\t = Validation score   (-mean_absolute_error)\n",
      "\t3.65s\t = Training   runtime\n",
      "\t0.83s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_BAG_L2 ...\n",
      "Specified total num_gpus: 1, but only 0 are available. Will use 0 instead\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t-11.2007\t = Validation score   (-mean_absolute_error)\n",
      "\t31.87s\t = Training   runtime\n",
      "\t0.35s\t = Validation runtime\n",
      "Fitting model: XGBoost_BAG_L2 ...\n",
      "Specified total num_gpus: 1, but only 0 are available. Will use 0 instead\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\tWarning: Exception caused XGBoost_BAG_L2 to fail during training... Skipping this model.\n",
      "\t\t\u001b[36mray::_ray_fit()\u001b[39m (pid=28200, ip=127.0.0.1)\n",
      "  File \"python\\ray\\_raylet.pyx\", line 857, in ray._raylet.execute_task\n",
      "  File \"python\\ray\\_raylet.pyx\", line 861, in ray._raylet.execute_task\n",
      "  File \"c:\\Users\\ineeji\\anaconda3\\envs\\v1\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 402, in _ray_fit\n",
      "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, **resources, **kwargs_fold)\n",
      "  File \"c:\\Users\\ineeji\\anaconda3\\envs\\v1\\lib\\site-packages\\autogluon\\core\\models\\abstract\\abstract_model.py\", line 829, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "  File \"c:\\Users\\ineeji\\anaconda3\\envs\\v1\\lib\\site-packages\\autogluon\\tabular\\models\\xgboost\\xgboost_model.py\", line 143, in _fit\n",
      "    self.params_trained[\"n_estimators\"] = bst.best_ntree_limit\n",
      "AttributeError: 'Booster' object has no attribute 'best_ntree_limit'\n",
      "Detailed Traceback:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\ineeji\\anaconda3\\envs\\v1\\lib\\site-packages\\autogluon\\core\\trainer\\abstract_trainer.py\", line 1733, in _train_and_save\n",
      "    model = self._train_single(X, y, model, X_val, y_val, total_resources=total_resources, **model_fit_kwargs)\n",
      "  File \"c:\\Users\\ineeji\\anaconda3\\envs\\v1\\lib\\site-packages\\autogluon\\core\\trainer\\abstract_trainer.py\", line 1684, in _train_single\n",
      "    model = model.fit(X=X, y=y, X_val=X_val, y_val=y_val, total_resources=total_resources, **model_fit_kwargs)\n",
      "  File \"c:\\Users\\ineeji\\anaconda3\\envs\\v1\\lib\\site-packages\\autogluon\\core\\models\\abstract\\abstract_model.py\", line 829, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "  File \"c:\\Users\\ineeji\\anaconda3\\envs\\v1\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\stacker_ensemble_model.py\", line 169, in _fit\n",
      "    return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
      "  File \"c:\\Users\\ineeji\\anaconda3\\envs\\v1\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\bagged_ensemble_model.py\", line 266, in _fit\n",
      "    self._fit_folds(\n",
      "  File \"c:\\Users\\ineeji\\anaconda3\\envs\\v1\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\bagged_ensemble_model.py\", line 592, in _fit_folds\n",
      "    fold_fitting_strategy.after_all_folds_scheduled()\n",
      "  File \"c:\\Users\\ineeji\\anaconda3\\envs\\v1\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 581, in after_all_folds_scheduled\n",
      "    raise processed_exception\n",
      "  File \"c:\\Users\\ineeji\\anaconda3\\envs\\v1\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 541, in after_all_folds_scheduled\n",
      "    fold_model, pred_proba, time_start_fit, time_end_fit, predict_time, predict_1_time = self.ray.get(finished)\n",
      "  File \"c:\\Users\\ineeji\\anaconda3\\envs\\v1\\lib\\site-packages\\ray\\_private\\client_mode_hook.py\", line 105, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"c:\\Users\\ineeji\\anaconda3\\envs\\v1\\lib\\site-packages\\ray\\_private\\worker.py\", line 2380, in get\n",
      "    raise value.as_instanceof_cause()\n",
      "ray.exceptions.RayTaskError(AttributeError): \u001b[36mray::_ray_fit()\u001b[39m (pid=28200, ip=127.0.0.1)\n",
      "  File \"python\\ray\\_raylet.pyx\", line 857, in ray._raylet.execute_task\n",
      "  File \"python\\ray\\_raylet.pyx\", line 861, in ray._raylet.execute_task\n",
      "  File \"c:\\Users\\ineeji\\anaconda3\\envs\\v1\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 402, in _ray_fit\n",
      "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, **resources, **kwargs_fold)\n",
      "  File \"c:\\Users\\ineeji\\anaconda3\\envs\\v1\\lib\\site-packages\\autogluon\\core\\models\\abstract\\abstract_model.py\", line 829, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "  File \"c:\\Users\\ineeji\\anaconda3\\envs\\v1\\lib\\site-packages\\autogluon\\tabular\\models\\xgboost\\xgboost_model.py\", line 143, in _fit\n",
      "    self.params_trained[\"n_estimators\"] = bst.best_ntree_limit\n",
      "AttributeError: 'Booster' object has no attribute 'best_ntree_limit'\n",
      "Fitting model: NeuralNetTorch_BAG_L2 ...\n",
      "Specified total num_gpus: 1, but only 0 are available. Will use 0 instead\n",
      "2023-10-17 05:54:59,029\tERROR worker.py:399 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2023-10-17 05:54:59,031\tERROR worker.py:399 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2023-10-17 05:54:59,035\tERROR worker.py:399 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2023-10-17 05:54:59,037\tERROR worker.py:399 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2023-10-17 05:54:59,040\tERROR worker.py:399 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2023-10-17 05:54:59,042\tERROR worker.py:399 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2023-10-17 05:54:59,045\tERROR worker.py:399 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t-11.6222\t = Validation score   (-mean_absolute_error)\n",
      "\t68.38s\t = Training   runtime\n",
      "\t0.17s\t = Validation runtime\n",
      "Fitting model: LightGBMLarge_BAG_L2 ...\n",
      "Specified total num_gpus: 1, but only 0 are available. Will use 0 instead\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t-8.9462\t = Validation score   (-mean_absolute_error)\n",
      "\t55.38s\t = Training   runtime\n",
      "\t38.78s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L3 ...\n",
      "\t-7.9044\t = Validation score   (-mean_absolute_error)\n",
      "\t0.33s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 1232.78s ... Best model: \"WeightedEnsemble_L3\"\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels\\ag-20231016_203642\\\")\n",
      "No path specified. Models will be saved in: \"AutogluonModels\\ag-20231016_205914\\\"\n",
      "Presets specified: ['best_quality']\n",
      "Stack configuration (auto_stack=True): num_stack_levels=1, num_bag_folds=8, num_bag_sets=1\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to \"AutogluonModels\\ag-20231016_205914\\\"\n",
      "AutoGluon Version:  0.8.2\n",
      "Python Version:     3.8.16\n",
      "Operating System:   Windows\n",
      "Platform Machine:   AMD64\n",
      "Platform Version:   10.0.22621\n",
      "Disk Space Avail:   128.78 GB / 511.09 GB (25.2%)\n",
      "Train Data Rows:    36385\n",
      "Train Data Columns: 7\n",
      "Label Column: CI_HOUR\n",
      "Preprocessing data ...\n",
      "AutoGluon infers your prediction problem is: 'regression' (because dtype of label-column == float and many unique label-values observed).\n",
      "\tLabel info (max, min, mean, stddev): (2157.861389, 0.100833333, 105.9172, 209.36872)\n",
      "\tIf 'regression' is not the correct problem_type, please manually specify the problem_type parameter during predictor init (You may specify problem_type as one of: ['binary', 'multiclass', 'regression'])\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    19117.47 MB\n",
      "\tTrain Data (Original)  Memory Usage: 1.75 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 5 | ['WTI', 'DUBAI', 'BRENT', 'OIL', 'BDI_ADJ']\n",
      "\t\t('int', [])   : 2 | ['month', 'day']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 5 | ['WTI', 'DUBAI', 'BRENT', 'OIL', 'BDI_ADJ']\n",
      "\t\t('int', [])   : 2 | ['month', 'day']\n",
      "\t0.1s = Fit runtime\n",
      "\t7 features in original data used to generate 7 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 1.75 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.08s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'mean_absolute_error'\n",
      "\tThis metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'NN_TORCH': {},\n",
      "\t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, 'GBMLarge'],\n",
      "\t'CAT': {},\n",
      "\t'XGB': {},\n",
      "\t'FASTAI': {},\n",
      "\t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'KNN': [{'weights': 'uniform', 'ag_args': {'name_suffix': 'Unif'}}, {'weights': 'distance', 'ag_args': {'name_suffix': 'Dist'}}],\n",
      "}\n",
      "AutoGluon will fit 2 stack levels (L1 to L2) ...\n",
      "Fitting 11 L1 models ...\n",
      "Fitting model: KNeighborsUnif_BAG_L1 ...\n",
      "Specified total num_gpus: 1, but only 0 are available. Will use 0 instead\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2017\n",
      "2017\n",
      "2017\n",
      "2017\n",
      "2017\n",
      "23785\n",
      "23785\n",
      "23785\n",
      "23785\n",
      "23785\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\t-34.506\t = Validation score   (-mean_absolute_error)\n",
      "\t0.05s\t = Training   runtime\n",
      "\t0.07s\t = Validation runtime\n",
      "Fitting model: KNeighborsDist_BAG_L1 ...\n",
      "Specified total num_gpus: 1, but only 0 are available. Will use 0 instead\n",
      "\t-29.7109\t = Validation score   (-mean_absolute_error)\n",
      "\t0.04s\t = Training   runtime\n",
      "\t0.1s\t = Validation runtime\n",
      "Fitting model: LightGBMXT_BAG_L1 ...\n",
      "Specified total num_gpus: 1, but only 0 are available. Will use 0 instead\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t-17.2039\t = Validation score   (-mean_absolute_error)\n",
      "\t33.0s\t = Training   runtime\n",
      "\t120.26s\t = Validation runtime\n",
      "Fitting model: LightGBM_BAG_L1 ...\n",
      "Specified total num_gpus: 1, but only 0 are available. Will use 0 instead\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t-10.2372\t = Validation score   (-mean_absolute_error)\n",
      "\t28.83s\t = Training   runtime\n",
      "\t110.5s\t = Validation runtime\n",
      "Fitting model: RandomForestMSE_BAG_L1 ...\n",
      "Specified total num_gpus: 1, but only 0 are available. Will use 0 instead\n",
      "\t-10.9428\t = Validation score   (-mean_absolute_error)\n",
      "\t3.27s\t = Training   runtime\n",
      "\t1.05s\t = Validation runtime\n",
      "Fitting model: CatBoost_BAG_L1 ...\n",
      "Specified total num_gpus: 1, but only 0 are available. Will use 0 instead\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t-9.3657\t = Validation score   (-mean_absolute_error)\n",
      "\t279.79s\t = Training   runtime\n",
      "\t0.08s\t = Validation runtime\n",
      "Fitting model: ExtraTreesMSE_BAG_L1 ...\n",
      "Specified total num_gpus: 1, but only 0 are available. Will use 0 instead\n",
      "\t-10.8809\t = Validation score   (-mean_absolute_error)\n",
      "\t1.56s\t = Training   runtime\n",
      "\t0.92s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_BAG_L1 ...\n",
      "Specified total num_gpus: 1, but only 0 are available. Will use 0 instead\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t-43.7441\t = Validation score   (-mean_absolute_error)\n",
      "\t46.04s\t = Training   runtime\n",
      "\t0.49s\t = Validation runtime\n",
      "Fitting model: XGBoost_BAG_L1 ...\n",
      "Specified total num_gpus: 1, but only 0 are available. Will use 0 instead\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\tWarning: Exception caused XGBoost_BAG_L1 to fail during training... Skipping this model.\n",
      "\t\t\u001b[36mray::_ray_fit()\u001b[39m (pid=22648, ip=127.0.0.1)\n",
      "  File \"python\\ray\\_raylet.pyx\", line 857, in ray._raylet.execute_task\n",
      "  File \"python\\ray\\_raylet.pyx\", line 861, in ray._raylet.execute_task\n",
      "  File \"c:\\Users\\ineeji\\anaconda3\\envs\\v1\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 402, in _ray_fit\n",
      "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, **resources, **kwargs_fold)\n",
      "  File \"c:\\Users\\ineeji\\anaconda3\\envs\\v1\\lib\\site-packages\\autogluon\\core\\models\\abstract\\abstract_model.py\", line 829, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "  File \"c:\\Users\\ineeji\\anaconda3\\envs\\v1\\lib\\site-packages\\autogluon\\tabular\\models\\xgboost\\xgboost_model.py\", line 143, in _fit\n",
      "    self.params_trained[\"n_estimators\"] = bst.best_ntree_limit\n",
      "AttributeError: 'Booster' object has no attribute 'best_ntree_limit'\n",
      "Detailed Traceback:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\ineeji\\anaconda3\\envs\\v1\\lib\\site-packages\\autogluon\\core\\trainer\\abstract_trainer.py\", line 1733, in _train_and_save\n",
      "    model = self._train_single(X, y, model, X_val, y_val, total_resources=total_resources, **model_fit_kwargs)\n",
      "  File \"c:\\Users\\ineeji\\anaconda3\\envs\\v1\\lib\\site-packages\\autogluon\\core\\trainer\\abstract_trainer.py\", line 1684, in _train_single\n",
      "    model = model.fit(X=X, y=y, X_val=X_val, y_val=y_val, total_resources=total_resources, **model_fit_kwargs)\n",
      "  File \"c:\\Users\\ineeji\\anaconda3\\envs\\v1\\lib\\site-packages\\autogluon\\core\\models\\abstract\\abstract_model.py\", line 829, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "  File \"c:\\Users\\ineeji\\anaconda3\\envs\\v1\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\stacker_ensemble_model.py\", line 169, in _fit\n",
      "    return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
      "  File \"c:\\Users\\ineeji\\anaconda3\\envs\\v1\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\bagged_ensemble_model.py\", line 266, in _fit\n",
      "    self._fit_folds(\n",
      "  File \"c:\\Users\\ineeji\\anaconda3\\envs\\v1\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\bagged_ensemble_model.py\", line 592, in _fit_folds\n",
      "    fold_fitting_strategy.after_all_folds_scheduled()\n",
      "  File \"c:\\Users\\ineeji\\anaconda3\\envs\\v1\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 581, in after_all_folds_scheduled\n",
      "    raise processed_exception\n",
      "  File \"c:\\Users\\ineeji\\anaconda3\\envs\\v1\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 541, in after_all_folds_scheduled\n",
      "    fold_model, pred_proba, time_start_fit, time_end_fit, predict_time, predict_1_time = self.ray.get(finished)\n",
      "  File \"c:\\Users\\ineeji\\anaconda3\\envs\\v1\\lib\\site-packages\\ray\\_private\\client_mode_hook.py\", line 105, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"c:\\Users\\ineeji\\anaconda3\\envs\\v1\\lib\\site-packages\\ray\\_private\\worker.py\", line 2380, in get\n",
      "    raise value.as_instanceof_cause()\n",
      "ray.exceptions.RayTaskError(AttributeError): \u001b[36mray::_ray_fit()\u001b[39m (pid=22648, ip=127.0.0.1)\n",
      "  File \"python\\ray\\_raylet.pyx\", line 857, in ray._raylet.execute_task\n",
      "  File \"python\\ray\\_raylet.pyx\", line 861, in ray._raylet.execute_task\n",
      "  File \"c:\\Users\\ineeji\\anaconda3\\envs\\v1\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 402, in _ray_fit\n",
      "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, **resources, **kwargs_fold)\n",
      "  File \"c:\\Users\\ineeji\\anaconda3\\envs\\v1\\lib\\site-packages\\autogluon\\core\\models\\abstract\\abstract_model.py\", line 829, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "  File \"c:\\Users\\ineeji\\anaconda3\\envs\\v1\\lib\\site-packages\\autogluon\\tabular\\models\\xgboost\\xgboost_model.py\", line 143, in _fit\n",
      "    self.params_trained[\"n_estimators\"] = bst.best_ntree_limit\n",
      "AttributeError: 'Booster' object has no attribute 'best_ntree_limit'\n",
      "Fitting model: NeuralNetTorch_BAG_L1 ...\n",
      "Specified total num_gpus: 1, but only 0 are available. Will use 0 instead\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "2023-10-17 06:06:53,604\tERROR worker.py:399 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2023-10-17 06:06:53,607\tERROR worker.py:399 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2023-10-17 06:06:53,611\tERROR worker.py:399 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2023-10-17 06:06:53,615\tERROR worker.py:399 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2023-10-17 06:06:53,641\tERROR worker.py:399 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2023-10-17 06:06:53,643\tERROR worker.py:399 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2023-10-17 06:06:53,647\tERROR worker.py:399 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "\t-20.8078\t = Validation score   (-mean_absolute_error)\n",
      "\t296.74s\t = Training   runtime\n",
      "\t0.14s\t = Validation runtime\n",
      "Fitting model: LightGBMLarge_BAG_L1 ...\n",
      "Specified total num_gpus: 1, but only 0 are available. Will use 0 instead\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t-10.6043\t = Validation score   (-mean_absolute_error)\n",
      "\t48.11s\t = Training   runtime\n",
      "\t76.85s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ...\n",
      "\t-9.3014\t = Validation score   (-mean_absolute_error)\n",
      "\t0.47s\t = Training   runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting 9 L2 models ...\n",
      "Fitting model: LightGBMXT_BAG_L2 ...\n",
      "Specified total num_gpus: 1, but only 0 are available. Will use 0 instead\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t-9.2522\t = Validation score   (-mean_absolute_error)\n",
      "\t38.27s\t = Training   runtime\n",
      "\t111.52s\t = Validation runtime\n",
      "Fitting model: LightGBM_BAG_L2 ...\n",
      "Specified total num_gpus: 1, but only 0 are available. Will use 0 instead\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t-7.8378\t = Validation score   (-mean_absolute_error)\n",
      "\t36.19s\t = Training   runtime\n",
      "\t65.13s\t = Validation runtime\n",
      "Fitting model: RandomForestMSE_BAG_L2 ...\n",
      "Specified total num_gpus: 1, but only 0 are available. Will use 0 instead\n",
      "\t-6.5016\t = Validation score   (-mean_absolute_error)\n",
      "\t26.72s\t = Training   runtime\n",
      "\t1.25s\t = Validation runtime\n",
      "Fitting model: CatBoost_BAG_L2 ...\n",
      "Specified total num_gpus: 1, but only 0 are available. Will use 0 instead\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t-7.902\t = Validation score   (-mean_absolute_error)\n",
      "\t343.44s\t = Training   runtime\n",
      "\t0.1s\t = Validation runtime\n",
      "Fitting model: ExtraTreesMSE_BAG_L2 ...\n",
      "Specified total num_gpus: 1, but only 0 are available. Will use 0 instead\n",
      "\t-6.359\t = Validation score   (-mean_absolute_error)\n",
      "\t5.15s\t = Training   runtime\n",
      "\t1.23s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_BAG_L2 ...\n",
      "Specified total num_gpus: 1, but only 0 are available. Will use 0 instead\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t-9.8869\t = Validation score   (-mean_absolute_error)\n",
      "\t46.53s\t = Training   runtime\n",
      "\t0.46s\t = Validation runtime\n",
      "Fitting model: XGBoost_BAG_L2 ...\n",
      "Specified total num_gpus: 1, but only 0 are available. Will use 0 instead\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\tWarning: Exception caused XGBoost_BAG_L2 to fail during training... Skipping this model.\n",
      "\t\t\u001b[36mray::_ray_fit()\u001b[39m (pid=36308, ip=127.0.0.1)\n",
      "  File \"python\\ray\\_raylet.pyx\", line 857, in ray._raylet.execute_task\n",
      "  File \"python\\ray\\_raylet.pyx\", line 861, in ray._raylet.execute_task\n",
      "  File \"c:\\Users\\ineeji\\anaconda3\\envs\\v1\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 402, in _ray_fit\n",
      "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, **resources, **kwargs_fold)\n",
      "  File \"c:\\Users\\ineeji\\anaconda3\\envs\\v1\\lib\\site-packages\\autogluon\\core\\models\\abstract\\abstract_model.py\", line 829, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "  File \"c:\\Users\\ineeji\\anaconda3\\envs\\v1\\lib\\site-packages\\autogluon\\tabular\\models\\xgboost\\xgboost_model.py\", line 143, in _fit\n",
      "    self.params_trained[\"n_estimators\"] = bst.best_ntree_limit\n",
      "AttributeError: 'Booster' object has no attribute 'best_ntree_limit'\n",
      "Detailed Traceback:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\ineeji\\anaconda3\\envs\\v1\\lib\\site-packages\\autogluon\\core\\trainer\\abstract_trainer.py\", line 1733, in _train_and_save\n",
      "    model = self._train_single(X, y, model, X_val, y_val, total_resources=total_resources, **model_fit_kwargs)\n",
      "  File \"c:\\Users\\ineeji\\anaconda3\\envs\\v1\\lib\\site-packages\\autogluon\\core\\trainer\\abstract_trainer.py\", line 1684, in _train_single\n",
      "    model = model.fit(X=X, y=y, X_val=X_val, y_val=y_val, total_resources=total_resources, **model_fit_kwargs)\n",
      "  File \"c:\\Users\\ineeji\\anaconda3\\envs\\v1\\lib\\site-packages\\autogluon\\core\\models\\abstract\\abstract_model.py\", line 829, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "  File \"c:\\Users\\ineeji\\anaconda3\\envs\\v1\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\stacker_ensemble_model.py\", line 169, in _fit\n",
      "    return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
      "  File \"c:\\Users\\ineeji\\anaconda3\\envs\\v1\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\bagged_ensemble_model.py\", line 266, in _fit\n",
      "    self._fit_folds(\n",
      "  File \"c:\\Users\\ineeji\\anaconda3\\envs\\v1\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\bagged_ensemble_model.py\", line 592, in _fit_folds\n",
      "    fold_fitting_strategy.after_all_folds_scheduled()\n",
      "  File \"c:\\Users\\ineeji\\anaconda3\\envs\\v1\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 581, in after_all_folds_scheduled\n",
      "    raise processed_exception\n",
      "  File \"c:\\Users\\ineeji\\anaconda3\\envs\\v1\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 541, in after_all_folds_scheduled\n",
      "    fold_model, pred_proba, time_start_fit, time_end_fit, predict_time, predict_1_time = self.ray.get(finished)\n",
      "  File \"c:\\Users\\ineeji\\anaconda3\\envs\\v1\\lib\\site-packages\\ray\\_private\\client_mode_hook.py\", line 105, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"c:\\Users\\ineeji\\anaconda3\\envs\\v1\\lib\\site-packages\\ray\\_private\\worker.py\", line 2380, in get\n",
      "    raise value.as_instanceof_cause()\n",
      "ray.exceptions.RayTaskError(AttributeError): \u001b[36mray::_ray_fit()\u001b[39m (pid=36308, ip=127.0.0.1)\n",
      "  File \"python\\ray\\_raylet.pyx\", line 857, in ray._raylet.execute_task\n",
      "  File \"python\\ray\\_raylet.pyx\", line 861, in ray._raylet.execute_task\n",
      "  File \"c:\\Users\\ineeji\\anaconda3\\envs\\v1\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 402, in _ray_fit\n",
      "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, **resources, **kwargs_fold)\n",
      "  File \"c:\\Users\\ineeji\\anaconda3\\envs\\v1\\lib\\site-packages\\autogluon\\core\\models\\abstract\\abstract_model.py\", line 829, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "  File \"c:\\Users\\ineeji\\anaconda3\\envs\\v1\\lib\\site-packages\\autogluon\\tabular\\models\\xgboost\\xgboost_model.py\", line 143, in _fit\n",
      "    self.params_trained[\"n_estimators\"] = bst.best_ntree_limit\n",
      "AttributeError: 'Booster' object has no attribute 'best_ntree_limit'\n",
      "Fitting model: NeuralNetTorch_BAG_L2 ...\n",
      "Specified total num_gpus: 1, but only 0 are available. Will use 0 instead\n",
      "2023-10-17 06:23:00,615\tERROR worker.py:399 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2023-10-17 06:23:00,631\tERROR worker.py:399 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2023-10-17 06:23:00,632\tERROR worker.py:399 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2023-10-17 06:23:00,632\tERROR worker.py:399 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2023-10-17 06:23:00,632\tERROR worker.py:399 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2023-10-17 06:23:00,642\tERROR worker.py:399 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2023-10-17 06:23:00,664\tERROR worker.py:399 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t-10.6333\t = Validation score   (-mean_absolute_error)\n",
      "\t71.66s\t = Training   runtime\n",
      "\t0.18s\t = Validation runtime\n",
      "Fitting model: LightGBMLarge_BAG_L2 ...\n",
      "Specified total num_gpus: 1, but only 0 are available. Will use 0 instead\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t-7.1154\t = Validation score   (-mean_absolute_error)\n",
      "\t75.02s\t = Training   runtime\n",
      "\t71.65s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L3 ...\n",
      "\t-6.3282\t = Validation score   (-mean_absolute_error)\n",
      "\t0.46s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 1592.33s ... Best model: \"WeightedEnsemble_L3\"\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels\\ag-20231016_205914\\\")\n",
      "No path specified. Models will be saved in: \"AutogluonModels\\ag-20231016_212837\\\"\n",
      "Presets specified: ['best_quality']\n",
      "Stack configuration (auto_stack=True): num_stack_levels=1, num_bag_folds=8, num_bag_sets=1\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to \"AutogluonModels\\ag-20231016_212837\\\"\n",
      "AutoGluon Version:  0.8.2\n",
      "Python Version:     3.8.16\n",
      "Operating System:   Windows\n",
      "Platform Machine:   AMD64\n",
      "Platform Version:   10.0.22621\n",
      "Disk Space Avail:   124.61 GB / 511.09 GB (24.4%)\n",
      "Train Data Rows:    1998\n",
      "Train Data Columns: 7\n",
      "Label Column: CI_HOUR\n",
      "Preprocessing data ...\n",
      "AutoGluon infers your prediction problem is: 'regression' (because dtype of label-column == float and many unique label-values observed).\n",
      "\tLabel info (max, min, mean, stddev): (1965.486111, 0.0725, 213.60864, 324.98236)\n",
      "\tIf 'regression' is not the correct problem_type, please manually specify the problem_type parameter during predictor init (You may specify problem_type as one of: ['binary', 'multiclass', 'regression'])\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    19024.17 MB\n",
      "\tTrain Data (Original)  Memory Usage: 0.1 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 5 | ['WTI', 'DUBAI', 'BRENT', 'OIL', 'BDI_ADJ']\n",
      "\t\t('int', [])   : 2 | ['month', 'day']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 5 | ['WTI', 'DUBAI', 'BRENT', 'OIL', 'BDI_ADJ']\n",
      "\t\t('int', [])   : 2 | ['month', 'day']\n",
      "\t0.0s = Fit runtime\n",
      "\t7 features in original data used to generate 7 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 0.1 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.05s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'mean_absolute_error'\n",
      "\tThis metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'NN_TORCH': {},\n",
      "\t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, 'GBMLarge'],\n",
      "\t'CAT': {},\n",
      "\t'XGB': {},\n",
      "\t'FASTAI': {},\n",
      "\t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'KNN': [{'weights': 'uniform', 'ag_args': {'name_suffix': 'Unif'}}, {'weights': 'distance', 'ag_args': {'name_suffix': 'Dist'}}],\n",
      "}\n",
      "AutoGluon will fit 2 stack levels (L1 to L2) ...\n",
      "Fitting 11 L1 models ...\n",
      "Fitting model: KNeighborsUnif_BAG_L1 ...\n",
      "Specified total num_gpus: 1, but only 0 are available. Will use 0 instead\n",
      "\t-96.4294\t = Validation score   (-mean_absolute_error)\n",
      "\t0.0s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: KNeighborsDist_BAG_L1 ...\n",
      "Specified total num_gpus: 1, but only 0 are available. Will use 0 instead\n",
      "\t-78.6457\t = Validation score   (-mean_absolute_error)\n",
      "\t0.0s\t = Training   runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: LightGBMXT_BAG_L1 ...\n",
      "Specified total num_gpus: 1, but only 0 are available. Will use 0 instead\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021\n",
      "2021\n",
      "2021\n",
      "2021\n",
      "2021\n",
      "36385\n",
      "36385\n",
      "36385\n",
      "36385\n",
      "36385\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\t-44.174\t = Validation score   (-mean_absolute_error)\n",
      "\t11.86s\t = Training   runtime\n",
      "\t2.98s\t = Validation runtime\n",
      "Fitting model: LightGBM_BAG_L1 ...\n",
      "Specified total num_gpus: 1, but only 0 are available. Will use 0 instead\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t-18.5138\t = Validation score   (-mean_absolute_error)\n",
      "\t12.76s\t = Training   runtime\n",
      "\t1.58s\t = Validation runtime\n",
      "Fitting model: RandomForestMSE_BAG_L1 ...\n",
      "Specified total num_gpus: 1, but only 0 are available. Will use 0 instead\n",
      "\t-21.3487\t = Validation score   (-mean_absolute_error)\n",
      "\t0.37s\t = Training   runtime\n",
      "\t0.08s\t = Validation runtime\n",
      "Fitting model: CatBoost_BAG_L1 ...\n",
      "Specified total num_gpus: 1, but only 0 are available. Will use 0 instead\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t-12.7344\t = Validation score   (-mean_absolute_error)\n",
      "\t121.76s\t = Training   runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Fitting model: ExtraTreesMSE_BAG_L1 ...\n",
      "Specified total num_gpus: 1, but only 0 are available. Will use 0 instead\n",
      "\t-19.6394\t = Validation score   (-mean_absolute_error)\n",
      "\t0.35s\t = Training   runtime\n",
      "\t0.1s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_BAG_L1 ...\n",
      "Specified total num_gpus: 1, but only 0 are available. Will use 0 instead\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t-36.0434\t = Validation score   (-mean_absolute_error)\n",
      "\t5.36s\t = Training   runtime\n",
      "\t0.05s\t = Validation runtime\n",
      "Fitting model: XGBoost_BAG_L1 ...\n",
      "Specified total num_gpus: 1, but only 0 are available. Will use 0 instead\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\tWarning: Exception caused XGBoost_BAG_L1 to fail during training... Skipping this model.\n",
      "\t\t\u001b[36mray::_ray_fit()\u001b[39m (pid=28492, ip=127.0.0.1)\n",
      "  File \"python\\ray\\_raylet.pyx\", line 857, in ray._raylet.execute_task\n",
      "  File \"python\\ray\\_raylet.pyx\", line 861, in ray._raylet.execute_task\n",
      "  File \"c:\\Users\\ineeji\\anaconda3\\envs\\v1\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 402, in _ray_fit\n",
      "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, **resources, **kwargs_fold)\n",
      "  File \"c:\\Users\\ineeji\\anaconda3\\envs\\v1\\lib\\site-packages\\autogluon\\core\\models\\abstract\\abstract_model.py\", line 829, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "  File \"c:\\Users\\ineeji\\anaconda3\\envs\\v1\\lib\\site-packages\\autogluon\\tabular\\models\\xgboost\\xgboost_model.py\", line 143, in _fit\n",
      "    self.params_trained[\"n_estimators\"] = bst.best_ntree_limit\n",
      "AttributeError: 'Booster' object has no attribute 'best_ntree_limit'\n",
      "Detailed Traceback:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\ineeji\\anaconda3\\envs\\v1\\lib\\site-packages\\autogluon\\core\\trainer\\abstract_trainer.py\", line 1733, in _train_and_save\n",
      "    model = self._train_single(X, y, model, X_val, y_val, total_resources=total_resources, **model_fit_kwargs)\n",
      "  File \"c:\\Users\\ineeji\\anaconda3\\envs\\v1\\lib\\site-packages\\autogluon\\core\\trainer\\abstract_trainer.py\", line 1684, in _train_single\n",
      "    model = model.fit(X=X, y=y, X_val=X_val, y_val=y_val, total_resources=total_resources, **model_fit_kwargs)\n",
      "  File \"c:\\Users\\ineeji\\anaconda3\\envs\\v1\\lib\\site-packages\\autogluon\\core\\models\\abstract\\abstract_model.py\", line 829, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "  File \"c:\\Users\\ineeji\\anaconda3\\envs\\v1\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\stacker_ensemble_model.py\", line 169, in _fit\n",
      "    return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
      "  File \"c:\\Users\\ineeji\\anaconda3\\envs\\v1\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\bagged_ensemble_model.py\", line 266, in _fit\n",
      "    self._fit_folds(\n",
      "  File \"c:\\Users\\ineeji\\anaconda3\\envs\\v1\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\bagged_ensemble_model.py\", line 592, in _fit_folds\n",
      "    fold_fitting_strategy.after_all_folds_scheduled()\n",
      "  File \"c:\\Users\\ineeji\\anaconda3\\envs\\v1\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 581, in after_all_folds_scheduled\n",
      "    raise processed_exception\n",
      "  File \"c:\\Users\\ineeji\\anaconda3\\envs\\v1\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 541, in after_all_folds_scheduled\n",
      "    fold_model, pred_proba, time_start_fit, time_end_fit, predict_time, predict_1_time = self.ray.get(finished)\n",
      "  File \"c:\\Users\\ineeji\\anaconda3\\envs\\v1\\lib\\site-packages\\ray\\_private\\client_mode_hook.py\", line 105, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"c:\\Users\\ineeji\\anaconda3\\envs\\v1\\lib\\site-packages\\ray\\_private\\worker.py\", line 2380, in get\n",
      "    raise value.as_instanceof_cause()\n",
      "ray.exceptions.RayTaskError(AttributeError): \u001b[36mray::_ray_fit()\u001b[39m (pid=28492, ip=127.0.0.1)\n",
      "  File \"python\\ray\\_raylet.pyx\", line 857, in ray._raylet.execute_task\n",
      "  File \"python\\ray\\_raylet.pyx\", line 861, in ray._raylet.execute_task\n",
      "  File \"c:\\Users\\ineeji\\anaconda3\\envs\\v1\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 402, in _ray_fit\n",
      "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, **resources, **kwargs_fold)\n",
      "  File \"c:\\Users\\ineeji\\anaconda3\\envs\\v1\\lib\\site-packages\\autogluon\\core\\models\\abstract\\abstract_model.py\", line 829, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "  File \"c:\\Users\\ineeji\\anaconda3\\envs\\v1\\lib\\site-packages\\autogluon\\tabular\\models\\xgboost\\xgboost_model.py\", line 143, in _fit\n",
      "    self.params_trained[\"n_estimators\"] = bst.best_ntree_limit\n",
      "AttributeError: 'Booster' object has no attribute 'best_ntree_limit'\n",
      "Fitting model: NeuralNetTorch_BAG_L1 ...\n",
      "Specified total num_gpus: 1, but only 0 are available. Will use 0 instead\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "2023-10-17 06:31:28,783\tERROR worker.py:399 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2023-10-17 06:31:28,786\tERROR worker.py:399 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2023-10-17 06:31:28,789\tERROR worker.py:399 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2023-10-17 06:31:28,796\tERROR worker.py:399 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2023-10-17 06:31:28,803\tERROR worker.py:399 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2023-10-17 06:31:28,806\tERROR worker.py:399 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2023-10-17 06:31:28,808\tERROR worker.py:399 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "\t-30.001\t = Validation score   (-mean_absolute_error)\n",
      "\t20.95s\t = Training   runtime\n",
      "\t0.07s\t = Validation runtime\n",
      "Fitting model: LightGBMLarge_BAG_L1 ...\n",
      "Specified total num_gpus: 1, but only 0 are available. Will use 0 instead\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t-20.9588\t = Validation score   (-mean_absolute_error)\n",
      "\t19.64s\t = Training   runtime\n",
      "\t1.37s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ...\n",
      "\t-12.725\t = Validation score   (-mean_absolute_error)\n",
      "\t0.22s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting 9 L2 models ...\n",
      "Fitting model: LightGBMXT_BAG_L2 ...\n",
      "Specified total num_gpus: 1, but only 0 are available. Will use 0 instead\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t-14.9747\t = Validation score   (-mean_absolute_error)\n",
      "\t13.06s\t = Training   runtime\n",
      "\t1.34s\t = Validation runtime\n",
      "Fitting model: LightGBM_BAG_L2 ...\n",
      "Specified total num_gpus: 1, but only 0 are available. Will use 0 instead\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t-13.11\t = Validation score   (-mean_absolute_error)\n",
      "\t2.78s\t = Training   runtime\n",
      "\t0.05s\t = Validation runtime\n",
      "Fitting model: RandomForestMSE_BAG_L2 ...\n",
      "Specified total num_gpus: 1, but only 0 are available. Will use 0 instead\n",
      "\t-11.9842\t = Validation score   (-mean_absolute_error)\n",
      "\t1.51s\t = Training   runtime\n",
      "\t0.12s\t = Validation runtime\n",
      "Fitting model: CatBoost_BAG_L2 ...\n",
      "Specified total num_gpus: 1, but only 0 are available. Will use 0 instead\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t-14.0069\t = Validation score   (-mean_absolute_error)\n",
      "\t164.51s\t = Training   runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Fitting model: ExtraTreesMSE_BAG_L2 ...\n",
      "Specified total num_gpus: 1, but only 0 are available. Will use 0 instead\n",
      "\t-12.0876\t = Validation score   (-mean_absolute_error)\n",
      "\t0.38s\t = Training   runtime\n",
      "\t0.09s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_BAG_L2 ...\n",
      "Specified total num_gpus: 1, but only 0 are available. Will use 0 instead\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t-15.8003\t = Validation score   (-mean_absolute_error)\n",
      "\t5.38s\t = Training   runtime\n",
      "\t0.06s\t = Validation runtime\n",
      "Fitting model: XGBoost_BAG_L2 ...\n",
      "Specified total num_gpus: 1, but only 0 are available. Will use 0 instead\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\tWarning: Exception caused XGBoost_BAG_L2 to fail during training... Skipping this model.\n",
      "\t\t\u001b[36mray::_ray_fit()\u001b[39m (pid=29756, ip=127.0.0.1)\n",
      "  File \"python\\ray\\_raylet.pyx\", line 857, in ray._raylet.execute_task\n",
      "  File \"python\\ray\\_raylet.pyx\", line 861, in ray._raylet.execute_task\n",
      "  File \"c:\\Users\\ineeji\\anaconda3\\envs\\v1\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 402, in _ray_fit\n",
      "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, **resources, **kwargs_fold)\n",
      "  File \"c:\\Users\\ineeji\\anaconda3\\envs\\v1\\lib\\site-packages\\autogluon\\core\\models\\abstract\\abstract_model.py\", line 829, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "  File \"c:\\Users\\ineeji\\anaconda3\\envs\\v1\\lib\\site-packages\\autogluon\\tabular\\models\\xgboost\\xgboost_model.py\", line 143, in _fit\n",
      "    self.params_trained[\"n_estimators\"] = bst.best_ntree_limit\n",
      "AttributeError: 'Booster' object has no attribute 'best_ntree_limit'\n",
      "Detailed Traceback:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\ineeji\\anaconda3\\envs\\v1\\lib\\site-packages\\autogluon\\core\\trainer\\abstract_trainer.py\", line 1733, in _train_and_save\n",
      "    model = self._train_single(X, y, model, X_val, y_val, total_resources=total_resources, **model_fit_kwargs)\n",
      "  File \"c:\\Users\\ineeji\\anaconda3\\envs\\v1\\lib\\site-packages\\autogluon\\core\\trainer\\abstract_trainer.py\", line 1684, in _train_single\n",
      "    model = model.fit(X=X, y=y, X_val=X_val, y_val=y_val, total_resources=total_resources, **model_fit_kwargs)\n",
      "  File \"c:\\Users\\ineeji\\anaconda3\\envs\\v1\\lib\\site-packages\\autogluon\\core\\models\\abstract\\abstract_model.py\", line 829, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "  File \"c:\\Users\\ineeji\\anaconda3\\envs\\v1\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\stacker_ensemble_model.py\", line 169, in _fit\n",
      "    return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
      "  File \"c:\\Users\\ineeji\\anaconda3\\envs\\v1\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\bagged_ensemble_model.py\", line 266, in _fit\n",
      "    self._fit_folds(\n",
      "  File \"c:\\Users\\ineeji\\anaconda3\\envs\\v1\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\bagged_ensemble_model.py\", line 592, in _fit_folds\n",
      "    fold_fitting_strategy.after_all_folds_scheduled()\n",
      "  File \"c:\\Users\\ineeji\\anaconda3\\envs\\v1\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 581, in after_all_folds_scheduled\n",
      "    raise processed_exception\n",
      "  File \"c:\\Users\\ineeji\\anaconda3\\envs\\v1\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 541, in after_all_folds_scheduled\n",
      "    fold_model, pred_proba, time_start_fit, time_end_fit, predict_time, predict_1_time = self.ray.get(finished)\n",
      "  File \"c:\\Users\\ineeji\\anaconda3\\envs\\v1\\lib\\site-packages\\ray\\_private\\client_mode_hook.py\", line 105, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"c:\\Users\\ineeji\\anaconda3\\envs\\v1\\lib\\site-packages\\ray\\_private\\worker.py\", line 2380, in get\n",
      "    raise value.as_instanceof_cause()\n",
      "ray.exceptions.RayTaskError(AttributeError): \u001b[36mray::_ray_fit()\u001b[39m (pid=29756, ip=127.0.0.1)\n",
      "  File \"python\\ray\\_raylet.pyx\", line 857, in ray._raylet.execute_task\n",
      "  File \"python\\ray\\_raylet.pyx\", line 861, in ray._raylet.execute_task\n",
      "  File \"c:\\Users\\ineeji\\anaconda3\\envs\\v1\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 402, in _ray_fit\n",
      "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, **resources, **kwargs_fold)\n",
      "  File \"c:\\Users\\ineeji\\anaconda3\\envs\\v1\\lib\\site-packages\\autogluon\\core\\models\\abstract\\abstract_model.py\", line 829, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "  File \"c:\\Users\\ineeji\\anaconda3\\envs\\v1\\lib\\site-packages\\autogluon\\tabular\\models\\xgboost\\xgboost_model.py\", line 143, in _fit\n",
      "    self.params_trained[\"n_estimators\"] = bst.best_ntree_limit\n",
      "AttributeError: 'Booster' object has no attribute 'best_ntree_limit'\n",
      "Fitting model: NeuralNetTorch_BAG_L2 ...\n",
      "Specified total num_gpus: 1, but only 0 are available. Will use 0 instead\n",
      "2023-10-17 06:35:42,657\tERROR worker.py:399 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2023-10-17 06:35:42,657\tERROR worker.py:399 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2023-10-17 06:35:42,686\tERROR worker.py:399 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2023-10-17 06:35:42,689\tERROR worker.py:399 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2023-10-17 06:35:42,692\tERROR worker.py:399 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2023-10-17 06:35:42,693\tERROR worker.py:399 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2023-10-17 06:35:42,696\tERROR worker.py:399 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t-16.5792\t = Validation score   (-mean_absolute_error)\n",
      "\t11.48s\t = Training   runtime\n",
      "\t0.11s\t = Validation runtime\n",
      "Fitting model: LightGBMLarge_BAG_L2 ...\n",
      "Specified total num_gpus: 1, but only 0 are available. Will use 0 instead\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t-12.951\t = Validation score   (-mean_absolute_error)\n",
      "\t40.37s\t = Training   runtime\n",
      "\t1.85s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L3 ...\n",
      "\t-11.8096\t = Validation score   (-mean_absolute_error)\n",
      "\t0.17s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 487.49s ... Best model: \"WeightedEnsemble_L3\"\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels\\ag-20231016_212837\\\")\n",
      "No path specified. Models will be saved in: \"AutogluonModels\\ag-20231016_213656\\\"\n",
      "Presets specified: ['best_quality']\n",
      "Stack configuration (auto_stack=True): num_stack_levels=1, num_bag_folds=8, num_bag_sets=1\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to \"AutogluonModels\\ag-20231016_213656\\\"\n",
      "AutoGluon Version:  0.8.2\n",
      "Python Version:     3.8.16\n",
      "Operating System:   Windows\n",
      "Platform Machine:   AMD64\n",
      "Platform Version:   10.0.22621\n",
      "Disk Space Avail:   123.56 GB / 511.09 GB (24.2%)\n",
      "Train Data Rows:    5363\n",
      "Train Data Columns: 7\n",
      "Label Column: CI_HOUR\n",
      "Preprocessing data ...\n",
      "AutoGluon infers your prediction problem is: 'regression' (because dtype of label-column == float and many unique label-values observed).\n",
      "\tLabel info (max, min, mean, stddev): (1186.935278, 0.635833333, 76.7644, 120.71198)\n",
      "\tIf 'regression' is not the correct problem_type, please manually specify the problem_type parameter during predictor init (You may specify problem_type as one of: ['binary', 'multiclass', 'regression'])\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    19031.62 MB\n",
      "\tTrain Data (Original)  Memory Usage: 0.26 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\t\t\tNote: Converting 1 features to boolean dtype as they only contain 2 unique values.\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 5 | ['WTI', 'DUBAI', 'BRENT', 'OIL', 'BDI_ADJ']\n",
      "\t\t('int', [])   : 2 | ['month', 'day']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('float', [])     : 5 | ['WTI', 'DUBAI', 'BRENT', 'OIL', 'BDI_ADJ']\n",
      "\t\t('int', [])       : 1 | ['day']\n",
      "\t\t('int', ['bool']) : 1 | ['month']\n",
      "\t0.0s = Fit runtime\n",
      "\t7 features in original data used to generate 7 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 0.24 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.07s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'mean_absolute_error'\n",
      "\tThis metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'NN_TORCH': {},\n",
      "\t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, 'GBMLarge'],\n",
      "\t'CAT': {},\n",
      "\t'XGB': {},\n",
      "\t'FASTAI': {},\n",
      "\t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'KNN': [{'weights': 'uniform', 'ag_args': {'name_suffix': 'Unif'}}, {'weights': 'distance', 'ag_args': {'name_suffix': 'Dist'}}],\n",
      "}\n",
      "AutoGluon will fit 2 stack levels (L1 to L2) ...\n",
      "Fitting 11 L1 models ...\n",
      "Fitting model: KNeighborsUnif_BAG_L1 ...\n",
      "Specified total num_gpus: 1, but only 0 are available. Will use 0 instead\n",
      "\t-21.1821\t = Validation score   (-mean_absolute_error)\n",
      "\t0.0s\t = Training   runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: KNeighborsDist_BAG_L1 ...\n",
      "Specified total num_gpus: 1, but only 0 are available. Will use 0 instead\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2014\n",
      "2014\n",
      "2014\n",
      "2014\n",
      "2014\n",
      "1998\n",
      "1998\n",
      "1998\n",
      "1998\n",
      "1998\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\t-19.1165\t = Validation score   (-mean_absolute_error)\n",
      "\t0.0s\t = Training   runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Fitting model: LightGBMXT_BAG_L1 ...\n",
      "Specified total num_gpus: 1, but only 0 are available. Will use 0 instead\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t-7.8999\t = Validation score   (-mean_absolute_error)\n",
      "\t14.94s\t = Training   runtime\n",
      "\t9.59s\t = Validation runtime\n",
      "Fitting model: LightGBM_BAG_L1 ...\n",
      "Specified total num_gpus: 1, but only 0 are available. Will use 0 instead\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t-8.1474\t = Validation score   (-mean_absolute_error)\n",
      "\t10.05s\t = Training   runtime\n",
      "\t1.72s\t = Validation runtime\n",
      "Fitting model: RandomForestMSE_BAG_L1 ...\n",
      "Specified total num_gpus: 1, but only 0 are available. Will use 0 instead\n",
      "\t-8.6461\t = Validation score   (-mean_absolute_error)\n",
      "\t0.39s\t = Training   runtime\n",
      "\t0.15s\t = Validation runtime\n",
      "Fitting model: CatBoost_BAG_L1 ...\n",
      "Specified total num_gpus: 1, but only 0 are available. Will use 0 instead\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t-7.8441\t = Validation score   (-mean_absolute_error)\n",
      "\t50.81s\t = Training   runtime\n",
      "\t0.07s\t = Validation runtime\n",
      "Fitting model: ExtraTreesMSE_BAG_L1 ...\n",
      "Specified total num_gpus: 1, but only 0 are available. Will use 0 instead\n",
      "\t-8.2374\t = Validation score   (-mean_absolute_error)\n",
      "\t0.39s\t = Training   runtime\n",
      "\t0.17s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_BAG_L1 ...\n",
      "Specified total num_gpus: 1, but only 0 are available. Will use 0 instead\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t-11.2918\t = Validation score   (-mean_absolute_error)\n",
      "\t9.32s\t = Training   runtime\n",
      "\t0.09s\t = Validation runtime\n",
      "Fitting model: XGBoost_BAG_L1 ...\n",
      "Specified total num_gpus: 1, but only 0 are available. Will use 0 instead\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\tWarning: Exception caused XGBoost_BAG_L1 to fail during training... Skipping this model.\n",
      "\t\t\u001b[36mray::_ray_fit()\u001b[39m (pid=38768, ip=127.0.0.1)\n",
      "  File \"python\\ray\\_raylet.pyx\", line 857, in ray._raylet.execute_task\n",
      "  File \"python\\ray\\_raylet.pyx\", line 861, in ray._raylet.execute_task\n",
      "  File \"c:\\Users\\ineeji\\anaconda3\\envs\\v1\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 402, in _ray_fit\n",
      "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, **resources, **kwargs_fold)\n",
      "  File \"c:\\Users\\ineeji\\anaconda3\\envs\\v1\\lib\\site-packages\\autogluon\\core\\models\\abstract\\abstract_model.py\", line 829, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "  File \"c:\\Users\\ineeji\\anaconda3\\envs\\v1\\lib\\site-packages\\autogluon\\tabular\\models\\xgboost\\xgboost_model.py\", line 143, in _fit\n",
      "    self.params_trained[\"n_estimators\"] = bst.best_ntree_limit\n",
      "AttributeError: 'Booster' object has no attribute 'best_ntree_limit'\n",
      "Detailed Traceback:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\ineeji\\anaconda3\\envs\\v1\\lib\\site-packages\\autogluon\\core\\trainer\\abstract_trainer.py\", line 1733, in _train_and_save\n",
      "    model = self._train_single(X, y, model, X_val, y_val, total_resources=total_resources, **model_fit_kwargs)\n",
      "  File \"c:\\Users\\ineeji\\anaconda3\\envs\\v1\\lib\\site-packages\\autogluon\\core\\trainer\\abstract_trainer.py\", line 1684, in _train_single\n",
      "    model = model.fit(X=X, y=y, X_val=X_val, y_val=y_val, total_resources=total_resources, **model_fit_kwargs)\n",
      "  File \"c:\\Users\\ineeji\\anaconda3\\envs\\v1\\lib\\site-packages\\autogluon\\core\\models\\abstract\\abstract_model.py\", line 829, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "  File \"c:\\Users\\ineeji\\anaconda3\\envs\\v1\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\stacker_ensemble_model.py\", line 169, in _fit\n",
      "    return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
      "  File \"c:\\Users\\ineeji\\anaconda3\\envs\\v1\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\bagged_ensemble_model.py\", line 266, in _fit\n",
      "    self._fit_folds(\n",
      "  File \"c:\\Users\\ineeji\\anaconda3\\envs\\v1\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\bagged_ensemble_model.py\", line 592, in _fit_folds\n",
      "    fold_fitting_strategy.after_all_folds_scheduled()\n",
      "  File \"c:\\Users\\ineeji\\anaconda3\\envs\\v1\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 581, in after_all_folds_scheduled\n",
      "    raise processed_exception\n",
      "  File \"c:\\Users\\ineeji\\anaconda3\\envs\\v1\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 541, in after_all_folds_scheduled\n",
      "    fold_model, pred_proba, time_start_fit, time_end_fit, predict_time, predict_1_time = self.ray.get(finished)\n",
      "  File \"c:\\Users\\ineeji\\anaconda3\\envs\\v1\\lib\\site-packages\\ray\\_private\\client_mode_hook.py\", line 105, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"c:\\Users\\ineeji\\anaconda3\\envs\\v1\\lib\\site-packages\\ray\\_private\\worker.py\", line 2380, in get\n",
      "    raise value.as_instanceof_cause()\n",
      "ray.exceptions.RayTaskError(AttributeError): \u001b[36mray::_ray_fit()\u001b[39m (pid=38768, ip=127.0.0.1)\n",
      "  File \"python\\ray\\_raylet.pyx\", line 857, in ray._raylet.execute_task\n",
      "  File \"python\\ray\\_raylet.pyx\", line 861, in ray._raylet.execute_task\n",
      "  File \"c:\\Users\\ineeji\\anaconda3\\envs\\v1\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 402, in _ray_fit\n",
      "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, **resources, **kwargs_fold)\n",
      "  File \"c:\\Users\\ineeji\\anaconda3\\envs\\v1\\lib\\site-packages\\autogluon\\core\\models\\abstract\\abstract_model.py\", line 829, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "  File \"c:\\Users\\ineeji\\anaconda3\\envs\\v1\\lib\\site-packages\\autogluon\\tabular\\models\\xgboost\\xgboost_model.py\", line 143, in _fit\n",
      "    self.params_trained[\"n_estimators\"] = bst.best_ntree_limit\n",
      "AttributeError: 'Booster' object has no attribute 'best_ntree_limit'\n",
      "Fitting model: NeuralNetTorch_BAG_L1 ...\n",
      "Specified total num_gpus: 1, but only 0 are available. Will use 0 instead\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "2023-10-17 06:38:46,387\tERROR worker.py:399 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2023-10-17 06:38:46,387\tERROR worker.py:399 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2023-10-17 06:38:46,387\tERROR worker.py:399 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2023-10-17 06:38:46,387\tERROR worker.py:399 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2023-10-17 06:38:46,404\tERROR worker.py:399 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2023-10-17 06:38:46,404\tERROR worker.py:399 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2023-10-17 06:38:46,404\tERROR worker.py:399 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "\t-12.0395\t = Validation score   (-mean_absolute_error)\n",
      "\t40.17s\t = Training   runtime\n",
      "\t0.08s\t = Validation runtime\n",
      "Fitting model: LightGBMLarge_BAG_L1 ...\n",
      "Specified total num_gpus: 1, but only 0 are available. Will use 0 instead\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t-8.4007\t = Validation score   (-mean_absolute_error)\n",
      "\t6.65s\t = Training   runtime\n",
      "\t0.71s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ...\n",
      "\t-7.7472\t = Validation score   (-mean_absolute_error)\n",
      "\t0.25s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting 9 L2 models ...\n",
      "Fitting model: LightGBMXT_BAG_L2 ...\n",
      "Specified total num_gpus: 1, but only 0 are available. Will use 0 instead\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t-5.5835\t = Validation score   (-mean_absolute_error)\n",
      "\t19.25s\t = Training   runtime\n",
      "\t16.35s\t = Validation runtime\n",
      "Fitting model: LightGBM_BAG_L2 ...\n",
      "Specified total num_gpus: 1, but only 0 are available. Will use 0 instead\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t-5.8877\t = Validation score   (-mean_absolute_error)\n",
      "\t21.27s\t = Training   runtime\n",
      "\t4.86s\t = Validation runtime\n",
      "Fitting model: RandomForestMSE_BAG_L2 ...\n",
      "Specified total num_gpus: 1, but only 0 are available. Will use 0 instead\n",
      "\t-5.0343\t = Validation score   (-mean_absolute_error)\n",
      "\t2.59s\t = Training   runtime\n",
      "\t0.2s\t = Validation runtime\n",
      "Fitting model: CatBoost_BAG_L2 ...\n",
      "Specified total num_gpus: 1, but only 0 are available. Will use 0 instead\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t-5.6059\t = Validation score   (-mean_absolute_error)\n",
      "\t248.71s\t = Training   runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Fitting model: ExtraTreesMSE_BAG_L2 ...\n",
      "Specified total num_gpus: 1, but only 0 are available. Will use 0 instead\n",
      "\t-4.958\t = Validation score   (-mean_absolute_error)\n",
      "\t0.76s\t = Training   runtime\n",
      "\t0.28s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_BAG_L2 ...\n",
      "Specified total num_gpus: 1, but only 0 are available. Will use 0 instead\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t-8.1826\t = Validation score   (-mean_absolute_error)\n",
      "\t10.38s\t = Training   runtime\n",
      "\t0.12s\t = Validation runtime\n",
      "Fitting model: XGBoost_BAG_L2 ...\n",
      "Specified total num_gpus: 1, but only 0 are available. Will use 0 instead\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\tWarning: Exception caused XGBoost_BAG_L2 to fail during training... Skipping this model.\n",
      "\t\t\u001b[36mray::_ray_fit()\u001b[39m (pid=25280, ip=127.0.0.1)\n",
      "  File \"python\\ray\\_raylet.pyx\", line 857, in ray._raylet.execute_task\n",
      "  File \"python\\ray\\_raylet.pyx\", line 861, in ray._raylet.execute_task\n",
      "  File \"c:\\Users\\ineeji\\anaconda3\\envs\\v1\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 402, in _ray_fit\n",
      "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, **resources, **kwargs_fold)\n",
      "  File \"c:\\Users\\ineeji\\anaconda3\\envs\\v1\\lib\\site-packages\\autogluon\\core\\models\\abstract\\abstract_model.py\", line 829, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "  File \"c:\\Users\\ineeji\\anaconda3\\envs\\v1\\lib\\site-packages\\autogluon\\tabular\\models\\xgboost\\xgboost_model.py\", line 143, in _fit\n",
      "    self.params_trained[\"n_estimators\"] = bst.best_ntree_limit\n",
      "AttributeError: 'Booster' object has no attribute 'best_ntree_limit'\n",
      "Detailed Traceback:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\ineeji\\anaconda3\\envs\\v1\\lib\\site-packages\\autogluon\\core\\trainer\\abstract_trainer.py\", line 1733, in _train_and_save\n",
      "    model = self._train_single(X, y, model, X_val, y_val, total_resources=total_resources, **model_fit_kwargs)\n",
      "  File \"c:\\Users\\ineeji\\anaconda3\\envs\\v1\\lib\\site-packages\\autogluon\\core\\trainer\\abstract_trainer.py\", line 1684, in _train_single\n",
      "    model = model.fit(X=X, y=y, X_val=X_val, y_val=y_val, total_resources=total_resources, **model_fit_kwargs)\n",
      "  File \"c:\\Users\\ineeji\\anaconda3\\envs\\v1\\lib\\site-packages\\autogluon\\core\\models\\abstract\\abstract_model.py\", line 829, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "  File \"c:\\Users\\ineeji\\anaconda3\\envs\\v1\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\stacker_ensemble_model.py\", line 169, in _fit\n",
      "    return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
      "  File \"c:\\Users\\ineeji\\anaconda3\\envs\\v1\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\bagged_ensemble_model.py\", line 266, in _fit\n",
      "    self._fit_folds(\n",
      "  File \"c:\\Users\\ineeji\\anaconda3\\envs\\v1\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\bagged_ensemble_model.py\", line 592, in _fit_folds\n",
      "    fold_fitting_strategy.after_all_folds_scheduled()\n",
      "  File \"c:\\Users\\ineeji\\anaconda3\\envs\\v1\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 581, in after_all_folds_scheduled\n",
      "    raise processed_exception\n",
      "  File \"c:\\Users\\ineeji\\anaconda3\\envs\\v1\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 541, in after_all_folds_scheduled\n",
      "    fold_model, pred_proba, time_start_fit, time_end_fit, predict_time, predict_1_time = self.ray.get(finished)\n",
      "  File \"c:\\Users\\ineeji\\anaconda3\\envs\\v1\\lib\\site-packages\\ray\\_private\\client_mode_hook.py\", line 105, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"c:\\Users\\ineeji\\anaconda3\\envs\\v1\\lib\\site-packages\\ray\\_private\\worker.py\", line 2380, in get\n",
      "    raise value.as_instanceof_cause()\n",
      "ray.exceptions.RayTaskError(AttributeError): \u001b[36mray::_ray_fit()\u001b[39m (pid=25280, ip=127.0.0.1)\n",
      "  File \"python\\ray\\_raylet.pyx\", line 857, in ray._raylet.execute_task\n",
      "  File \"python\\ray\\_raylet.pyx\", line 861, in ray._raylet.execute_task\n",
      "  File \"c:\\Users\\ineeji\\anaconda3\\envs\\v1\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 402, in _ray_fit\n",
      "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, **resources, **kwargs_fold)\n",
      "  File \"c:\\Users\\ineeji\\anaconda3\\envs\\v1\\lib\\site-packages\\autogluon\\core\\models\\abstract\\abstract_model.py\", line 829, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "  File \"c:\\Users\\ineeji\\anaconda3\\envs\\v1\\lib\\site-packages\\autogluon\\tabular\\models\\xgboost\\xgboost_model.py\", line 143, in _fit\n",
      "    self.params_trained[\"n_estimators\"] = bst.best_ntree_limit\n",
      "AttributeError: 'Booster' object has no attribute 'best_ntree_limit'\n",
      "Fitting model: NeuralNetTorch_BAG_L2 ...\n",
      "Specified total num_gpus: 1, but only 0 are available. Will use 0 instead\n",
      "2023-10-17 06:45:02,374\tERROR worker.py:399 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2023-10-17 06:45:02,374\tERROR worker.py:399 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2023-10-17 06:45:02,374\tERROR worker.py:399 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2023-10-17 06:45:02,390\tERROR worker.py:399 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2023-10-17 06:45:02,390\tERROR worker.py:399 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2023-10-17 06:45:02,390\tERROR worker.py:399 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2023-10-17 06:45:02,400\tERROR worker.py:399 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t-8.6817\t = Validation score   (-mean_absolute_error)\n",
      "\t28.13s\t = Training   runtime\n",
      "\t0.13s\t = Validation runtime\n",
      "Fitting model: LightGBMLarge_BAG_L2 ...\n",
      "Specified total num_gpus: 1, but only 0 are available. Will use 0 instead\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t-5.496\t = Validation score   (-mean_absolute_error)\n",
      "\t10.41s\t = Training   runtime\n",
      "\t0.75s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L3 ...\n",
      "\t-4.9229\t = Validation score   (-mean_absolute_error)\n",
      "\t0.23s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 530.33s ... Best model: \"WeightedEnsemble_L3\"\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels\\ag-20231016_213656\\\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023\n",
      "2023\n",
      "2023\n",
      "2023\n",
      "2023\n",
      "5363\n",
      "5363\n",
      "5363\n",
      "5363\n",
      "5363\n",
      "          SAMPLE_ID      CI_HOUR\n",
      "0       TEST_000000    93.441460\n",
      "1       TEST_000001   383.563049\n",
      "2       TEST_000002     9.032112\n",
      "3       TEST_000003    10.249702\n",
      "4       TEST_000004     6.499660\n",
      "...             ...          ...\n",
      "244984  TEST_244984    45.439926\n",
      "244985  TEST_244985   485.015625\n",
      "244986  TEST_244986     7.015471\n",
      "244987  TEST_244987    10.500275\n",
      "244988  TEST_244988  1043.593994\n",
      "\n",
      "[244989 rows x 2 columns]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SAMPLE_ID</th>\n",
       "      <th>CI_HOUR</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TEST_000000</td>\n",
       "      <td>93.441460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>TEST_000001</td>\n",
       "      <td>383.563049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>TEST_000002</td>\n",
       "      <td>9.032112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>TEST_000003</td>\n",
       "      <td>10.249702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>TEST_000004</td>\n",
       "      <td>6.499660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>244984</th>\n",
       "      <td>TEST_244984</td>\n",
       "      <td>45.439926</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>244985</th>\n",
       "      <td>TEST_244985</td>\n",
       "      <td>485.015625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>244986</th>\n",
       "      <td>TEST_244986</td>\n",
       "      <td>7.015471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>244987</th>\n",
       "      <td>TEST_244987</td>\n",
       "      <td>10.500275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>244988</th>\n",
       "      <td>TEST_244988</td>\n",
       "      <td>1043.593994</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>244989 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          SAMPLE_ID      CI_HOUR\n",
       "0       TEST_000000    93.441460\n",
       "1       TEST_000001   383.563049\n",
       "2       TEST_000002     9.032112\n",
       "3       TEST_000003    10.249702\n",
       "4       TEST_000004     6.499660\n",
       "...             ...          ...\n",
       "244984  TEST_244984    45.439926\n",
       "244985  TEST_244985   485.015625\n",
       "244986  TEST_244986     7.015471\n",
       "244987  TEST_244987    10.500275\n",
       "244988  TEST_244988  1043.593994\n",
       "\n",
       "[244989 rows x 2 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from autogluon.tabular import TabularDataset, TabularPredictor\n",
    "\n",
    "# 각 ARI_CO 별로 데이터 분할 후 학습 및 예측\n",
    "unique_ari_co = train['year'].unique()\n",
    "predictors = {}\n",
    "\n",
    "for ari_co in unique_ari_co:\n",
    "    # ARI_CO 별 데이터 분할\n",
    "    train_subset = train[train['year'] == ari_co].copy()\n",
    "    test_subset = test[test['year'] == ari_co].copy()\n",
    "    train_subset.drop(['year'],axis=1,inplace=True)\n",
    "    test_subset.drop(['year'],axis=1,inplace=True)    \n",
    "\n",
    "    # 데이터셋 변환\n",
    "    train_data = TabularDataset(train_subset)\n",
    "    test_data = TabularDataset(test_subset)\n",
    "    predictors[ari_co] = TabularPredictor(label='CI_HOUR', eval_metric='mean_absolute_error').fit(\n",
    "        train_data, \n",
    "        presets='best_quality',\n",
    "        num_gpus=1\n",
    "    )\n",
    "    # 예측 및 결과 저장\n",
    "    y_pred = predictors[ari_co].predict(test_data)\n",
    "    submission.loc[test_subset.index, 'CI_HOUR'] = y_pred.values\n",
    "    print(ari_co)\n",
    "    print(ari_co)\n",
    "    print(ari_co)\n",
    "    print(ari_co)\n",
    "    print(ari_co)\n",
    "    print(len(train_subset))\n",
    "    print(len(train_subset))\n",
    "    print(len(train_subset))\n",
    "    print(len(train_subset))\n",
    "    print(len(train_subset))\n",
    "    #predictor.leaderboard(train, silent=True)    \n",
    "\n",
    "# 최종 결과 확인\n",
    "print(submission)\n",
    "submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d1638a76",
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.to_csv('abc.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8fa3c4c5",
   "metadata": {},
   "outputs": [
    {
     "ename": "SettingWithCopyError",
     "evalue": "\nA value is trying to be set on a copy of a slice from a DataFrame\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mSettingWithCopyError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\ineeji\\Desktop\\HD\\Autogluon_featue_selection.ipynb Cell 26\u001b[0m line \u001b[0;36m6\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/ineeji/Desktop/HD/Autogluon_featue_selection.ipynb#X43sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m \u001b[39mall\u001b[39m\u001b[39m.\u001b[39mloc[\u001b[39mall\u001b[39m[\u001b[39m'\u001b[39m\u001b[39mDIST\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mCI_HOUR\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/ineeji/Desktop/HD/Autogluon_featue_selection.ipynb#X43sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m submission[\u001b[39m'\u001b[39m\u001b[39mCI_HOUR\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m \u001b[39mall\u001b[39m[\u001b[39m'\u001b[39m\u001b[39mCI_HOUR\u001b[39m\u001b[39m'\u001b[39m]\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/ineeji/Desktop/HD/Autogluon_featue_selection.ipynb#X43sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m submission[\u001b[39m'\u001b[39;49m\u001b[39mCI_HOUR\u001b[39;49m\u001b[39m'\u001b[39;49m][submission[\u001b[39m'\u001b[39;49m\u001b[39mCI_HOUR\u001b[39;49m\u001b[39m'\u001b[39;49m] \u001b[39m<\u001b[39;49m \u001b[39m0\u001b[39;49m] \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/ineeji/Desktop/HD/Autogluon_featue_selection.ipynb#X43sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m submission\u001b[39m.\u001b[39mto_csv(\u001b[39m'\u001b[39m\u001b[39msep_testing_v22.csv\u001b[39m\u001b[39m'\u001b[39m,index\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/ineeji/Desktop/HD/Autogluon_featue_selection.ipynb#X43sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m submission\n",
      "File \u001b[1;32mc:\\Users\\ineeji\\anaconda3\\envs\\v1\\lib\\site-packages\\pandas\\core\\series.py:1149\u001b[0m, in \u001b[0;36mSeries.__setitem__\u001b[1;34m(self, key, value)\u001b[0m\n\u001b[0;32m   1147\u001b[0m check_dict_or_set_indexers(key)\n\u001b[0;32m   1148\u001b[0m key \u001b[39m=\u001b[39m com\u001b[39m.\u001b[39mapply_if_callable(key, \u001b[39mself\u001b[39m)\n\u001b[1;32m-> 1149\u001b[0m cacher_needs_updating \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_check_is_chained_assignment_possible()\n\u001b[0;32m   1151\u001b[0m \u001b[39mif\u001b[39;00m key \u001b[39mis\u001b[39;00m \u001b[39mEllipsis\u001b[39m:\n\u001b[0;32m   1152\u001b[0m     key \u001b[39m=\u001b[39m \u001b[39mslice\u001b[39m(\u001b[39mNone\u001b[39;00m)\n",
      "File \u001b[1;32mc:\\Users\\ineeji\\anaconda3\\envs\\v1\\lib\\site-packages\\pandas\\core\\series.py:1334\u001b[0m, in \u001b[0;36mSeries._check_is_chained_assignment_possible\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1332\u001b[0m     ref \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_get_cacher()\n\u001b[0;32m   1333\u001b[0m     \u001b[39mif\u001b[39;00m ref \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m ref\u001b[39m.\u001b[39m_is_mixed_type:\n\u001b[1;32m-> 1334\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_check_setitem_copy(t\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mreferent\u001b[39;49m\u001b[39m\"\u001b[39;49m, force\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n\u001b[0;32m   1335\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mTrue\u001b[39;00m\n\u001b[0;32m   1336\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39m()\u001b[39m.\u001b[39m_check_is_chained_assignment_possible()\n",
      "File \u001b[1;32mc:\\Users\\ineeji\\anaconda3\\envs\\v1\\lib\\site-packages\\pandas\\core\\generic.py:4247\u001b[0m, in \u001b[0;36mNDFrame._check_setitem_copy\u001b[1;34m(self, t, force)\u001b[0m\n\u001b[0;32m   4236\u001b[0m     t \u001b[39m=\u001b[39m (\n\u001b[0;32m   4237\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[0;32m   4238\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mA value is trying to be set on a copy of a slice from a \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   4243\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mindexing.html#returning-a-view-versus-a-copy\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   4244\u001b[0m     )\n\u001b[0;32m   4246\u001b[0m \u001b[39mif\u001b[39;00m value \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mraise\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[1;32m-> 4247\u001b[0m     \u001b[39mraise\u001b[39;00m SettingWithCopyError(t)\n\u001b[0;32m   4248\u001b[0m \u001b[39mif\u001b[39;00m value \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mwarn\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[0;32m   4249\u001b[0m     warnings\u001b[39m.\u001b[39mwarn(t, SettingWithCopyWarning, stacklevel\u001b[39m=\u001b[39mfind_stack_level())\n",
      "\u001b[1;31mSettingWithCopyError\u001b[0m: \nA value is trying to be set on a copy of a slice from a DataFrame\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy"
     ]
    }
   ],
   "source": [
    "test = pd.read_csv('test.csv')\n",
    "all = pd.concat([test,submission],axis=1)\n",
    "#all['CI_HOUR'][all['DIST'] == 0] = 0\n",
    "all.loc[all['DIST'] == 0, 'CI_HOUR'] = 0\n",
    "submission['CI_HOUR'] = all['CI_HOUR']\n",
    "submission['CI_HOUR'][submission['CI_HOUR'] < 0] = 0\n",
    "submission.to_csv('sep_testing_v22.csv',index=False)\n",
    "submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7222de06",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "v1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
