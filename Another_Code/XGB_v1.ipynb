{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "kvY2HmDexFj3"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import random\n",
        "import os\n",
        "import numpy as np\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from tqdm import tqdm\n",
        "import math\n",
        "import os\n",
        "import torch\n",
        "import random\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn import datasets, ensemble\n",
        "from catboost import CatBoostRegressor\n",
        "from tqdm import tqdm\n",
        "from sklearn.experimental import enable_iterative_imputer\n",
        "from sklearn.impute import IterativeImputer\n",
        "\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.metrics import make_scorer, mean_squared_error\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.metrics import mean_absolute_error\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.model_selection import cross_validate, train_test_split\n",
        "import itertools\n",
        "import math\n",
        "import warnings\n",
        "warnings.filterwarnings(action='ignore')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>SAMPLE_ID</th>\n",
              "      <th>ARI_CO</th>\n",
              "      <th>ARI_PO</th>\n",
              "      <th>SHIP_TYPE_CATEGORY</th>\n",
              "      <th>DIST</th>\n",
              "      <th>ATA</th>\n",
              "      <th>ID</th>\n",
              "      <th>BREADTH</th>\n",
              "      <th>BUILT</th>\n",
              "      <th>DEADWEIGHT</th>\n",
              "      <th>...</th>\n",
              "      <th>V_WIND</th>\n",
              "      <th>AIR_TEMPERATURE</th>\n",
              "      <th>BN</th>\n",
              "      <th>ATA_LT</th>\n",
              "      <th>DUBAI</th>\n",
              "      <th>BRENT</th>\n",
              "      <th>WTI</th>\n",
              "      <th>BDI_ADJ</th>\n",
              "      <th>PORT_SIZE</th>\n",
              "      <th>CI_HOUR</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>TRAIN_000000</td>\n",
              "      <td>CN</td>\n",
              "      <td>EKP8</td>\n",
              "      <td>Bulk</td>\n",
              "      <td>30.736578</td>\n",
              "      <td>2020-10-15 4:03</td>\n",
              "      <td>Z517571</td>\n",
              "      <td>30.0</td>\n",
              "      <td>28</td>\n",
              "      <td>73100</td>\n",
              "      <td>...</td>\n",
              "      <td>3.77</td>\n",
              "      <td>15.9</td>\n",
              "      <td>2.730798</td>\n",
              "      <td>12</td>\n",
              "      <td>42.01</td>\n",
              "      <td>43.16</td>\n",
              "      <td>40.96</td>\n",
              "      <td>1407.668330</td>\n",
              "      <td>0.001660</td>\n",
              "      <td>3.048333</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>TRAIN_000001</td>\n",
              "      <td>CN</td>\n",
              "      <td>EUC8</td>\n",
              "      <td>Container</td>\n",
              "      <td>63.220425</td>\n",
              "      <td>2019-09-17 2:55</td>\n",
              "      <td>U467618</td>\n",
              "      <td>30.0</td>\n",
              "      <td>15</td>\n",
              "      <td>37900</td>\n",
              "      <td>...</td>\n",
              "      <td>-6.72</td>\n",
              "      <td>24.5</td>\n",
              "      <td>4.289058</td>\n",
              "      <td>10</td>\n",
              "      <td>67.53</td>\n",
              "      <td>64.55</td>\n",
              "      <td>59.34</td>\n",
              "      <td>2089.046774</td>\n",
              "      <td>0.001614</td>\n",
              "      <td>17.138611</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>TRAIN_000002</td>\n",
              "      <td>CN</td>\n",
              "      <td>NGG6</td>\n",
              "      <td>Container</td>\n",
              "      <td>90.427421</td>\n",
              "      <td>2019-02-23 6:43</td>\n",
              "      <td>V378315</td>\n",
              "      <td>50.0</td>\n",
              "      <td>7</td>\n",
              "      <td>115000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.00</td>\n",
              "      <td>9.4</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>14</td>\n",
              "      <td>65.30</td>\n",
              "      <td>66.39</td>\n",
              "      <td>56.94</td>\n",
              "      <td>603.193047</td>\n",
              "      <td>0.001743</td>\n",
              "      <td>98.827500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>TRAIN_000003</td>\n",
              "      <td>JP</td>\n",
              "      <td>TMR7</td>\n",
              "      <td>Cargo</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>2020-09-18 22:06</td>\n",
              "      <td>B726632</td>\n",
              "      <td>10.0</td>\n",
              "      <td>33</td>\n",
              "      <td>1490</td>\n",
              "      <td>...</td>\n",
              "      <td>-7.31</td>\n",
              "      <td>22.1</td>\n",
              "      <td>4.693735</td>\n",
              "      <td>7</td>\n",
              "      <td>43.02</td>\n",
              "      <td>43.15</td>\n",
              "      <td>41.11</td>\n",
              "      <td>1169.853455</td>\n",
              "      <td>0.000069</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>TRAIN_000004</td>\n",
              "      <td>RU</td>\n",
              "      <td>NNC2</td>\n",
              "      <td>Container</td>\n",
              "      <td>8.813725</td>\n",
              "      <td>2022-08-13 12:57</td>\n",
              "      <td>D215135</td>\n",
              "      <td>30.0</td>\n",
              "      <td>10</td>\n",
              "      <td>27600</td>\n",
              "      <td>...</td>\n",
              "      <td>2.31</td>\n",
              "      <td>22.8</td>\n",
              "      <td>2.345875</td>\n",
              "      <td>14</td>\n",
              "      <td>90.45</td>\n",
              "      <td>93.65</td>\n",
              "      <td>88.11</td>\n",
              "      <td>1107.944894</td>\n",
              "      <td>0.000197</td>\n",
              "      <td>96.030556</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>367436</th>\n",
              "      <td>TRAIN_367436</td>\n",
              "      <td>CN</td>\n",
              "      <td>YRT6</td>\n",
              "      <td>Bulk</td>\n",
              "      <td>59.018184</td>\n",
              "      <td>2017-11-11 22:23</td>\n",
              "      <td>J661243</td>\n",
              "      <td>40.0</td>\n",
              "      <td>13</td>\n",
              "      <td>93200</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>6</td>\n",
              "      <td>61.25</td>\n",
              "      <td>62.21</td>\n",
              "      <td>55.70</td>\n",
              "      <td>1333.609109</td>\n",
              "      <td>0.000360</td>\n",
              "      <td>65.850000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>367437</th>\n",
              "      <td>TRAIN_367437</td>\n",
              "      <td>JP</td>\n",
              "      <td>QYY1</td>\n",
              "      <td>Tanker</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>2022-04-29 2:58</td>\n",
              "      <td>D847216</td>\n",
              "      <td>10.0</td>\n",
              "      <td>9</td>\n",
              "      <td>1280</td>\n",
              "      <td>...</td>\n",
              "      <td>0.87</td>\n",
              "      <td>17.1</td>\n",
              "      <td>1.028558</td>\n",
              "      <td>11</td>\n",
              "      <td>105.37</td>\n",
              "      <td>109.34</td>\n",
              "      <td>104.69</td>\n",
              "      <td>1955.103846</td>\n",
              "      <td>0.000552</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>367438</th>\n",
              "      <td>TRAIN_367438</td>\n",
              "      <td>SG</td>\n",
              "      <td>GIW5</td>\n",
              "      <td>Container</td>\n",
              "      <td>1.768630</td>\n",
              "      <td>2022-07-14 7:58</td>\n",
              "      <td>Q635545</td>\n",
              "      <td>30.0</td>\n",
              "      <td>6</td>\n",
              "      <td>25000</td>\n",
              "      <td>...</td>\n",
              "      <td>3.36</td>\n",
              "      <td>31.7</td>\n",
              "      <td>2.557156</td>\n",
              "      <td>15</td>\n",
              "      <td>97.73</td>\n",
              "      <td>99.10</td>\n",
              "      <td>95.78</td>\n",
              "      <td>1601.291086</td>\n",
              "      <td>0.002615</td>\n",
              "      <td>0.997500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>367439</th>\n",
              "      <td>TRAIN_367439</td>\n",
              "      <td>JP</td>\n",
              "      <td>TMR7</td>\n",
              "      <td>Cargo</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>2020-12-22 10:07</td>\n",
              "      <td>N211282</td>\n",
              "      <td>10.0</td>\n",
              "      <td>8</td>\n",
              "      <td>2400</td>\n",
              "      <td>...</td>\n",
              "      <td>-2.44</td>\n",
              "      <td>10.8</td>\n",
              "      <td>3.055715</td>\n",
              "      <td>19</td>\n",
              "      <td>49.75</td>\n",
              "      <td>50.08</td>\n",
              "      <td>47.02</td>\n",
              "      <td>1191.353331</td>\n",
              "      <td>0.000069</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>367440</th>\n",
              "      <td>TRAIN_367440</td>\n",
              "      <td>CN</td>\n",
              "      <td>EKP8</td>\n",
              "      <td>Bulk</td>\n",
              "      <td>32.152412</td>\n",
              "      <td>2021-06-04 14:54</td>\n",
              "      <td>V628821</td>\n",
              "      <td>40.0</td>\n",
              "      <td>10</td>\n",
              "      <td>87200</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.84</td>\n",
              "      <td>19.8</td>\n",
              "      <td>3.177475</td>\n",
              "      <td>22</td>\n",
              "      <td>70.10</td>\n",
              "      <td>71.89</td>\n",
              "      <td>69.62</td>\n",
              "      <td>2115.046707</td>\n",
              "      <td>0.001660</td>\n",
              "      <td>8.464167</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>367441 rows × 27 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "           SAMPLE_ID ARI_CO ARI_PO SHIP_TYPE_CATEGORY       DIST  \\\n",
              "0       TRAIN_000000     CN   EKP8               Bulk  30.736578   \n",
              "1       TRAIN_000001     CN   EUC8          Container  63.220425   \n",
              "2       TRAIN_000002     CN   NGG6          Container  90.427421   \n",
              "3       TRAIN_000003     JP   TMR7              Cargo   0.000000   \n",
              "4       TRAIN_000004     RU   NNC2          Container   8.813725   \n",
              "...              ...    ...    ...                ...        ...   \n",
              "367436  TRAIN_367436     CN   YRT6               Bulk  59.018184   \n",
              "367437  TRAIN_367437     JP   QYY1             Tanker   0.000000   \n",
              "367438  TRAIN_367438     SG   GIW5          Container   1.768630   \n",
              "367439  TRAIN_367439     JP   TMR7              Cargo   0.000000   \n",
              "367440  TRAIN_367440     CN   EKP8               Bulk  32.152412   \n",
              "\n",
              "                     ATA       ID  BREADTH  BUILT  DEADWEIGHT  ...  V_WIND  \\\n",
              "0        2020-10-15 4:03  Z517571     30.0     28       73100  ...    3.77   \n",
              "1        2019-09-17 2:55  U467618     30.0     15       37900  ...   -6.72   \n",
              "2        2019-02-23 6:43  V378315     50.0      7      115000  ...    0.00   \n",
              "3       2020-09-18 22:06  B726632     10.0     33        1490  ...   -7.31   \n",
              "4       2022-08-13 12:57  D215135     30.0     10       27600  ...    2.31   \n",
              "...                  ...      ...      ...    ...         ...  ...     ...   \n",
              "367436  2017-11-11 22:23  J661243     40.0     13       93200  ...     NaN   \n",
              "367437   2022-04-29 2:58  D847216     10.0      9        1280  ...    0.87   \n",
              "367438   2022-07-14 7:58  Q635545     30.0      6       25000  ...    3.36   \n",
              "367439  2020-12-22 10:07  N211282     10.0      8        2400  ...   -2.44   \n",
              "367440  2021-06-04 14:54  V628821     40.0     10       87200  ...   -0.84   \n",
              "\n",
              "        AIR_TEMPERATURE        BN  ATA_LT   DUBAI   BRENT     WTI  \\\n",
              "0                  15.9  2.730798      12   42.01   43.16   40.96   \n",
              "1                  24.5  4.289058      10   67.53   64.55   59.34   \n",
              "2                   9.4  0.000000      14   65.30   66.39   56.94   \n",
              "3                  22.1  4.693735       7   43.02   43.15   41.11   \n",
              "4                  22.8  2.345875      14   90.45   93.65   88.11   \n",
              "...                 ...       ...     ...     ...     ...     ...   \n",
              "367436              NaN       NaN       6   61.25   62.21   55.70   \n",
              "367437             17.1  1.028558      11  105.37  109.34  104.69   \n",
              "367438             31.7  2.557156      15   97.73   99.10   95.78   \n",
              "367439             10.8  3.055715      19   49.75   50.08   47.02   \n",
              "367440             19.8  3.177475      22   70.10   71.89   69.62   \n",
              "\n",
              "            BDI_ADJ  PORT_SIZE    CI_HOUR  \n",
              "0       1407.668330   0.001660   3.048333  \n",
              "1       2089.046774   0.001614  17.138611  \n",
              "2        603.193047   0.001743  98.827500  \n",
              "3       1169.853455   0.000069   0.000000  \n",
              "4       1107.944894   0.000197  96.030556  \n",
              "...             ...        ...        ...  \n",
              "367436  1333.609109   0.000360  65.850000  \n",
              "367437  1955.103846   0.000552   0.000000  \n",
              "367438  1601.291086   0.002615   0.997500  \n",
              "367439  1191.353331   0.000069   0.000000  \n",
              "367440  2115.046707   0.001660   8.464167  \n",
              "\n",
              "[367441 rows x 27 columns]"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train = pd.read_csv('train.csv')\n",
        "test = pd.read_csv('test.csv')\n",
        "submission = pd.read_csv('sample_submission.csv')\n",
        "train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>SAMPLE_ID</th>\n",
              "      <th>ARI_CO</th>\n",
              "      <th>ARI_PO</th>\n",
              "      <th>SHIP_TYPE_CATEGORY</th>\n",
              "      <th>DIST</th>\n",
              "      <th>ATA</th>\n",
              "      <th>ID</th>\n",
              "      <th>BREADTH</th>\n",
              "      <th>BUILT</th>\n",
              "      <th>DEADWEIGHT</th>\n",
              "      <th>...</th>\n",
              "      <th>V_WIND</th>\n",
              "      <th>AIR_TEMPERATURE</th>\n",
              "      <th>BN</th>\n",
              "      <th>ATA_LT</th>\n",
              "      <th>DUBAI</th>\n",
              "      <th>BRENT</th>\n",
              "      <th>WTI</th>\n",
              "      <th>BDI_ADJ</th>\n",
              "      <th>PORT_SIZE</th>\n",
              "      <th>CI_HOUR</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>TRAIN_000000</td>\n",
              "      <td>CN</td>\n",
              "      <td>EKP8</td>\n",
              "      <td>Bulk</td>\n",
              "      <td>30.736578</td>\n",
              "      <td>2020-10-15 4:03</td>\n",
              "      <td>Z517571</td>\n",
              "      <td>30.0</td>\n",
              "      <td>28</td>\n",
              "      <td>73100</td>\n",
              "      <td>...</td>\n",
              "      <td>3.77</td>\n",
              "      <td>15.9</td>\n",
              "      <td>2.730798</td>\n",
              "      <td>12</td>\n",
              "      <td>42.01</td>\n",
              "      <td>43.16</td>\n",
              "      <td>40.96</td>\n",
              "      <td>1407.668330</td>\n",
              "      <td>0.001660</td>\n",
              "      <td>3.048333</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>TRAIN_000001</td>\n",
              "      <td>CN</td>\n",
              "      <td>EUC8</td>\n",
              "      <td>Container</td>\n",
              "      <td>63.220425</td>\n",
              "      <td>2019-09-17 2:55</td>\n",
              "      <td>U467618</td>\n",
              "      <td>30.0</td>\n",
              "      <td>15</td>\n",
              "      <td>37900</td>\n",
              "      <td>...</td>\n",
              "      <td>-6.72</td>\n",
              "      <td>24.5</td>\n",
              "      <td>4.289058</td>\n",
              "      <td>10</td>\n",
              "      <td>67.53</td>\n",
              "      <td>64.55</td>\n",
              "      <td>59.34</td>\n",
              "      <td>2089.046774</td>\n",
              "      <td>0.001614</td>\n",
              "      <td>17.138611</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>TRAIN_000002</td>\n",
              "      <td>CN</td>\n",
              "      <td>NGG6</td>\n",
              "      <td>Container</td>\n",
              "      <td>90.427421</td>\n",
              "      <td>2019-02-23 6:43</td>\n",
              "      <td>V378315</td>\n",
              "      <td>50.0</td>\n",
              "      <td>7</td>\n",
              "      <td>115000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.00</td>\n",
              "      <td>9.4</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>14</td>\n",
              "      <td>65.30</td>\n",
              "      <td>66.39</td>\n",
              "      <td>56.94</td>\n",
              "      <td>603.193047</td>\n",
              "      <td>0.001743</td>\n",
              "      <td>98.827500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>TRAIN_000004</td>\n",
              "      <td>RU</td>\n",
              "      <td>NNC2</td>\n",
              "      <td>Container</td>\n",
              "      <td>8.813725</td>\n",
              "      <td>2022-08-13 12:57</td>\n",
              "      <td>D215135</td>\n",
              "      <td>30.0</td>\n",
              "      <td>10</td>\n",
              "      <td>27600</td>\n",
              "      <td>...</td>\n",
              "      <td>2.31</td>\n",
              "      <td>22.8</td>\n",
              "      <td>2.345875</td>\n",
              "      <td>14</td>\n",
              "      <td>90.45</td>\n",
              "      <td>93.65</td>\n",
              "      <td>88.11</td>\n",
              "      <td>1107.944894</td>\n",
              "      <td>0.000197</td>\n",
              "      <td>96.030556</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>TRAIN_000005</td>\n",
              "      <td>CN</td>\n",
              "      <td>NGG6</td>\n",
              "      <td>Container</td>\n",
              "      <td>81.435335</td>\n",
              "      <td>2015-09-08 14:24</td>\n",
              "      <td>Z156413</td>\n",
              "      <td>30.0</td>\n",
              "      <td>22</td>\n",
              "      <td>18100</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>22</td>\n",
              "      <td>45.75</td>\n",
              "      <td>48.89</td>\n",
              "      <td>45.92</td>\n",
              "      <td>820.288044</td>\n",
              "      <td>0.001743</td>\n",
              "      <td>42.078056</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>220050</th>\n",
              "      <td>TRAIN_367433</td>\n",
              "      <td>IN</td>\n",
              "      <td>UJM2</td>\n",
              "      <td>Bulk</td>\n",
              "      <td>30.199074</td>\n",
              "      <td>2022-03-23 8:35</td>\n",
              "      <td>Y242521</td>\n",
              "      <td>30.0</td>\n",
              "      <td>2</td>\n",
              "      <td>63500</td>\n",
              "      <td>...</td>\n",
              "      <td>3.54</td>\n",
              "      <td>36.5</td>\n",
              "      <td>4.306719</td>\n",
              "      <td>14</td>\n",
              "      <td>111.93</td>\n",
              "      <td>120.65</td>\n",
              "      <td>113.90</td>\n",
              "      <td>2077.159292</td>\n",
              "      <td>0.000217</td>\n",
              "      <td>53.400833</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>220051</th>\n",
              "      <td>TRAIN_367434</td>\n",
              "      <td>CN</td>\n",
              "      <td>QQW1</td>\n",
              "      <td>Bulk</td>\n",
              "      <td>55.408765</td>\n",
              "      <td>2022-06-16 14:27</td>\n",
              "      <td>D236761</td>\n",
              "      <td>30.0</td>\n",
              "      <td>16</td>\n",
              "      <td>26500</td>\n",
              "      <td>...</td>\n",
              "      <td>0.96</td>\n",
              "      <td>28.2</td>\n",
              "      <td>2.651752</td>\n",
              "      <td>22</td>\n",
              "      <td>108.43</td>\n",
              "      <td>114.13</td>\n",
              "      <td>109.56</td>\n",
              "      <td>2067.433444</td>\n",
              "      <td>0.000595</td>\n",
              "      <td>83.960833</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>220052</th>\n",
              "      <td>TRAIN_367436</td>\n",
              "      <td>CN</td>\n",
              "      <td>YRT6</td>\n",
              "      <td>Bulk</td>\n",
              "      <td>59.018184</td>\n",
              "      <td>2017-11-11 22:23</td>\n",
              "      <td>J661243</td>\n",
              "      <td>40.0</td>\n",
              "      <td>13</td>\n",
              "      <td>93200</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>6</td>\n",
              "      <td>61.25</td>\n",
              "      <td>62.21</td>\n",
              "      <td>55.70</td>\n",
              "      <td>1333.609109</td>\n",
              "      <td>0.000360</td>\n",
              "      <td>65.850000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>220053</th>\n",
              "      <td>TRAIN_367438</td>\n",
              "      <td>SG</td>\n",
              "      <td>GIW5</td>\n",
              "      <td>Container</td>\n",
              "      <td>1.768630</td>\n",
              "      <td>2022-07-14 7:58</td>\n",
              "      <td>Q635545</td>\n",
              "      <td>30.0</td>\n",
              "      <td>6</td>\n",
              "      <td>25000</td>\n",
              "      <td>...</td>\n",
              "      <td>3.36</td>\n",
              "      <td>31.7</td>\n",
              "      <td>2.557156</td>\n",
              "      <td>15</td>\n",
              "      <td>97.73</td>\n",
              "      <td>99.10</td>\n",
              "      <td>95.78</td>\n",
              "      <td>1601.291086</td>\n",
              "      <td>0.002615</td>\n",
              "      <td>0.997500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>220054</th>\n",
              "      <td>TRAIN_367440</td>\n",
              "      <td>CN</td>\n",
              "      <td>EKP8</td>\n",
              "      <td>Bulk</td>\n",
              "      <td>32.152412</td>\n",
              "      <td>2021-06-04 14:54</td>\n",
              "      <td>V628821</td>\n",
              "      <td>40.0</td>\n",
              "      <td>10</td>\n",
              "      <td>87200</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.84</td>\n",
              "      <td>19.8</td>\n",
              "      <td>3.177475</td>\n",
              "      <td>22</td>\n",
              "      <td>70.10</td>\n",
              "      <td>71.89</td>\n",
              "      <td>69.62</td>\n",
              "      <td>2115.046707</td>\n",
              "      <td>0.001660</td>\n",
              "      <td>8.464167</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>220055 rows × 27 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "           SAMPLE_ID ARI_CO ARI_PO SHIP_TYPE_CATEGORY       DIST  \\\n",
              "0       TRAIN_000000     CN   EKP8               Bulk  30.736578   \n",
              "1       TRAIN_000001     CN   EUC8          Container  63.220425   \n",
              "2       TRAIN_000002     CN   NGG6          Container  90.427421   \n",
              "3       TRAIN_000004     RU   NNC2          Container   8.813725   \n",
              "4       TRAIN_000005     CN   NGG6          Container  81.435335   \n",
              "...              ...    ...    ...                ...        ...   \n",
              "220050  TRAIN_367433     IN   UJM2               Bulk  30.199074   \n",
              "220051  TRAIN_367434     CN   QQW1               Bulk  55.408765   \n",
              "220052  TRAIN_367436     CN   YRT6               Bulk  59.018184   \n",
              "220053  TRAIN_367438     SG   GIW5          Container   1.768630   \n",
              "220054  TRAIN_367440     CN   EKP8               Bulk  32.152412   \n",
              "\n",
              "                     ATA       ID  BREADTH  BUILT  DEADWEIGHT  ...  V_WIND  \\\n",
              "0        2020-10-15 4:03  Z517571     30.0     28       73100  ...    3.77   \n",
              "1        2019-09-17 2:55  U467618     30.0     15       37900  ...   -6.72   \n",
              "2        2019-02-23 6:43  V378315     50.0      7      115000  ...    0.00   \n",
              "3       2022-08-13 12:57  D215135     30.0     10       27600  ...    2.31   \n",
              "4       2015-09-08 14:24  Z156413     30.0     22       18100  ...     NaN   \n",
              "...                  ...      ...      ...    ...         ...  ...     ...   \n",
              "220050   2022-03-23 8:35  Y242521     30.0      2       63500  ...    3.54   \n",
              "220051  2022-06-16 14:27  D236761     30.0     16       26500  ...    0.96   \n",
              "220052  2017-11-11 22:23  J661243     40.0     13       93200  ...     NaN   \n",
              "220053   2022-07-14 7:58  Q635545     30.0      6       25000  ...    3.36   \n",
              "220054  2021-06-04 14:54  V628821     40.0     10       87200  ...   -0.84   \n",
              "\n",
              "        AIR_TEMPERATURE        BN  ATA_LT   DUBAI   BRENT     WTI  \\\n",
              "0                  15.9  2.730798      12   42.01   43.16   40.96   \n",
              "1                  24.5  4.289058      10   67.53   64.55   59.34   \n",
              "2                   9.4  0.000000      14   65.30   66.39   56.94   \n",
              "3                  22.8  2.345875      14   90.45   93.65   88.11   \n",
              "4                   NaN       NaN      22   45.75   48.89   45.92   \n",
              "...                 ...       ...     ...     ...     ...     ...   \n",
              "220050             36.5  4.306719      14  111.93  120.65  113.90   \n",
              "220051             28.2  2.651752      22  108.43  114.13  109.56   \n",
              "220052              NaN       NaN       6   61.25   62.21   55.70   \n",
              "220053             31.7  2.557156      15   97.73   99.10   95.78   \n",
              "220054             19.8  3.177475      22   70.10   71.89   69.62   \n",
              "\n",
              "            BDI_ADJ  PORT_SIZE    CI_HOUR  \n",
              "0       1407.668330   0.001660   3.048333  \n",
              "1       2089.046774   0.001614  17.138611  \n",
              "2        603.193047   0.001743  98.827500  \n",
              "3       1107.944894   0.000197  96.030556  \n",
              "4        820.288044   0.001743  42.078056  \n",
              "...             ...        ...        ...  \n",
              "220050  2077.159292   0.000217  53.400833  \n",
              "220051  2067.433444   0.000595  83.960833  \n",
              "220052  1333.609109   0.000360  65.850000  \n",
              "220053  1601.291086   0.002615   0.997500  \n",
              "220054  2115.046707   0.001660   8.464167  \n",
              "\n",
              "[220055 rows x 27 columns]"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train = train[train['DIST'] != 0]\n",
        "train = train.reset_index(drop = True)\n",
        "train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [],
      "source": [
        "# datetime 컬럼 처리\n",
        "train['ATA'] = pd.to_datetime(train['ATA'])\n",
        "test['ATA'] = pd.to_datetime(test['ATA'])\n",
        "\n",
        "# datetime을 여러 파생 변수로 변환\n",
        "for df in [train, test]:\n",
        "    df['year'] = df['ATA'].dt.year\n",
        "    df['month'] = df['ATA'].dt.month\n",
        "    df['day'] = df['ATA'].dt.day\n",
        "    df['hour'] = df['ATA'].dt.hour\n",
        "    df['minute'] = df['ATA'].dt.minute\n",
        "    df['weekday'] = df['ATA'].dt.weekday\n",
        "\n",
        "# datetime 컬럼 제거\n",
        "train.drop(columns='ATA', inplace=True)\n",
        "test.drop(columns='ATA', inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [],
      "source": [
        "train.drop(['SAMPLE_ID'],axis=1,inplace=True)\n",
        "test.drop(['SAMPLE_ID'],axis=1,inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [],
      "source": [
        "train_x = train.drop(['CI_HOUR'],axis=1)\n",
        "train_y = train[['CI_HOUR']]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# AG"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "No path specified. Models will be saved in: \"AutogluonModels\\ag-20231005_024957\\\"\n",
            "Presets specified: ['medium_quality']\n",
            "Warning: Training may take a very long time because `time_limit` was not specified and `train_data` is large (367441 samples, 203.75 MB).\n",
            "\tConsider setting `time_limit` to ensure training finishes within an expected duration or experiment with a small portion of `train_data` to identify an ideal `presets` and `hyperparameters` configuration.\n",
            "Beginning AutoGluon training ...\n",
            "AutoGluon will save models to \"AutogluonModels\\ag-20231005_024957\\\"\n",
            "AutoGluon Version:  0.8.2\n",
            "Python Version:     3.8.16\n",
            "Operating System:   Windows\n",
            "Platform Machine:   AMD64\n",
            "Platform Version:   10.0.22621\n",
            "Disk Space Avail:   33.32 GB / 511.09 GB (6.5%)\n",
            "Train Data Rows:    367441\n",
            "Train Data Columns: 30\n",
            "Label Column: CI_HOUR\n",
            "Preprocessing data ...\n",
            "AutoGluon infers your prediction problem is: 'regression' (because dtype of label-column == float and many unique label-values observed).\n",
            "\tLabel info (max, min, mean, stddev): (2159.130556, 0.0, 61.87712, 170.57522)\n",
            "\tIf 'regression' is not the correct problem_type, please manually specify the problem_type parameter during predictor init (You may specify problem_type as one of: ['binary', 'multiclass', 'regression'])\n",
            "Using Feature Generators to preprocess the data ...\n",
            "Fitting AutoMLPipelineFeatureGenerator...\n",
            "\tAvailable Memory:                    13116.62 MB\n",
            "\tTrain Data (Original)  Memory Usage: 200.81 MB (1.5% of available memory)\n",
            "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
            "\tStage 1 Generators:\n",
            "\t\tFitting AsTypeFeatureGenerator...\n",
            "\tStage 2 Generators:\n",
            "\t\tFitting FillNaFeatureGenerator...\n",
            "\tStage 3 Generators:\n",
            "\t\tFitting IdentityFeatureGenerator...\n",
            "\t\tFitting CategoryFeatureGenerator...\n",
            "\t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n",
            "\tStage 4 Generators:\n",
            "\t\tFitting DropUniqueFeatureGenerator...\n",
            "\tStage 5 Generators:\n",
            "\t\tFitting DropDuplicatesFeatureGenerator...\n",
            "\tTypes of features in original data (raw dtype, special dtypes):\n",
            "\t\t('float', [])  : 14 | ['DIST', 'BREADTH', 'DEPTH', 'DRAUGHT', 'LENGTH', ...]\n",
            "\t\t('int', [])    : 10 | ['BUILT', 'DEADWEIGHT', 'GT', 'ATA_LT', 'year', ...]\n",
            "\t\t('object', []) :  6 | ['ARI_CO', 'ARI_PO', 'SHIP_TYPE_CATEGORY', 'ID', 'SHIPMANAGER', ...]\n",
            "\tTypes of features in processed data (raw dtype, special dtypes):\n",
            "\t\t('category', []) :  6 | ['ARI_CO', 'ARI_PO', 'SHIP_TYPE_CATEGORY', 'ID', 'SHIPMANAGER', ...]\n",
            "\t\t('float', [])    : 14 | ['DIST', 'BREADTH', 'DEPTH', 'DRAUGHT', 'LENGTH', ...]\n",
            "\t\t('int', [])      : 10 | ['BUILT', 'DEADWEIGHT', 'GT', 'ATA_LT', 'year', ...]\n",
            "\t1.7s = Fit runtime\n",
            "\t30 features in original data used to generate 30 features in processed data.\n",
            "\tTrain Data (Processed) Memory Usage: 64.67 MB (0.5% of available memory)\n",
            "Data preprocessing and feature engineering runtime = 1.92s ...\n",
            "AutoGluon will gauge predictive performance using evaluation metric: 'mean_absolute_error'\n",
            "\tThis metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.\n",
            "\tTo change this, specify the eval_metric parameter of Predictor()\n",
            "Automatically generating train/validation split with holdout_frac=0.01, Train Rows: 363766, Val Rows: 3675\n",
            "User-specified model hyperparameters to be fit:\n",
            "{\n",
            "\t'NN_TORCH': {},\n",
            "\t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, 'GBMLarge'],\n",
            "\t'CAT': {},\n",
            "\t'XGB': {},\n",
            "\t'FASTAI': {},\n",
            "\t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
            "\t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
            "\t'KNN': [{'weights': 'uniform', 'ag_args': {'name_suffix': 'Unif'}}, {'weights': 'distance', 'ag_args': {'name_suffix': 'Dist'}}],\n",
            "}\n",
            "Fitting 11 L1 models ...\n",
            "Fitting model: KNeighborsUnif ...\n",
            "\t-81.1563\t = Validation score   (-mean_absolute_error)\n",
            "\t0.23s\t = Training   runtime\n",
            "\t1.59s\t = Validation runtime\n",
            "Fitting model: KNeighborsDist ...\n",
            "\t-80.2924\t = Validation score   (-mean_absolute_error)\n",
            "\t0.21s\t = Training   runtime\n",
            "\t1.37s\t = Validation runtime\n",
            "Fitting model: LightGBMXT ...\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[1000]\tvalid_set's l1: 56.1213\n",
            "[2000]\tvalid_set's l1: 54.9496\n",
            "[3000]\tvalid_set's l1: 53.8918\n",
            "[4000]\tvalid_set's l1: 52.7832\n",
            "[5000]\tvalid_set's l1: 52.0745\n",
            "[6000]\tvalid_set's l1: 51.5883\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[1;32mc:\\Users\\ineeji\\Desktop\\HD\\XGB_v1.ipynb Cell 7\u001b[0m line \u001b[0;36m7\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/ineeji/Desktop/HD/XGB_v1.ipynb#W6sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m train_data \u001b[39m=\u001b[39m TabularDataset(train)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/ineeji/Desktop/HD/XGB_v1.ipynb#W6sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m test_data \u001b[39m=\u001b[39m TabularDataset(test)\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/ineeji/Desktop/HD/XGB_v1.ipynb#W6sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m predictor \u001b[39m=\u001b[39m TabularPredictor(label\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mCI_HOUR\u001b[39;49m\u001b[39m'\u001b[39;49m,  eval_metric\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mmean_absolute_error\u001b[39;49m\u001b[39m'\u001b[39;49m)\u001b[39m.\u001b[39;49mfit(train, presets\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mmedium_quality\u001b[39;49m\u001b[39m'\u001b[39;49m,  ag_args_fit\u001b[39m=\u001b[39;49m{\u001b[39m'\u001b[39;49m\u001b[39mnum_gpus\u001b[39;49m\u001b[39m'\u001b[39;49m: \u001b[39m0\u001b[39;49m})\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/ineeji/Desktop/HD/XGB_v1.ipynb#W6sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m predictor\u001b[39m.\u001b[39mleaderboard(train, silent\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/ineeji/Desktop/HD/XGB_v1.ipynb#W6sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m y_pred \u001b[39m=\u001b[39m predictor\u001b[39m.\u001b[39mpredict(test_data)\n",
            "File \u001b[1;32mc:\\Users\\ineeji\\anaconda3\\envs\\v1\\lib\\site-packages\\autogluon\\core\\utils\\decorators.py:31\u001b[0m, in \u001b[0;36munpack.<locals>._unpack_inner.<locals>._call\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     28\u001b[0m \u001b[39m@functools\u001b[39m\u001b[39m.\u001b[39mwraps(f)\n\u001b[0;32m     29\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_call\u001b[39m(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m     30\u001b[0m     gargs, gkwargs \u001b[39m=\u001b[39m g(\u001b[39m*\u001b[39mother_args, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m---> 31\u001b[0m     \u001b[39mreturn\u001b[39;00m f(\u001b[39m*\u001b[39;49mgargs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mgkwargs)\n",
            "File \u001b[1;32mc:\\Users\\ineeji\\anaconda3\\envs\\v1\\lib\\site-packages\\autogluon\\tabular\\predictor\\predictor.py:986\u001b[0m, in \u001b[0;36mTabularPredictor.fit\u001b[1;34m(self, train_data, tuning_data, time_limit, presets, hyperparameters, feature_metadata, infer_limit, infer_limit_batch_size, fit_weighted_ensemble, calibrate_decision_threshold, num_cpus, num_gpus, **kwargs)\u001b[0m\n\u001b[0;32m    984\u001b[0m     aux_kwargs[\u001b[39m\"\u001b[39m\u001b[39mfit_weighted_ensemble\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[0;32m    985\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msave(silent\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)  \u001b[39m# Save predictor to disk to enable prediction and training after interrupt\u001b[39;00m\n\u001b[1;32m--> 986\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_learner\u001b[39m.\u001b[39;49mfit(\n\u001b[0;32m    987\u001b[0m     X\u001b[39m=\u001b[39;49mtrain_data,\n\u001b[0;32m    988\u001b[0m     X_val\u001b[39m=\u001b[39;49mtuning_data,\n\u001b[0;32m    989\u001b[0m     X_unlabeled\u001b[39m=\u001b[39;49munlabeled_data,\n\u001b[0;32m    990\u001b[0m     holdout_frac\u001b[39m=\u001b[39;49mholdout_frac,\n\u001b[0;32m    991\u001b[0m     num_bag_folds\u001b[39m=\u001b[39;49mnum_bag_folds,\n\u001b[0;32m    992\u001b[0m     num_bag_sets\u001b[39m=\u001b[39;49mnum_bag_sets,\n\u001b[0;32m    993\u001b[0m     num_stack_levels\u001b[39m=\u001b[39;49mnum_stack_levels,\n\u001b[0;32m    994\u001b[0m     hyperparameters\u001b[39m=\u001b[39;49mhyperparameters,\n\u001b[0;32m    995\u001b[0m     core_kwargs\u001b[39m=\u001b[39;49mcore_kwargs,\n\u001b[0;32m    996\u001b[0m     aux_kwargs\u001b[39m=\u001b[39;49maux_kwargs,\n\u001b[0;32m    997\u001b[0m     time_limit\u001b[39m=\u001b[39;49mtime_limit,\n\u001b[0;32m    998\u001b[0m     infer_limit\u001b[39m=\u001b[39;49minfer_limit,\n\u001b[0;32m    999\u001b[0m     infer_limit_batch_size\u001b[39m=\u001b[39;49minfer_limit_batch_size,\n\u001b[0;32m   1000\u001b[0m     verbosity\u001b[39m=\u001b[39;49mverbosity,\n\u001b[0;32m   1001\u001b[0m     use_bag_holdout\u001b[39m=\u001b[39;49muse_bag_holdout,\n\u001b[0;32m   1002\u001b[0m )\n\u001b[0;32m   1003\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_set_post_fit_vars()\n\u001b[0;32m   1005\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_post_fit(\n\u001b[0;32m   1006\u001b[0m     keep_only_best\u001b[39m=\u001b[39mkwargs[\u001b[39m\"\u001b[39m\u001b[39mkeep_only_best\u001b[39m\u001b[39m\"\u001b[39m],\n\u001b[0;32m   1007\u001b[0m     refit_full\u001b[39m=\u001b[39mkwargs[\u001b[39m\"\u001b[39m\u001b[39mrefit_full\u001b[39m\u001b[39m\"\u001b[39m],\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1012\u001b[0m     infer_limit\u001b[39m=\u001b[39minfer_limit,\n\u001b[0;32m   1013\u001b[0m )\n",
            "File \u001b[1;32mc:\\Users\\ineeji\\anaconda3\\envs\\v1\\lib\\site-packages\\autogluon\\tabular\\learner\\abstract_learner.py:159\u001b[0m, in \u001b[0;36mAbstractTabularLearner.fit\u001b[1;34m(self, X, X_val, **kwargs)\u001b[0m\n\u001b[0;32m    157\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mAssertionError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mLearner is already fit.\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m    158\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_validate_fit_input(X\u001b[39m=\u001b[39mX, X_val\u001b[39m=\u001b[39mX_val, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m--> 159\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_fit(X\u001b[39m=\u001b[39;49mX, X_val\u001b[39m=\u001b[39;49mX_val, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
            "File \u001b[1;32mc:\\Users\\ineeji\\anaconda3\\envs\\v1\\lib\\site-packages\\autogluon\\tabular\\learner\\default_learner.py:157\u001b[0m, in \u001b[0;36mDefaultLearner._fit\u001b[1;34m(self, X, X_val, X_unlabeled, holdout_frac, num_bag_folds, num_bag_sets, time_limit, infer_limit, infer_limit_batch_size, verbosity, **trainer_fit_kwargs)\u001b[0m\n\u001b[0;32m    154\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39meval_metric \u001b[39m=\u001b[39m trainer\u001b[39m.\u001b[39meval_metric\n\u001b[0;32m    156\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msave()\n\u001b[1;32m--> 157\u001b[0m trainer\u001b[39m.\u001b[39;49mfit(\n\u001b[0;32m    158\u001b[0m     X\u001b[39m=\u001b[39;49mX,\n\u001b[0;32m    159\u001b[0m     y\u001b[39m=\u001b[39;49my,\n\u001b[0;32m    160\u001b[0m     X_val\u001b[39m=\u001b[39;49mX_val,\n\u001b[0;32m    161\u001b[0m     y_val\u001b[39m=\u001b[39;49my_val,\n\u001b[0;32m    162\u001b[0m     X_unlabeled\u001b[39m=\u001b[39;49mX_unlabeled,\n\u001b[0;32m    163\u001b[0m     holdout_frac\u001b[39m=\u001b[39;49mholdout_frac,\n\u001b[0;32m    164\u001b[0m     time_limit\u001b[39m=\u001b[39;49mtime_limit_trainer,\n\u001b[0;32m    165\u001b[0m     infer_limit\u001b[39m=\u001b[39;49minfer_limit,\n\u001b[0;32m    166\u001b[0m     infer_limit_batch_size\u001b[39m=\u001b[39;49minfer_limit_batch_size,\n\u001b[0;32m    167\u001b[0m     groups\u001b[39m=\u001b[39;49mgroups,\n\u001b[0;32m    168\u001b[0m     \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mtrainer_fit_kwargs,\n\u001b[0;32m    169\u001b[0m )\n\u001b[0;32m    170\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msave_trainer(trainer\u001b[39m=\u001b[39mtrainer)\n\u001b[0;32m    171\u001b[0m time_end \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime()\n",
            "File \u001b[1;32mc:\\Users\\ineeji\\anaconda3\\envs\\v1\\lib\\site-packages\\autogluon\\tabular\\trainer\\auto_trainer.py:114\u001b[0m, in \u001b[0;36mAutoTrainer.fit\u001b[1;34m(self, X, y, hyperparameters, X_val, y_val, X_unlabeled, holdout_frac, num_stack_levels, core_kwargs, aux_kwargs, time_limit, infer_limit, infer_limit_batch_size, use_bag_holdout, groups, **kwargs)\u001b[0m\n\u001b[0;32m    111\u001b[0m log_str \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m}\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    112\u001b[0m logger\u001b[39m.\u001b[39mlog(\u001b[39m20\u001b[39m, log_str)\n\u001b[1;32m--> 114\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_train_multi_and_ensemble(\n\u001b[0;32m    115\u001b[0m     X\u001b[39m=\u001b[39;49mX,\n\u001b[0;32m    116\u001b[0m     y\u001b[39m=\u001b[39;49my,\n\u001b[0;32m    117\u001b[0m     X_val\u001b[39m=\u001b[39;49mX_val,\n\u001b[0;32m    118\u001b[0m     y_val\u001b[39m=\u001b[39;49my_val,\n\u001b[0;32m    119\u001b[0m     X_unlabeled\u001b[39m=\u001b[39;49mX_unlabeled,\n\u001b[0;32m    120\u001b[0m     hyperparameters\u001b[39m=\u001b[39;49mhyperparameters,\n\u001b[0;32m    121\u001b[0m     num_stack_levels\u001b[39m=\u001b[39;49mnum_stack_levels,\n\u001b[0;32m    122\u001b[0m     time_limit\u001b[39m=\u001b[39;49mtime_limit,\n\u001b[0;32m    123\u001b[0m     core_kwargs\u001b[39m=\u001b[39;49mcore_kwargs,\n\u001b[0;32m    124\u001b[0m     aux_kwargs\u001b[39m=\u001b[39;49maux_kwargs,\n\u001b[0;32m    125\u001b[0m     infer_limit\u001b[39m=\u001b[39;49minfer_limit,\n\u001b[0;32m    126\u001b[0m     infer_limit_batch_size\u001b[39m=\u001b[39;49minfer_limit_batch_size,\n\u001b[0;32m    127\u001b[0m     groups\u001b[39m=\u001b[39;49mgroups,\n\u001b[0;32m    128\u001b[0m )\n",
            "File \u001b[1;32mc:\\Users\\ineeji\\anaconda3\\envs\\v1\\lib\\site-packages\\autogluon\\core\\trainer\\abstract_trainer.py:2371\u001b[0m, in \u001b[0;36mAbstractTrainer._train_multi_and_ensemble\u001b[1;34m(self, X, y, X_val, y_val, hyperparameters, X_unlabeled, num_stack_levels, time_limit, groups, **kwargs)\u001b[0m\n\u001b[0;32m   2369\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_rows_val \u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(X_val)\n\u001b[0;32m   2370\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_cols_train \u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(\u001b[39mlist\u001b[39m(X\u001b[39m.\u001b[39mcolumns))\n\u001b[1;32m-> 2371\u001b[0m model_names_fit \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrain_multi_levels(\n\u001b[0;32m   2372\u001b[0m     X,\n\u001b[0;32m   2373\u001b[0m     y,\n\u001b[0;32m   2374\u001b[0m     hyperparameters\u001b[39m=\u001b[39;49mhyperparameters,\n\u001b[0;32m   2375\u001b[0m     X_val\u001b[39m=\u001b[39;49mX_val,\n\u001b[0;32m   2376\u001b[0m     y_val\u001b[39m=\u001b[39;49my_val,\n\u001b[0;32m   2377\u001b[0m     X_unlabeled\u001b[39m=\u001b[39;49mX_unlabeled,\n\u001b[0;32m   2378\u001b[0m     level_start\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m,\n\u001b[0;32m   2379\u001b[0m     level_end\u001b[39m=\u001b[39;49mnum_stack_levels \u001b[39m+\u001b[39;49m \u001b[39m1\u001b[39;49m,\n\u001b[0;32m   2380\u001b[0m     time_limit\u001b[39m=\u001b[39;49mtime_limit,\n\u001b[0;32m   2381\u001b[0m     \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs,\n\u001b[0;32m   2382\u001b[0m )\n\u001b[0;32m   2383\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mget_model_names()) \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[0;32m   2384\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mAutoGluon did not successfully train any models\u001b[39m\u001b[39m\"\u001b[39m)\n",
            "File \u001b[1;32mc:\\Users\\ineeji\\anaconda3\\envs\\v1\\lib\\site-packages\\autogluon\\core\\trainer\\abstract_trainer.py:395\u001b[0m, in \u001b[0;36mAbstractTrainer.train_multi_levels\u001b[1;34m(self, X, y, hyperparameters, X_val, y_val, X_unlabeled, base_model_names, core_kwargs, aux_kwargs, level_start, level_end, time_limit, name_suffix, relative_stack, level_time_modifier, infer_limit, infer_limit_batch_size)\u001b[0m\n\u001b[0;32m    393\u001b[0m         core_kwargs_level[\u001b[39m\"\u001b[39m\u001b[39mtime_limit\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m core_kwargs_level\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mtime_limit\u001b[39m\u001b[39m\"\u001b[39m, time_limit_core)\n\u001b[0;32m    394\u001b[0m         aux_kwargs_level[\u001b[39m\"\u001b[39m\u001b[39mtime_limit\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m aux_kwargs_level\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mtime_limit\u001b[39m\u001b[39m\"\u001b[39m, time_limit_aux)\n\u001b[1;32m--> 395\u001b[0m     base_model_names, aux_models \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mstack_new_level(\n\u001b[0;32m    396\u001b[0m         X\u001b[39m=\u001b[39;49mX,\n\u001b[0;32m    397\u001b[0m         y\u001b[39m=\u001b[39;49my,\n\u001b[0;32m    398\u001b[0m         X_val\u001b[39m=\u001b[39;49mX_val,\n\u001b[0;32m    399\u001b[0m         y_val\u001b[39m=\u001b[39;49my_val,\n\u001b[0;32m    400\u001b[0m         X_unlabeled\u001b[39m=\u001b[39;49mX_unlabeled,\n\u001b[0;32m    401\u001b[0m         models\u001b[39m=\u001b[39;49mhyperparameters,\n\u001b[0;32m    402\u001b[0m         level\u001b[39m=\u001b[39;49mlevel,\n\u001b[0;32m    403\u001b[0m         base_model_names\u001b[39m=\u001b[39;49mbase_model_names,\n\u001b[0;32m    404\u001b[0m         core_kwargs\u001b[39m=\u001b[39;49mcore_kwargs_level,\n\u001b[0;32m    405\u001b[0m         aux_kwargs\u001b[39m=\u001b[39;49maux_kwargs_level,\n\u001b[0;32m    406\u001b[0m         name_suffix\u001b[39m=\u001b[39;49mname_suffix,\n\u001b[0;32m    407\u001b[0m         infer_limit\u001b[39m=\u001b[39;49minfer_limit,\n\u001b[0;32m    408\u001b[0m         infer_limit_batch_size\u001b[39m=\u001b[39;49minfer_limit_batch_size,\n\u001b[0;32m    409\u001b[0m     )\n\u001b[0;32m    410\u001b[0m     model_names_fit \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m base_model_names \u001b[39m+\u001b[39m aux_models\n\u001b[0;32m    411\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel_best \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \u001b[39mlen\u001b[39m(model_names_fit) \u001b[39m!=\u001b[39m \u001b[39m0\u001b[39m:\n",
            "File \u001b[1;32mc:\\Users\\ineeji\\anaconda3\\envs\\v1\\lib\\site-packages\\autogluon\\core\\trainer\\abstract_trainer.py:539\u001b[0m, in \u001b[0;36mAbstractTrainer.stack_new_level\u001b[1;34m(self, X, y, models, X_val, y_val, X_unlabeled, level, base_model_names, core_kwargs, aux_kwargs, name_suffix, infer_limit, infer_limit_batch_size)\u001b[0m\n\u001b[0;32m    537\u001b[0m     core_kwargs[\u001b[39m\"\u001b[39m\u001b[39mname_suffix\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m core_kwargs\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mname_suffix\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39m+\u001b[39m name_suffix\n\u001b[0;32m    538\u001b[0m     aux_kwargs[\u001b[39m\"\u001b[39m\u001b[39mname_suffix\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m aux_kwargs\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mname_suffix\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39m+\u001b[39m name_suffix\n\u001b[1;32m--> 539\u001b[0m core_models \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mstack_new_level_core(\n\u001b[0;32m    540\u001b[0m     X\u001b[39m=\u001b[39;49mX,\n\u001b[0;32m    541\u001b[0m     y\u001b[39m=\u001b[39;49my,\n\u001b[0;32m    542\u001b[0m     X_val\u001b[39m=\u001b[39;49mX_val,\n\u001b[0;32m    543\u001b[0m     y_val\u001b[39m=\u001b[39;49my_val,\n\u001b[0;32m    544\u001b[0m     X_unlabeled\u001b[39m=\u001b[39;49mX_unlabeled,\n\u001b[0;32m    545\u001b[0m     models\u001b[39m=\u001b[39;49mmodels,\n\u001b[0;32m    546\u001b[0m     level\u001b[39m=\u001b[39;49mlevel,\n\u001b[0;32m    547\u001b[0m     infer_limit\u001b[39m=\u001b[39;49minfer_limit,\n\u001b[0;32m    548\u001b[0m     infer_limit_batch_size\u001b[39m=\u001b[39;49minfer_limit_batch_size,\n\u001b[0;32m    549\u001b[0m     base_model_names\u001b[39m=\u001b[39;49mbase_model_names,\n\u001b[0;32m    550\u001b[0m     \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mcore_kwargs,\n\u001b[0;32m    551\u001b[0m )\n\u001b[0;32m    553\u001b[0m \u001b[39mif\u001b[39;00m X_val \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    554\u001b[0m     aux_models \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstack_new_level_aux(\n\u001b[0;32m    555\u001b[0m         X\u001b[39m=\u001b[39mX, y\u001b[39m=\u001b[39my, base_model_names\u001b[39m=\u001b[39mcore_models, level\u001b[39m=\u001b[39mlevel \u001b[39m+\u001b[39m \u001b[39m1\u001b[39m, infer_limit\u001b[39m=\u001b[39minfer_limit, infer_limit_batch_size\u001b[39m=\u001b[39minfer_limit_batch_size, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39maux_kwargs\n\u001b[0;32m    556\u001b[0m     )\n",
            "File \u001b[1;32mc:\\Users\\ineeji\\anaconda3\\envs\\v1\\lib\\site-packages\\autogluon\\core\\trainer\\abstract_trainer.py:673\u001b[0m, in \u001b[0;36mAbstractTrainer.stack_new_level_core\u001b[1;34m(self, X, y, models, X_val, y_val, X_unlabeled, level, base_model_names, stack_name, ag_args, ag_args_fit, ag_args_ensemble, included_model_types, excluded_model_types, ensemble_type, name_suffix, get_models_func, refit_full, infer_limit, infer_limit_batch_size, **kwargs)\u001b[0m\n\u001b[0;32m    670\u001b[0m fit_kwargs \u001b[39m=\u001b[39m \u001b[39mdict\u001b[39m(num_classes\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnum_classes)\n\u001b[0;32m    672\u001b[0m \u001b[39m# FIXME: TODO: v0.1 X_unlabeled isn't cached so it won't be available during refit_full or fit_extra.\u001b[39;00m\n\u001b[1;32m--> 673\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_train_multi(\n\u001b[0;32m    674\u001b[0m     X\u001b[39m=\u001b[39;49mX_init,\n\u001b[0;32m    675\u001b[0m     y\u001b[39m=\u001b[39;49my,\n\u001b[0;32m    676\u001b[0m     X_val\u001b[39m=\u001b[39;49mX_val,\n\u001b[0;32m    677\u001b[0m     y_val\u001b[39m=\u001b[39;49my_val,\n\u001b[0;32m    678\u001b[0m     X_unlabeled\u001b[39m=\u001b[39;49mX_unlabeled,\n\u001b[0;32m    679\u001b[0m     models\u001b[39m=\u001b[39;49mmodels,\n\u001b[0;32m    680\u001b[0m     level\u001b[39m=\u001b[39;49mlevel,\n\u001b[0;32m    681\u001b[0m     stack_name\u001b[39m=\u001b[39;49mstack_name,\n\u001b[0;32m    682\u001b[0m     compute_score\u001b[39m=\u001b[39;49mcompute_score,\n\u001b[0;32m    683\u001b[0m     fit_kwargs\u001b[39m=\u001b[39;49mfit_kwargs,\n\u001b[0;32m    684\u001b[0m     \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs,\n\u001b[0;32m    685\u001b[0m )\n",
            "File \u001b[1;32mc:\\Users\\ineeji\\anaconda3\\envs\\v1\\lib\\site-packages\\autogluon\\core\\trainer\\abstract_trainer.py:2321\u001b[0m, in \u001b[0;36mAbstractTrainer._train_multi\u001b[1;34m(self, X, y, models, hyperparameter_tune_kwargs, feature_prune_kwargs, k_fold, n_repeats, n_repeat_start, time_limit, **kwargs)\u001b[0m\n\u001b[0;32m   2319\u001b[0m \u001b[39mif\u001b[39;00m n_repeat_start \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[0;32m   2320\u001b[0m     time_start \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime()\n\u001b[1;32m-> 2321\u001b[0m     model_names_trained \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_train_multi_initial(\n\u001b[0;32m   2322\u001b[0m         X\u001b[39m=\u001b[39;49mX,\n\u001b[0;32m   2323\u001b[0m         y\u001b[39m=\u001b[39;49my,\n\u001b[0;32m   2324\u001b[0m         models\u001b[39m=\u001b[39;49mmodels,\n\u001b[0;32m   2325\u001b[0m         k_fold\u001b[39m=\u001b[39;49mk_fold,\n\u001b[0;32m   2326\u001b[0m         n_repeats\u001b[39m=\u001b[39;49mn_repeats_initial,\n\u001b[0;32m   2327\u001b[0m         hyperparameter_tune_kwargs\u001b[39m=\u001b[39;49mhyperparameter_tune_kwargs,\n\u001b[0;32m   2328\u001b[0m         feature_prune_kwargs\u001b[39m=\u001b[39;49mfeature_prune_kwargs,\n\u001b[0;32m   2329\u001b[0m         time_limit\u001b[39m=\u001b[39;49mtime_limit,\n\u001b[0;32m   2330\u001b[0m         \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs,\n\u001b[0;32m   2331\u001b[0m     )\n\u001b[0;32m   2332\u001b[0m     n_repeat_start \u001b[39m=\u001b[39m n_repeats_initial\n\u001b[0;32m   2333\u001b[0m     \u001b[39mif\u001b[39;00m time_limit \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
            "File \u001b[1;32mc:\\Users\\ineeji\\anaconda3\\envs\\v1\\lib\\site-packages\\autogluon\\core\\trainer\\abstract_trainer.py:2160\u001b[0m, in \u001b[0;36mAbstractTrainer._train_multi_initial\u001b[1;34m(self, X, y, models, k_fold, n_repeats, hyperparameter_tune_kwargs, time_limit, feature_prune_kwargs, **kwargs)\u001b[0m\n\u001b[0;32m   2158\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m bagged:\n\u001b[0;32m   2159\u001b[0m     time_ratio \u001b[39m=\u001b[39m hpo_time_ratio \u001b[39mif\u001b[39;00m hpo_enabled \u001b[39melse\u001b[39;00m \u001b[39m1\u001b[39m\n\u001b[1;32m-> 2160\u001b[0m     models \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_train_multi_fold(\n\u001b[0;32m   2161\u001b[0m         models\u001b[39m=\u001b[39;49mmodels,\n\u001b[0;32m   2162\u001b[0m         hyperparameter_tune_kwargs\u001b[39m=\u001b[39;49mhyperparameter_tune_kwargs,\n\u001b[0;32m   2163\u001b[0m         time_limit\u001b[39m=\u001b[39;49mtime_limit,\n\u001b[0;32m   2164\u001b[0m         time_split\u001b[39m=\u001b[39;49mtime_split,\n\u001b[0;32m   2165\u001b[0m         time_ratio\u001b[39m=\u001b[39;49mtime_ratio,\n\u001b[0;32m   2166\u001b[0m         \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mfit_args,\n\u001b[0;32m   2167\u001b[0m     )\n\u001b[0;32m   2168\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   2169\u001b[0m     time_ratio \u001b[39m=\u001b[39m hpo_time_ratio \u001b[39mif\u001b[39;00m hpo_enabled \u001b[39melse\u001b[39;00m \u001b[39m1\u001b[39m\n",
            "File \u001b[1;32mc:\\Users\\ineeji\\anaconda3\\envs\\v1\\lib\\site-packages\\autogluon\\core\\trainer\\abstract_trainer.py:2278\u001b[0m, in \u001b[0;36mAbstractTrainer._train_multi_fold\u001b[1;34m(self, X, y, models, time_limit, time_split, time_ratio, hyperparameter_tune_kwargs, **kwargs)\u001b[0m\n\u001b[0;32m   2276\u001b[0m         time_start_model \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime()\n\u001b[0;32m   2277\u001b[0m         time_left \u001b[39m=\u001b[39m time_limit \u001b[39m-\u001b[39m (time_start_model \u001b[39m-\u001b[39m time_start)\n\u001b[1;32m-> 2278\u001b[0m model_name_trained_lst \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_train_single_full(\n\u001b[0;32m   2279\u001b[0m     X, y, model, time_limit\u001b[39m=\u001b[39;49mtime_left, hyperparameter_tune_kwargs\u001b[39m=\u001b[39;49mhyperparameter_tune_kwargs_model, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs\n\u001b[0;32m   2280\u001b[0m )\n\u001b[0;32m   2282\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlow_memory:\n\u001b[0;32m   2283\u001b[0m     \u001b[39mdel\u001b[39;00m model\n",
            "File \u001b[1;32mc:\\Users\\ineeji\\anaconda3\\envs\\v1\\lib\\site-packages\\autogluon\\core\\trainer\\abstract_trainer.py:2051\u001b[0m, in \u001b[0;36mAbstractTrainer._train_single_full\u001b[1;34m(self, X, y, model, X_unlabeled, X_val, y_val, X_pseudo, y_pseudo, feature_prune, hyperparameter_tune_kwargs, stack_name, k_fold, k_fold_start, k_fold_end, n_repeats, n_repeat_start, level, time_limit, fit_kwargs, compute_score, total_resources, **kwargs)\u001b[0m\n\u001b[0;32m   2047\u001b[0m         bagged_model_fit_kwargs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_get_bagged_model_fit_kwargs(\n\u001b[0;32m   2048\u001b[0m             k_fold\u001b[39m=\u001b[39mk_fold, k_fold_start\u001b[39m=\u001b[39mk_fold_start, k_fold_end\u001b[39m=\u001b[39mk_fold_end, n_repeats\u001b[39m=\u001b[39mn_repeats, n_repeat_start\u001b[39m=\u001b[39mn_repeat_start\n\u001b[0;32m   2049\u001b[0m         )\n\u001b[0;32m   2050\u001b[0m         model_fit_kwargs\u001b[39m.\u001b[39mupdate(bagged_model_fit_kwargs)\n\u001b[1;32m-> 2051\u001b[0m     model_names_trained \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_train_and_save(\n\u001b[0;32m   2052\u001b[0m         X\u001b[39m=\u001b[39;49mX,\n\u001b[0;32m   2053\u001b[0m         y\u001b[39m=\u001b[39;49my,\n\u001b[0;32m   2054\u001b[0m         model\u001b[39m=\u001b[39;49mmodel,\n\u001b[0;32m   2055\u001b[0m         X_val\u001b[39m=\u001b[39;49mX_val,\n\u001b[0;32m   2056\u001b[0m         y_val\u001b[39m=\u001b[39;49my_val,\n\u001b[0;32m   2057\u001b[0m         X_unlabeled\u001b[39m=\u001b[39;49mX_unlabeled,\n\u001b[0;32m   2058\u001b[0m         stack_name\u001b[39m=\u001b[39;49mstack_name,\n\u001b[0;32m   2059\u001b[0m         level\u001b[39m=\u001b[39;49mlevel,\n\u001b[0;32m   2060\u001b[0m         compute_score\u001b[39m=\u001b[39;49mcompute_score,\n\u001b[0;32m   2061\u001b[0m         total_resources\u001b[39m=\u001b[39;49mtotal_resources,\n\u001b[0;32m   2062\u001b[0m         \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mmodel_fit_kwargs,\n\u001b[0;32m   2063\u001b[0m     )\n\u001b[0;32m   2064\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msave()\n\u001b[0;32m   2065\u001b[0m \u001b[39mreturn\u001b[39;00m model_names_trained\n",
            "File \u001b[1;32mc:\\Users\\ineeji\\anaconda3\\envs\\v1\\lib\\site-packages\\autogluon\\core\\trainer\\abstract_trainer.py:1733\u001b[0m, in \u001b[0;36mAbstractTrainer._train_and_save\u001b[1;34m(self, X, y, model, X_val, y_val, stack_name, level, compute_score, total_resources, **model_fit_kwargs)\u001b[0m\n\u001b[0;32m   1731\u001b[0m     model \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_train_single(X_w_pseudo, y_w_pseudo, model, X_val, y_val, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mmodel_fit_kwargs)\n\u001b[0;32m   1732\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m-> 1733\u001b[0m     model \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_train_single(X, y, model, X_val, y_val, total_resources\u001b[39m=\u001b[39;49mtotal_resources, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mmodel_fit_kwargs)\n\u001b[0;32m   1735\u001b[0m fit_end_time \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime()\n\u001b[0;32m   1736\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mweight_evaluation:\n",
            "File \u001b[1;32mc:\\Users\\ineeji\\anaconda3\\envs\\v1\\lib\\site-packages\\autogluon\\core\\trainer\\abstract_trainer.py:1684\u001b[0m, in \u001b[0;36mAbstractTrainer._train_single\u001b[1;34m(self, X, y, model, X_val, y_val, total_resources, **model_fit_kwargs)\u001b[0m\n\u001b[0;32m   1679\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_train_single\u001b[39m(\u001b[39mself\u001b[39m, X, y, model: AbstractModel, X_val\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, y_val\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, total_resources\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mmodel_fit_kwargs) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m AbstractModel:\n\u001b[0;32m   1680\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m   1681\u001b[0m \u001b[39m    Trains model but does not add the trained model to this Trainer.\u001b[39;00m\n\u001b[0;32m   1682\u001b[0m \u001b[39m    Returns trained model object.\u001b[39;00m\n\u001b[0;32m   1683\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 1684\u001b[0m     model \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39;49mfit(X\u001b[39m=\u001b[39;49mX, y\u001b[39m=\u001b[39;49my, X_val\u001b[39m=\u001b[39;49mX_val, y_val\u001b[39m=\u001b[39;49my_val, total_resources\u001b[39m=\u001b[39;49mtotal_resources, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mmodel_fit_kwargs)\n\u001b[0;32m   1685\u001b[0m     \u001b[39mreturn\u001b[39;00m model\n",
            "File \u001b[1;32mc:\\Users\\ineeji\\anaconda3\\envs\\v1\\lib\\site-packages\\autogluon\\core\\models\\abstract\\abstract_model.py:829\u001b[0m, in \u001b[0;36mAbstractModel.fit\u001b[1;34m(self, **kwargs)\u001b[0m\n\u001b[0;32m    827\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mvalidate_fit_resources(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    828\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_validate_fit_memory_usage(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m--> 829\u001b[0m out \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_fit(\u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m    830\u001b[0m \u001b[39mif\u001b[39;00m out \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    831\u001b[0m     out \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\n",
            "File \u001b[1;32mc:\\Users\\ineeji\\anaconda3\\envs\\v1\\lib\\site-packages\\autogluon\\tabular\\models\\lgb\\lgb_model.py:194\u001b[0m, in \u001b[0;36mLGBModel._fit\u001b[1;34m(self, X, y, X_val, y_val, time_limit, num_gpus, num_cpus, sample_weight, sample_weight_val, verbosity, **kwargs)\u001b[0m\n\u001b[0;32m    192\u001b[0m warnings\u001b[39m.\u001b[39mfilterwarnings(\u001b[39m\"\u001b[39m\u001b[39mignore\u001b[39m\u001b[39m\"\u001b[39m, message\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mcategorical_column in param dict is overridden.\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m    193\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 194\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel \u001b[39m=\u001b[39m train_lgb_model(early_stopping_callback_kwargs\u001b[39m=\u001b[39;49mearly_stopping_callback_kwargs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mtrain_params)\n\u001b[0;32m    195\u001b[0m \u001b[39mexcept\u001b[39;00m LightGBMError:\n\u001b[0;32m    196\u001b[0m     \u001b[39mif\u001b[39;00m train_params[\u001b[39m\"\u001b[39m\u001b[39mparams\u001b[39m\u001b[39m\"\u001b[39m]\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mdevice\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mcpu\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39m!=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mgpu\u001b[39m\u001b[39m\"\u001b[39m:\n",
            "File \u001b[1;32mc:\\Users\\ineeji\\anaconda3\\envs\\v1\\lib\\site-packages\\autogluon\\tabular\\models\\lgb\\lgb_utils.py:124\u001b[0m, in \u001b[0;36mtrain_lgb_model\u001b[1;34m(early_stopping_callback_kwargs, **train_params)\u001b[0m\n\u001b[0;32m    122\u001b[0m     \u001b[39mreturn\u001b[39;00m booster\u001b[39m.\u001b[39mfit(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mtrain_params)\n\u001b[0;32m    123\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 124\u001b[0m     \u001b[39mreturn\u001b[39;00m lgb\u001b[39m.\u001b[39;49mtrain(\u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mtrain_params)\n",
            "File \u001b[1;32mc:\\Users\\ineeji\\anaconda3\\envs\\v1\\lib\\site-packages\\lightgbm\\engine.py:292\u001b[0m, in \u001b[0;36mtrain\u001b[1;34m(params, train_set, num_boost_round, valid_sets, valid_names, fobj, feval, init_model, feature_name, categorical_feature, early_stopping_rounds, evals_result, verbose_eval, learning_rates, keep_training_booster, callbacks)\u001b[0m\n\u001b[0;32m    284\u001b[0m \u001b[39mfor\u001b[39;00m cb \u001b[39min\u001b[39;00m callbacks_before_iter:\n\u001b[0;32m    285\u001b[0m     cb(callback\u001b[39m.\u001b[39mCallbackEnv(model\u001b[39m=\u001b[39mbooster,\n\u001b[0;32m    286\u001b[0m                             params\u001b[39m=\u001b[39mparams,\n\u001b[0;32m    287\u001b[0m                             iteration\u001b[39m=\u001b[39mi,\n\u001b[0;32m    288\u001b[0m                             begin_iteration\u001b[39m=\u001b[39minit_iteration,\n\u001b[0;32m    289\u001b[0m                             end_iteration\u001b[39m=\u001b[39minit_iteration \u001b[39m+\u001b[39m num_boost_round,\n\u001b[0;32m    290\u001b[0m                             evaluation_result_list\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m))\n\u001b[1;32m--> 292\u001b[0m booster\u001b[39m.\u001b[39;49mupdate(fobj\u001b[39m=\u001b[39;49mfobj)\n\u001b[0;32m    294\u001b[0m evaluation_result_list \u001b[39m=\u001b[39m []\n\u001b[0;32m    295\u001b[0m \u001b[39m# check evaluation result.\u001b[39;00m\n",
            "File \u001b[1;32mc:\\Users\\ineeji\\anaconda3\\envs\\v1\\lib\\site-packages\\lightgbm\\basic.py:3021\u001b[0m, in \u001b[0;36mBooster.update\u001b[1;34m(self, train_set, fobj)\u001b[0m\n\u001b[0;32m   3019\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m__set_objective_to_none:\n\u001b[0;32m   3020\u001b[0m     \u001b[39mraise\u001b[39;00m LightGBMError(\u001b[39m'\u001b[39m\u001b[39mCannot update due to null objective function.\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m-> 3021\u001b[0m _safe_call(_LIB\u001b[39m.\u001b[39;49mLGBM_BoosterUpdateOneIter(\n\u001b[0;32m   3022\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mhandle,\n\u001b[0;32m   3023\u001b[0m     ctypes\u001b[39m.\u001b[39;49mbyref(is_finished)))\n\u001b[0;32m   3024\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m__is_predicted_cur_iter \u001b[39m=\u001b[39m [\u001b[39mFalse\u001b[39;00m \u001b[39mfor\u001b[39;00m _ \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m__num_dataset)]\n\u001b[0;32m   3025\u001b[0m \u001b[39mreturn\u001b[39;00m is_finished\u001b[39m.\u001b[39mvalue \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m\n",
            "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "from autogluon.tabular import TabularDataset, TabularPredictor\n",
        "\n",
        "train_data = TabularDataset(train)\n",
        "test_data = TabularDataset(test)\n",
        "\n",
        "\n",
        "predictor = TabularPredictor(label='CI_HOUR',  eval_metric='mean_absolute_error').fit(train, presets='medium_quality',  ag_args_fit={'num_gpus': 0})\n",
        "predictor.leaderboard(train, silent=True)\n",
        "\n",
        "\n",
        "y_pred = predictor.predict(test_data)\n",
        "y_pred = pd.DataFrame(y_pred, columns=['CI_HOUR'])\n",
        "submission['CI_HOUR'] = y_pred['CI_HOUR']\n",
        "predictor.leaderboard(train, silent=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "predictor.leaderboard(train, silent=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "submission.to_csv('base.csv',index=False)\n",
        "submission"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Mljar"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "AutoML directory: AutoML_7\n",
            "The task is regression with evaluation metric user_defined_metric\n",
            "AutoML will use algorithms: ['LightGBM', 'Xgboost', 'CatBoost']\n",
            "AutoML will stack models\n",
            "AutoML will ensemble available models\n",
            "AutoML steps: ['adjust_validation', 'simple_algorithms', 'default_algorithms', 'not_so_random', 'mix_encoding', 'golden_features', 'kmeans_features', 'insert_random_feature', 'features_selection', 'hill_climbing_1', 'hill_climbing_2', 'boost_on_errors', 'ensemble', 'stack', 'ensemble_stacked']\n",
            "* Step adjust_validation will try to check up to 1 model\n",
            "1_DecisionTree user_defined_metric 62.792915 trained in 16.24 seconds\n",
            "Disable stacking for split validation\n",
            "Skip simple_algorithms because no parameters were generated.\n",
            "* Step default_algorithms will try to check up to 3 models\n",
            "There was an error during 2_Default_LightGBM training.\n",
            "Please check AutoML_7\\errors.md for details.\n",
            "* Step not_so_random will try to check up to 27 models\n",
            "There was an error during 11_LightGBM training.\n",
            "Please check AutoML_7\\errors.md for details.\n",
            "Skip mix_encoding because no parameters were generated.\n",
            "Skip golden_features because no parameters were generated.\n",
            "'score' Traceback (most recent call last):\n",
            "  File \"c:\\Users\\ineeji\\anaconda3\\envs\\v1\\lib\\site-packages\\supervised\\tuner\\mljar_tuner.py\", line 225, in generate_params\n",
            "    return self.get_kmeans_features_params(\n",
            "  File \"c:\\Users\\ineeji\\anaconda3\\envs\\v1\\lib\\site-packages\\supervised\\tuner\\mljar_tuner.py\", line 1188, in get_kmeans_features_params\n",
            "    df_models, algorithms = self.df_models_algorithms(\n",
            "  File \"c:\\Users\\ineeji\\anaconda3\\envs\\v1\\lib\\site-packages\\supervised\\tuner\\mljar_tuner.py\", line 1113, in df_models_algorithms\n",
            "    df_models.sort_values(by=\"score\", ascending=True, inplace=True)\n",
            "  File \"c:\\Users\\ineeji\\anaconda3\\envs\\v1\\lib\\site-packages\\pandas\\core\\frame.py\", line 6758, in sort_values\n",
            "    k = self._get_label_or_level_values(by, axis=axis)\n",
            "  File \"c:\\Users\\ineeji\\anaconda3\\envs\\v1\\lib\\site-packages\\pandas\\core\\generic.py\", line 1778, in _get_label_or_level_values\n",
            "    raise KeyError(key)\n",
            "KeyError: 'score'\n",
            "\n",
            "Skip kmeans_features because no parameters were generated.\n",
            "Skip insert_random_feature because no parameters were generated.\n",
            "Skip features_selection because no parameters were generated.\n",
            "* Step hill_climbing_1 will try to check up to 1 model\n",
            "2_DecisionTree user_defined_metric 65.00222 trained in 22.14 seconds\n",
            "* Step hill_climbing_2 will try to check up to 1 model\n",
            "3_DecisionTree user_defined_metric 66.025871 trained in 19.02 seconds\n",
            "* Step ensemble will try to check up to 1 model\n",
            "Ensemble user_defined_metric 62.792915 trained in 0.24 seconds\n",
            "AutoML fit time: 109.18 seconds\n",
            "AutoML best model: 1_DecisionTree\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "array([7.71755289e+01, 7.71755289e+01, 5.54033668e-03, ...,\n",
              "       5.54033668e-03, 5.54033668e-03, 7.71755289e+01])"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from supervised.automl import AutoML\n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "\n",
        "'''\n",
        "automl = AutoML(\n",
        "    algorithms=[\"CatBoost\", \"Xgboost\", \"LightGBM\"],\n",
        "    model_time_limit=30*60,\n",
        "    start_random_models=10,\n",
        "    hill_climbing_steps=3,\n",
        "    top_models_to_improve=3,\n",
        "    golden_features=True,\n",
        "    features_selection=False,\n",
        "    stack_models=True,\n",
        "    train_ensemble=True,\n",
        "    explain_level=0,\n",
        "    validation_strategy={\n",
        "        \"validation_type\": \"kfold\",\n",
        "        \"k_folds\": 4,\n",
        "        \"shuffle\": False,\n",
        "        \"stratify\": True,\n",
        "    }\n",
        ")\n",
        "'''\n",
        "automl = AutoML(mode = \"Compete\",\n",
        "                algorithms = ['LightGBM', 'Xgboost', 'CatBoost'], golden_features=True,\n",
        "                ml_task = \"regression\", eval_metric=mean_absolute_error, random_state = 42, total_time_limit=100)\n",
        "\n",
        "automl.fit(train_x, train_y)\n",
        "\n",
        "predictions = automl.predict(test)\n",
        "predictions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# H2o"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# pycaret"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from pycaret.regression import *\n",
        "import category_encoders\n",
        "\n",
        "reg = setup(data=train, target='CI_HOUR', use_gpu=True, session_id=313, encoding_method=category_encoders.target_encoder.TargetEncoder(smoothing=10))\n",
        "reg.pipeline\n",
        "best = compare_models(n_select=4)\n",
        "best[2] = tune_model(best[2], optimize='MAE', n_iter=100) #lgbm\n",
        "best[3] = tune_model(best[3], optimize='MAE', n_iter=100) #xgb\n",
        "stack_lr = stack_models(best, optimize='MAE', choose_better=True)\n",
        "stack_finalized = finalize_model(stack_lr)\n",
        "predictions['CI_HOUR'] = stack_finalized.predict(test)\n",
        "predictions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# XGB"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [],
      "source": [
        "from xgboost import XGBRegressor\n",
        "#import xgboost as xgb\n",
        "import optuna\n",
        "from optuna import Trial\n",
        "from optuna.samplers import TPESampler\n",
        "from xgboost import XGBRegressor\n",
        "from sklearn.metrics import mean_absolute_error\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_squared_error\n",
        "import numpy as np\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "def objective(trial: Trial, X_train, y_train, X_val, y_val):\n",
        "    params = {\n",
        "            'iterations':trial.suggest_int(\"iterations\", 300, 1000),\n",
        "            'learning_rate' : trial.suggest_uniform('learning_rate',0.1, 1),\n",
        "            'depth': trial.suggest_int('depth',5, 16),\n",
        "            'min_data_in_leaf': trial.suggest_int('min_data_in_leaf',1,30),\n",
        "            'reg_lambda': trial.suggest_uniform('reg_lambda',30,100),\n",
        "            'subsample': trial.suggest_uniform('subsample',0.3,1),\n",
        "            'random_strength': trial.suggest_uniform('random_strength',10,100),\n",
        "            'od_wait':trial.suggest_int('od_wait', 10, 150),\n",
        "            'leaf_estimation_iterations': trial.suggest_int('leaf_estimation_iterations',1,20),\n",
        "            'bagging_temperature' :trial.suggest_loguniform('bagging_temperature', 1, 100),\n",
        "            \"colsample_bylevel\": trial.suggest_float(\"colsample_bylevel\", 0., 1.0),\n",
        "            'random_state' : 9555,\n",
        "            'verbose' : 0,\n",
        "        }\n",
        "    #'task_type' : 'GPU',\n",
        "    #\"eval_metric\":'RMSE',\n",
        "    cat = CatBoostRegressor(**params)\n",
        "    cat.fit(X_train, y_train, eval_set=[(X_train,y_train),(X_val,y_val)],cat_features=cat_features,\n",
        "              verbose=False)\n",
        "    cat_pred = cat.predict(X_val)\n",
        "    score = mean_absolute_error(y_val, cat_pred)\n",
        "    return score\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "import bisect\n",
        "'''\n",
        "# Categorical 컬럼 인코딩\n",
        "categorical_features = ['ARI_CO', 'ARI_PO', 'SHIP_TYPE_CATEGORY', 'ID', 'SHIPMANAGER', 'FLAG']\n",
        "encoders = {}\n",
        "\n",
        "for feature in tqdm(categorical_features, desc=\"Encoding features\"):\n",
        "    le = LabelEncoder()\n",
        "    train[feature] = le.fit_transform(train[feature].astype(str))\n",
        "    le_classes_set = set(le.classes_)\n",
        "    test[feature] = test[feature].map(lambda s: '-1' if s not in le_classes_set else s)\n",
        "    le_classes = le.classes_.tolist()\n",
        "    bisect.insort_left(le_classes, '-1')\n",
        "    le.classes_ = np.array(le_classes)\n",
        "    test[feature] = le.transform(test[feature].astype(str))\n",
        "    encoders[feature] = le\n",
        "cat_features = ['ARI_CO', 'ARI_PO', 'SHIP_TYPE_CATEGORY', 'ID', 'SHIPMANAGER', 'FLAG']\n",
        "\n",
        "# 결측치 처리\n",
        "train_x.fillna(train_x.mean(), inplace=True)\n",
        "test.fillna(train_x.mean(), inplace=True)\n",
        "'''\n",
        "cat_features = ['ARI_CO', 'ARI_PO', 'SHIP_TYPE_CATEGORY', 'ID', 'SHIPMANAGER', 'FLAG']\n",
        "# 수치형 변수만 대상으로 결측치 대체\n",
        "numeric_cols = train_x.select_dtypes(include=[np.number]).columns\n",
        "\n",
        "# 훈련 데이터의 평균 계산\n",
        "mean_values = train_x[numeric_cols].mean()\n",
        "\n",
        "# 결측치 대체\n",
        "train_x[numeric_cols] = train_x[numeric_cols].fillna(mean_values)\n",
        "test[numeric_cols] = test[numeric_cols].fillna(mean_values)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2023-10-05 22:57:32,559] A new study created in memory with name: no-name-9bac196a-a60b-465e-951f-a59786c40290\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Optimizing hyperparameters for fold 1...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2023-10-05 23:00:06,429] Trial 0 finished with value: 61.04548939421835 and parameters: {'iterations': 434, 'learning_rate': 0.6598978939358486, 'depth': 10, 'min_data_in_leaf': 24, 'reg_lambda': 84.59830656831625, 'subsample': 0.4908148236978491, 'random_strength': 34.8817829628787, 'od_wait': 123, 'leaf_estimation_iterations': 20, 'bagging_temperature': 56.47617424572882, 'colsample_bylevel': 0.35781726995786667}. Best is trial 0 with value: 61.04548939421835.\n",
            "[I 2023-10-05 23:05:21,120] Trial 1 finished with value: 68.16594682071415 and parameters: {'iterations': 651, 'learning_rate': 0.7151166416549226, 'depth': 13, 'min_data_in_leaf': 12, 'reg_lambda': 69.28373302459374, 'subsample': 0.6521582157154668, 'random_strength': 11.2391604631614, 'od_wait': 118, 'leaf_estimation_iterations': 18, 'bagging_temperature': 5.367498945698209, 'colsample_bylevel': 0.6153961784334937}. Best is trial 0 with value: 61.04548939421835.\n",
            "[W 2023-10-05 23:10:07,354] Trial 2 failed with parameters: {'iterations': 352, 'learning_rate': 0.43194160540177706, 'depth': 16, 'min_data_in_leaf': 20, 'reg_lambda': 57.80418044083079, 'subsample': 0.8521111000585218, 'random_strength': 38.515250995198414, 'od_wait': 90, 'leaf_estimation_iterations': 18, 'bagging_temperature': 7.45326989102335, 'colsample_bylevel': 0.8021476420801591} because of the following error: KeyboardInterrupt('').\n",
            "Traceback (most recent call last):\n",
            "  File \"c:\\Users\\ineeji\\anaconda3\\envs\\v1\\lib\\site-packages\\optuna\\study\\_optimize.py\", line 200, in _run_trial\n",
            "    value_or_values = func(trial)\n",
            "  File \"C:\\Users\\ineeji\\AppData\\Local\\Temp\\ipykernel_50720\\3045383138.py\", line 15, in <lambda>\n",
            "    study.optimize(lambda trial: objective(trial, X_train, y_train, X_val, y_val.values), n_trials=20)\n",
            "  File \"C:\\Users\\ineeji\\AppData\\Local\\Temp\\ipykernel_50720\\4085348997.py\", line 33, in objective\n",
            "    cat.fit(X_train, y_train, eval_set=[(X_train,y_train),(X_val,y_val)],cat_features=cat_features,\n",
            "  File \"c:\\Users\\ineeji\\anaconda3\\envs\\v1\\lib\\site-packages\\catboost\\core.py\", line 5734, in fit\n",
            "    return self._fit(X, y, cat_features, text_features, embedding_features, None, sample_weight, None, None, None, None, baseline,\n",
            "  File \"c:\\Users\\ineeji\\anaconda3\\envs\\v1\\lib\\site-packages\\catboost\\core.py\", line 2357, in _fit\n",
            "    self._train(\n",
            "  File \"c:\\Users\\ineeji\\anaconda3\\envs\\v1\\lib\\site-packages\\catboost\\core.py\", line 1761, in _train\n",
            "    self._object._train(train_pool, test_pool, params, allow_clear_pool, init_model._object if init_model else None)\n",
            "  File \"_catboost.pyx\", line 4624, in _catboost._CatBoost._train\n",
            "  File \"_catboost.pyx\", line 4673, in _catboost._CatBoost._train\n",
            "KeyboardInterrupt\n",
            "[W 2023-10-05 23:10:07,363] Trial 2 failed with value None.\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[1;32mc:\\Users\\ineeji\\Desktop\\HD\\XGB_v1.ipynb Cell 20\u001b[0m line \u001b[0;36m1\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/ineeji/Desktop/HD/XGB_v1.ipynb#X33sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mOptimizing hyperparameters for fold \u001b[39m\u001b[39m{\u001b[39;00mfold\u001b[39m+\u001b[39m\u001b[39m1\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m...\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/ineeji/Desktop/HD/XGB_v1.ipynb#X33sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m study \u001b[39m=\u001b[39m optuna\u001b[39m.\u001b[39mcreate_study(direction\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mminimize\u001b[39m\u001b[39m'\u001b[39m, sampler\u001b[39m=\u001b[39mTPESampler(seed\u001b[39m=\u001b[39m\u001b[39m1234\u001b[39m))\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/ineeji/Desktop/HD/XGB_v1.ipynb#X33sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m study\u001b[39m.\u001b[39;49moptimize(\u001b[39mlambda\u001b[39;49;00m trial: objective(trial, X_train, y_train, X_val, y_val\u001b[39m.\u001b[39;49mvalues), n_trials\u001b[39m=\u001b[39;49m\u001b[39m20\u001b[39;49m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/ineeji/Desktop/HD/XGB_v1.ipynb#X33sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m best_params \u001b[39m=\u001b[39m study\u001b[39m.\u001b[39mbest_params\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/ineeji/Desktop/HD/XGB_v1.ipynb#X33sZmlsZQ%3D%3D?line=17'>18</a>\u001b[0m best_score \u001b[39m=\u001b[39m study\u001b[39m.\u001b[39mbest_value\n",
            "File \u001b[1;32mc:\\Users\\ineeji\\anaconda3\\envs\\v1\\lib\\site-packages\\optuna\\study\\study.py:443\u001b[0m, in \u001b[0;36mStudy.optimize\u001b[1;34m(self, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[0;32m    339\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39moptimize\u001b[39m(\n\u001b[0;32m    340\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[0;32m    341\u001b[0m     func: ObjectiveFuncType,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    348\u001b[0m     show_progress_bar: \u001b[39mbool\u001b[39m \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m,\n\u001b[0;32m    349\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    350\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Optimize an objective function.\u001b[39;00m\n\u001b[0;32m    351\u001b[0m \n\u001b[0;32m    352\u001b[0m \u001b[39m    Optimization is done by choosing a suitable set of hyperparameter values from a given\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    440\u001b[0m \u001b[39m            If nested invocation of this method occurs.\u001b[39;00m\n\u001b[0;32m    441\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 443\u001b[0m     _optimize(\n\u001b[0;32m    444\u001b[0m         study\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m,\n\u001b[0;32m    445\u001b[0m         func\u001b[39m=\u001b[39;49mfunc,\n\u001b[0;32m    446\u001b[0m         n_trials\u001b[39m=\u001b[39;49mn_trials,\n\u001b[0;32m    447\u001b[0m         timeout\u001b[39m=\u001b[39;49mtimeout,\n\u001b[0;32m    448\u001b[0m         n_jobs\u001b[39m=\u001b[39;49mn_jobs,\n\u001b[0;32m    449\u001b[0m         catch\u001b[39m=\u001b[39;49m\u001b[39mtuple\u001b[39;49m(catch) \u001b[39mif\u001b[39;49;00m \u001b[39misinstance\u001b[39;49m(catch, Iterable) \u001b[39melse\u001b[39;49;00m (catch,),\n\u001b[0;32m    450\u001b[0m         callbacks\u001b[39m=\u001b[39;49mcallbacks,\n\u001b[0;32m    451\u001b[0m         gc_after_trial\u001b[39m=\u001b[39;49mgc_after_trial,\n\u001b[0;32m    452\u001b[0m         show_progress_bar\u001b[39m=\u001b[39;49mshow_progress_bar,\n\u001b[0;32m    453\u001b[0m     )\n",
            "File \u001b[1;32mc:\\Users\\ineeji\\anaconda3\\envs\\v1\\lib\\site-packages\\optuna\\study\\_optimize.py:66\u001b[0m, in \u001b[0;36m_optimize\u001b[1;34m(study, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[0;32m     64\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m     65\u001b[0m     \u001b[39mif\u001b[39;00m n_jobs \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[1;32m---> 66\u001b[0m         _optimize_sequential(\n\u001b[0;32m     67\u001b[0m             study,\n\u001b[0;32m     68\u001b[0m             func,\n\u001b[0;32m     69\u001b[0m             n_trials,\n\u001b[0;32m     70\u001b[0m             timeout,\n\u001b[0;32m     71\u001b[0m             catch,\n\u001b[0;32m     72\u001b[0m             callbacks,\n\u001b[0;32m     73\u001b[0m             gc_after_trial,\n\u001b[0;32m     74\u001b[0m             reseed_sampler_rng\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[0;32m     75\u001b[0m             time_start\u001b[39m=\u001b[39;49m\u001b[39mNone\u001b[39;49;00m,\n\u001b[0;32m     76\u001b[0m             progress_bar\u001b[39m=\u001b[39;49mprogress_bar,\n\u001b[0;32m     77\u001b[0m         )\n\u001b[0;32m     78\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m     79\u001b[0m         \u001b[39mif\u001b[39;00m n_jobs \u001b[39m==\u001b[39m \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m:\n",
            "File \u001b[1;32mc:\\Users\\ineeji\\anaconda3\\envs\\v1\\lib\\site-packages\\optuna\\study\\_optimize.py:163\u001b[0m, in \u001b[0;36m_optimize_sequential\u001b[1;34m(study, func, n_trials, timeout, catch, callbacks, gc_after_trial, reseed_sampler_rng, time_start, progress_bar)\u001b[0m\n\u001b[0;32m    160\u001b[0m         \u001b[39mbreak\u001b[39;00m\n\u001b[0;32m    162\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 163\u001b[0m     frozen_trial \u001b[39m=\u001b[39m _run_trial(study, func, catch)\n\u001b[0;32m    164\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[0;32m    165\u001b[0m     \u001b[39m# The following line mitigates memory problems that can be occurred in some\u001b[39;00m\n\u001b[0;32m    166\u001b[0m     \u001b[39m# environments (e.g., services that use computing containers such as GitHub Actions).\u001b[39;00m\n\u001b[0;32m    167\u001b[0m     \u001b[39m# Please refer to the following PR for further details:\u001b[39;00m\n\u001b[0;32m    168\u001b[0m     \u001b[39m# https://github.com/optuna/optuna/pull/325.\u001b[39;00m\n\u001b[0;32m    169\u001b[0m     \u001b[39mif\u001b[39;00m gc_after_trial:\n",
            "File \u001b[1;32mc:\\Users\\ineeji\\anaconda3\\envs\\v1\\lib\\site-packages\\optuna\\study\\_optimize.py:251\u001b[0m, in \u001b[0;36m_run_trial\u001b[1;34m(study, func, catch)\u001b[0m\n\u001b[0;32m    244\u001b[0m         \u001b[39massert\u001b[39;00m \u001b[39mFalse\u001b[39;00m, \u001b[39m\"\u001b[39m\u001b[39mShould not reach.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    246\u001b[0m \u001b[39mif\u001b[39;00m (\n\u001b[0;32m    247\u001b[0m     frozen_trial\u001b[39m.\u001b[39mstate \u001b[39m==\u001b[39m TrialState\u001b[39m.\u001b[39mFAIL\n\u001b[0;32m    248\u001b[0m     \u001b[39mand\u001b[39;00m func_err \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m    249\u001b[0m     \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(func_err, catch)\n\u001b[0;32m    250\u001b[0m ):\n\u001b[1;32m--> 251\u001b[0m     \u001b[39mraise\u001b[39;00m func_err\n\u001b[0;32m    252\u001b[0m \u001b[39mreturn\u001b[39;00m frozen_trial\n",
            "File \u001b[1;32mc:\\Users\\ineeji\\anaconda3\\envs\\v1\\lib\\site-packages\\optuna\\study\\_optimize.py:200\u001b[0m, in \u001b[0;36m_run_trial\u001b[1;34m(study, func, catch)\u001b[0m\n\u001b[0;32m    198\u001b[0m \u001b[39mwith\u001b[39;00m get_heartbeat_thread(trial\u001b[39m.\u001b[39m_trial_id, study\u001b[39m.\u001b[39m_storage):\n\u001b[0;32m    199\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 200\u001b[0m         value_or_values \u001b[39m=\u001b[39m func(trial)\n\u001b[0;32m    201\u001b[0m     \u001b[39mexcept\u001b[39;00m exceptions\u001b[39m.\u001b[39mTrialPruned \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    202\u001b[0m         \u001b[39m# TODO(mamu): Handle multi-objective cases.\u001b[39;00m\n\u001b[0;32m    203\u001b[0m         state \u001b[39m=\u001b[39m TrialState\u001b[39m.\u001b[39mPRUNED\n",
            "\u001b[1;32mc:\\Users\\ineeji\\Desktop\\HD\\XGB_v1.ipynb Cell 20\u001b[0m line \u001b[0;36m1\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/ineeji/Desktop/HD/XGB_v1.ipynb#X33sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mOptimizing hyperparameters for fold \u001b[39m\u001b[39m{\u001b[39;00mfold\u001b[39m+\u001b[39m\u001b[39m1\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m...\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/ineeji/Desktop/HD/XGB_v1.ipynb#X33sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m study \u001b[39m=\u001b[39m optuna\u001b[39m.\u001b[39mcreate_study(direction\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mminimize\u001b[39m\u001b[39m'\u001b[39m, sampler\u001b[39m=\u001b[39mTPESampler(seed\u001b[39m=\u001b[39m\u001b[39m1234\u001b[39m))\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/ineeji/Desktop/HD/XGB_v1.ipynb#X33sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m study\u001b[39m.\u001b[39moptimize(\u001b[39mlambda\u001b[39;00m trial: objective(trial, X_train, y_train, X_val, y_val\u001b[39m.\u001b[39;49mvalues), n_trials\u001b[39m=\u001b[39m\u001b[39m20\u001b[39m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/ineeji/Desktop/HD/XGB_v1.ipynb#X33sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m best_params \u001b[39m=\u001b[39m study\u001b[39m.\u001b[39mbest_params\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/ineeji/Desktop/HD/XGB_v1.ipynb#X33sZmlsZQ%3D%3D?line=17'>18</a>\u001b[0m best_score \u001b[39m=\u001b[39m study\u001b[39m.\u001b[39mbest_value\n",
            "\u001b[1;32mc:\\Users\\ineeji\\Desktop\\HD\\XGB_v1.ipynb Cell 20\u001b[0m line \u001b[0;36m3\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/ineeji/Desktop/HD/XGB_v1.ipynb#X33sZmlsZQ%3D%3D?line=29'>30</a>\u001b[0m \u001b[39m#'task_type' : 'GPU',\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/ineeji/Desktop/HD/XGB_v1.ipynb#X33sZmlsZQ%3D%3D?line=30'>31</a>\u001b[0m \u001b[39m#\"eval_metric\":'RMSE',\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/ineeji/Desktop/HD/XGB_v1.ipynb#X33sZmlsZQ%3D%3D?line=31'>32</a>\u001b[0m cat \u001b[39m=\u001b[39m CatBoostRegressor(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mparams)\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/ineeji/Desktop/HD/XGB_v1.ipynb#X33sZmlsZQ%3D%3D?line=32'>33</a>\u001b[0m cat\u001b[39m.\u001b[39;49mfit(X_train, y_train, eval_set\u001b[39m=\u001b[39;49m[(X_train,y_train),(X_val,y_val)],cat_features\u001b[39m=\u001b[39;49mcat_features,\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/ineeji/Desktop/HD/XGB_v1.ipynb#X33sZmlsZQ%3D%3D?line=33'>34</a>\u001b[0m           verbose\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/ineeji/Desktop/HD/XGB_v1.ipynb#X33sZmlsZQ%3D%3D?line=34'>35</a>\u001b[0m cat_pred \u001b[39m=\u001b[39m cat\u001b[39m.\u001b[39mpredict(X_val)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/ineeji/Desktop/HD/XGB_v1.ipynb#X33sZmlsZQ%3D%3D?line=35'>36</a>\u001b[0m score \u001b[39m=\u001b[39m mean_absolute_error(y_val, cat_pred)\n",
            "File \u001b[1;32mc:\\Users\\ineeji\\anaconda3\\envs\\v1\\lib\\site-packages\\catboost\\core.py:5734\u001b[0m, in \u001b[0;36mCatBoostRegressor.fit\u001b[1;34m(self, X, y, cat_features, text_features, embedding_features, sample_weight, baseline, use_best_model, eval_set, verbose, logging_level, plot, plot_file, column_description, verbose_eval, metric_period, silent, early_stopping_rounds, save_snapshot, snapshot_file, snapshot_interval, init_model, callbacks, log_cout, log_cerr)\u001b[0m\n\u001b[0;32m   5731\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39m'\u001b[39m\u001b[39mloss_function\u001b[39m\u001b[39m'\u001b[39m \u001b[39min\u001b[39;00m params:\n\u001b[0;32m   5732\u001b[0m     CatBoostRegressor\u001b[39m.\u001b[39m_check_is_compatible_loss(params[\u001b[39m'\u001b[39m\u001b[39mloss_function\u001b[39m\u001b[39m'\u001b[39m])\n\u001b[1;32m-> 5734\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_fit(X, y, cat_features, text_features, embedding_features, \u001b[39mNone\u001b[39;49;00m, sample_weight, \u001b[39mNone\u001b[39;49;00m, \u001b[39mNone\u001b[39;49;00m, \u001b[39mNone\u001b[39;49;00m, \u001b[39mNone\u001b[39;49;00m, baseline,\n\u001b[0;32m   5735\u001b[0m                  use_best_model, eval_set, verbose, logging_level, plot, plot_file, column_description,\n\u001b[0;32m   5736\u001b[0m                  verbose_eval, metric_period, silent, early_stopping_rounds,\n\u001b[0;32m   5737\u001b[0m                  save_snapshot, snapshot_file, snapshot_interval, init_model, callbacks, log_cout, log_cerr)\n",
            "File \u001b[1;32mc:\\Users\\ineeji\\anaconda3\\envs\\v1\\lib\\site-packages\\catboost\\core.py:2357\u001b[0m, in \u001b[0;36mCatBoost._fit\u001b[1;34m(self, X, y, cat_features, text_features, embedding_features, pairs, sample_weight, group_id, group_weight, subgroup_id, pairs_weight, baseline, use_best_model, eval_set, verbose, logging_level, plot, plot_file, column_description, verbose_eval, metric_period, silent, early_stopping_rounds, save_snapshot, snapshot_file, snapshot_interval, init_model, callbacks, log_cout, log_cerr)\u001b[0m\n\u001b[0;32m   2353\u001b[0m allow_clear_pool \u001b[39m=\u001b[39m train_params[\u001b[39m\"\u001b[39m\u001b[39mallow_clear_pool\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[0;32m   2355\u001b[0m \u001b[39mwith\u001b[39;00m log_fixup(log_cout, log_cerr), \\\n\u001b[0;32m   2356\u001b[0m     plot_wrapper(plot, plot_file, \u001b[39m'\u001b[39m\u001b[39mTraining plots\u001b[39m\u001b[39m'\u001b[39m, [_get_train_dir(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mget_params())]):\n\u001b[1;32m-> 2357\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_train(\n\u001b[0;32m   2358\u001b[0m         train_pool,\n\u001b[0;32m   2359\u001b[0m         train_params[\u001b[39m\"\u001b[39;49m\u001b[39meval_sets\u001b[39;49m\u001b[39m\"\u001b[39;49m],\n\u001b[0;32m   2360\u001b[0m         params,\n\u001b[0;32m   2361\u001b[0m         allow_clear_pool,\n\u001b[0;32m   2362\u001b[0m         train_params[\u001b[39m\"\u001b[39;49m\u001b[39minit_model\u001b[39;49m\u001b[39m\"\u001b[39;49m]\n\u001b[0;32m   2363\u001b[0m     )\n\u001b[0;32m   2365\u001b[0m \u001b[39m# Have property feature_importance possibly set\u001b[39;00m\n\u001b[0;32m   2366\u001b[0m loss \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_object\u001b[39m.\u001b[39m_get_loss_function_name()\n",
            "File \u001b[1;32mc:\\Users\\ineeji\\anaconda3\\envs\\v1\\lib\\site-packages\\catboost\\core.py:1761\u001b[0m, in \u001b[0;36m_CatBoostBase._train\u001b[1;34m(self, train_pool, test_pool, params, allow_clear_pool, init_model)\u001b[0m\n\u001b[0;32m   1760\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_train\u001b[39m(\u001b[39mself\u001b[39m, train_pool, test_pool, params, allow_clear_pool, init_model):\n\u001b[1;32m-> 1761\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_object\u001b[39m.\u001b[39;49m_train(train_pool, test_pool, params, allow_clear_pool, init_model\u001b[39m.\u001b[39;49m_object \u001b[39mif\u001b[39;49;00m init_model \u001b[39melse\u001b[39;49;00m \u001b[39mNone\u001b[39;49;00m)\n\u001b[0;32m   1762\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_set_trained_model_attributes()\n",
            "File \u001b[1;32m_catboost.pyx:4624\u001b[0m, in \u001b[0;36m_catboost._CatBoost._train\u001b[1;34m()\u001b[0m\n",
            "File \u001b[1;32m_catboost.pyx:4673\u001b[0m, in \u001b[0;36m_catboost._CatBoost._train\u001b[1;34m()\u001b[0m\n",
            "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "train_x = train.drop(['CI_HOUR'],axis=1)\n",
        "train_y = train[['CI_HOUR']]\n",
        "\n",
        "kf = KFold(n_splits=5, shuffle=True, random_state=3553)\n",
        "fold_results = []\n",
        "test_predictions = []\n",
        "\n",
        "# 각 Fold에 대해서 Optuna로 하이퍼파라미터 튜닝\n",
        "for fold, (train_index, val_index) in enumerate(kf.split(train_x)):\n",
        "    X_train, X_val = train_x.iloc[train_index, :], train_x.iloc[val_index, :]\n",
        "    y_train, y_val = train_y.iloc[train_index, :], train_y.iloc[val_index, :]\n",
        "\n",
        "    print(f\"Optimizing hyperparameters for fold {fold+1}...\")\n",
        "    study = optuna.create_study(direction='minimize', sampler=TPESampler(seed=1234))\n",
        "    study.optimize(lambda trial: objective(trial, X_train, y_train, X_val, y_val.values), n_trials=20)\n",
        "\n",
        "    best_params = study.best_params\n",
        "    best_score = study.best_value\n",
        "    \n",
        "    print(f\"Best RMSE for fold {fold+1}: {best_score}\")\n",
        "    print(f\"Best hyperparameters for fold {fold+1}: {best_params}\")\n",
        "    \n",
        "    fold_results.append({\n",
        "        'fold': fold+1,\n",
        "        'best_score': best_score,\n",
        "        'best_params': best_params\n",
        "    })\n",
        "    \n",
        "    # 최적의 하이퍼파라미터로 테스트 데이터 예측\n",
        "    model = CatBoostRegressor(**best_params)\n",
        "    model.fit(X_train, y_train, cat_features=cat_features)\n",
        "    test_pred = model.predict(test)\n",
        "    test_predictions.append(test_pred)\n",
        "\n",
        "# 평균 앙상블\n",
        "final_prediction = np.mean(test_predictions, axis=0)\n",
        "\n",
        "# 결과 출력\n",
        "for result in fold_results:\n",
        "    print(f\"Fold {result['fold']}, Best MAE: {result['best_score']}, Best hyperparameters: {result['best_params']}\")\n",
        "\n",
        "# 최종 예측 저장\n",
        "final_prediction_df = pd.DataFrame(final_prediction, columns=['MLM'])\n",
        "submission['CI_HOUR'] = final_prediction"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2023-10-05 18:34:50,397] A new study created in memory with name: no-name-b26d2697-0fcd-4dee-9e39-39065c14aaac\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Optimizing hyperparameters for fold 1...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2023-10-05 18:35:19,781] Trial 0 finished with value: 42.85265927112725 and parameters: {'iterations': 434, 'learning_rate': 0.6598978939358486, 'depth': 10, 'min_data_in_leaf': 24, 'reg_lambda': 84.59830656831625, 'subsample': 0.4908148236978491, 'random_strength': 34.8817829628787, 'od_wait': 123, 'leaf_estimation_iterations': 20, 'bagging_temperature': 56.47617424572882, 'colsample_bylevel': 0.35781726995786667}. Best is trial 0 with value: 42.85265927112725.\n",
            "[I 2023-10-05 18:36:53,140] Trial 1 finished with value: 48.80106549563911 and parameters: {'iterations': 651, 'learning_rate': 0.7151166416549226, 'depth': 13, 'min_data_in_leaf': 12, 'reg_lambda': 69.28373302459374, 'subsample': 0.6521582157154668, 'random_strength': 11.2391604631614, 'od_wait': 118, 'leaf_estimation_iterations': 18, 'bagging_temperature': 5.367498945698209, 'colsample_bylevel': 0.6153961784334937}. Best is trial 0 with value: 42.85265927112725.\n",
            "[I 2023-10-05 18:52:12,454] Trial 2 finished with value: 52.916567267857396 and parameters: {'iterations': 352, 'learning_rate': 0.43194160540177706, 'depth': 16, 'min_data_in_leaf': 20, 'reg_lambda': 57.80418044083079, 'subsample': 0.8521111000585218, 'random_strength': 38.515250995198414, 'od_wait': 90, 'leaf_estimation_iterations': 18, 'bagging_temperature': 7.45326989102335, 'colsample_bylevel': 0.8021476420801591}. Best is trial 0 with value: 42.85265927112725.\n",
            "[I 2023-10-05 18:53:32,691] Trial 3 finished with value: 45.59199925907557 and parameters: {'iterations': 400, 'learning_rate': 0.7338348740065018, 'depth': 13, 'min_data_in_leaf': 7, 'reg_lambda': 94.74073400308956, 'subsample': 0.6094985287829235, 'random_strength': 91.83843630752253, 'od_wait': 18, 'leaf_estimation_iterations': 4, 'bagging_temperature': 1.2436854617398172, 'colsample_bylevel': 0.6748809435823302}. Best is trial 0 with value: 42.85265927112725.\n",
            "[I 2023-10-05 18:53:58,060] Trial 4 finished with value: 40.89163353137333 and parameters: {'iterations': 716, 'learning_rate': 0.5799791466988755, 'depth': 5, 'min_data_in_leaf': 17, 'reg_lambda': 53.07679119346405, 'subsample': 0.6520767831788328, 'random_strength': 20.070488581696345, 'od_wait': 95, 'leaf_estimation_iterations': 12, 'bagging_temperature': 1.0316398840646337, 'colsample_bylevel': 0.617441708804297}. Best is trial 4 with value: 40.89163353137333.\n",
            "[I 2023-10-05 18:54:41,473] Trial 5 finished with value: 68.75757195227922 and parameters: {'iterations': 939, 'learning_rate': 0.81147171975133, 'depth': 16, 'min_data_in_leaf': 29, 'reg_lambda': 85.43748947041479, 'subsample': 0.4996756720171568, 'random_strength': 66.24250347753198, 'od_wait': 77, 'leaf_estimation_iterations': 4, 'bagging_temperature': 5.816140699158812, 'colsample_bylevel': 0.05387368514623658}. Best is trial 4 with value: 40.89163353137333.\n",
            "[I 2023-10-05 18:54:59,010] Trial 6 finished with value: 43.457078393729404 and parameters: {'iterations': 616, 'learning_rate': 0.983804267369759, 'depth': 6, 'min_data_in_leaf': 4, 'reg_lambda': 81.69661393003427, 'subsample': 0.7111125434247891, 'random_strength': 52.4469280888331, 'od_wait': 25, 'leaf_estimation_iterations': 5, 'bagging_temperature': 63.08562204066738, 'colsample_bylevel': 0.4167535378026932}. Best is trial 4 with value: 40.89163353137333.\n",
            "[I 2023-10-05 18:55:28,127] Trial 7 finished with value: 45.514597923532925 and parameters: {'iterations': 675, 'learning_rate': 0.10558766492841647, 'depth': 8, 'min_data_in_leaf': 14, 'reg_lambda': 72.85042979460303, 'subsample': 0.942738652766401, 'random_strength': 66.31630029662819, 'od_wait': 109, 'leaf_estimation_iterations': 3, 'bagging_temperature': 31.05466282532861, 'colsample_bylevel': 0.8310069924335378}. Best is trial 4 with value: 40.89163353137333.\n",
            "[I 2023-10-05 18:55:46,555] Trial 8 finished with value: 59.26679310147062 and parameters: {'iterations': 744, 'learning_rate': 0.4944788930101848, 'depth': 6, 'min_data_in_leaf': 18, 'reg_lambda': 66.97569943095424, 'subsample': 0.9660001346275151, 'random_strength': 53.23232606590145, 'od_wait': 80, 'leaf_estimation_iterations': 11, 'bagging_temperature': 43.491474724548446, 'colsample_bylevel': 0.05711563808885989}. Best is trial 4 with value: 40.89163353137333.\n",
            "[W 2023-10-05 18:56:31,876] Trial 9 failed with parameters: {'iterations': 769, 'learning_rate': 0.7904049655415252, 'depth': 13, 'min_data_in_leaf': 24, 'reg_lambda': 69.04325798992147, 'subsample': 0.9760855723944892, 'random_strength': 23.244120990369744, 'od_wait': 14, 'leaf_estimation_iterations': 12, 'bagging_temperature': 1.6909524585029, 'colsample_bylevel': 0.9508098500841222} because of the following error: KeyboardInterrupt('').\n",
            "Traceback (most recent call last):\n",
            "  File \"c:\\Users\\ineeji\\anaconda3\\envs\\v1\\lib\\site-packages\\optuna\\study\\_optimize.py\", line 200, in _run_trial\n",
            "    value_or_values = func(trial)\n",
            "  File \"C:\\Users\\ineeji\\AppData\\Local\\Temp\\ipykernel_53616\\1968957422.py\", line 15, in <lambda>\n",
            "    study.optimize(lambda trial: objective(trial, X_train, y_train, X_val, y_val.values), n_trials=20)\n",
            "  File \"C:\\Users\\ineeji\\AppData\\Local\\Temp\\ipykernel_53616\\1286444639.py\", line 56, in objective\n",
            "    cat.fit(X_train, y_train, eval_set=[(X_train,y_train),(X_val,y_val)],\n",
            "  File \"c:\\Users\\ineeji\\anaconda3\\envs\\v1\\lib\\site-packages\\catboost\\core.py\", line 5734, in fit\n",
            "    return self._fit(X, y, cat_features, text_features, embedding_features, None, sample_weight, None, None, None, None, baseline,\n",
            "  File \"c:\\Users\\ineeji\\anaconda3\\envs\\v1\\lib\\site-packages\\catboost\\core.py\", line 2357, in _fit\n",
            "    self._train(\n",
            "  File \"c:\\Users\\ineeji\\anaconda3\\envs\\v1\\lib\\site-packages\\catboost\\core.py\", line 1761, in _train\n",
            "    self._object._train(train_pool, test_pool, params, allow_clear_pool, init_model._object if init_model else None)\n",
            "  File \"_catboost.pyx\", line 4624, in _catboost._CatBoost._train\n",
            "  File \"_catboost.pyx\", line 4673, in _catboost._CatBoost._train\n",
            "KeyboardInterrupt\n",
            "[W 2023-10-05 18:56:31,882] Trial 9 failed with value None.\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[1;32mc:\\Users\\ineeji\\Desktop\\HD\\XGB_v1.ipynb Cell 19\u001b[0m line \u001b[0;36m1\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/ineeji/Desktop/HD/XGB_v1.ipynb#X15sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mOptimizing hyperparameters for fold \u001b[39m\u001b[39m{\u001b[39;00mfold\u001b[39m+\u001b[39m\u001b[39m1\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m...\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/ineeji/Desktop/HD/XGB_v1.ipynb#X15sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m study \u001b[39m=\u001b[39m optuna\u001b[39m.\u001b[39mcreate_study(direction\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mminimize\u001b[39m\u001b[39m'\u001b[39m, sampler\u001b[39m=\u001b[39mTPESampler(seed\u001b[39m=\u001b[39m\u001b[39m1234\u001b[39m))\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/ineeji/Desktop/HD/XGB_v1.ipynb#X15sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m study\u001b[39m.\u001b[39;49moptimize(\u001b[39mlambda\u001b[39;49;00m trial: objective(trial, X_train, y_train, X_val, y_val\u001b[39m.\u001b[39;49mvalues), n_trials\u001b[39m=\u001b[39;49m\u001b[39m20\u001b[39;49m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/ineeji/Desktop/HD/XGB_v1.ipynb#X15sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m best_params \u001b[39m=\u001b[39m study\u001b[39m.\u001b[39mbest_params\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/ineeji/Desktop/HD/XGB_v1.ipynb#X15sZmlsZQ%3D%3D?line=17'>18</a>\u001b[0m best_score \u001b[39m=\u001b[39m study\u001b[39m.\u001b[39mbest_value\n",
            "File \u001b[1;32mc:\\Users\\ineeji\\anaconda3\\envs\\v1\\lib\\site-packages\\optuna\\study\\study.py:443\u001b[0m, in \u001b[0;36mStudy.optimize\u001b[1;34m(self, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[0;32m    339\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39moptimize\u001b[39m(\n\u001b[0;32m    340\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[0;32m    341\u001b[0m     func: ObjectiveFuncType,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    348\u001b[0m     show_progress_bar: \u001b[39mbool\u001b[39m \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m,\n\u001b[0;32m    349\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    350\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Optimize an objective function.\u001b[39;00m\n\u001b[0;32m    351\u001b[0m \n\u001b[0;32m    352\u001b[0m \u001b[39m    Optimization is done by choosing a suitable set of hyperparameter values from a given\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    440\u001b[0m \u001b[39m            If nested invocation of this method occurs.\u001b[39;00m\n\u001b[0;32m    441\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 443\u001b[0m     _optimize(\n\u001b[0;32m    444\u001b[0m         study\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m,\n\u001b[0;32m    445\u001b[0m         func\u001b[39m=\u001b[39;49mfunc,\n\u001b[0;32m    446\u001b[0m         n_trials\u001b[39m=\u001b[39;49mn_trials,\n\u001b[0;32m    447\u001b[0m         timeout\u001b[39m=\u001b[39;49mtimeout,\n\u001b[0;32m    448\u001b[0m         n_jobs\u001b[39m=\u001b[39;49mn_jobs,\n\u001b[0;32m    449\u001b[0m         catch\u001b[39m=\u001b[39;49m\u001b[39mtuple\u001b[39;49m(catch) \u001b[39mif\u001b[39;49;00m \u001b[39misinstance\u001b[39;49m(catch, Iterable) \u001b[39melse\u001b[39;49;00m (catch,),\n\u001b[0;32m    450\u001b[0m         callbacks\u001b[39m=\u001b[39;49mcallbacks,\n\u001b[0;32m    451\u001b[0m         gc_after_trial\u001b[39m=\u001b[39;49mgc_after_trial,\n\u001b[0;32m    452\u001b[0m         show_progress_bar\u001b[39m=\u001b[39;49mshow_progress_bar,\n\u001b[0;32m    453\u001b[0m     )\n",
            "File \u001b[1;32mc:\\Users\\ineeji\\anaconda3\\envs\\v1\\lib\\site-packages\\optuna\\study\\_optimize.py:66\u001b[0m, in \u001b[0;36m_optimize\u001b[1;34m(study, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[0;32m     64\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m     65\u001b[0m     \u001b[39mif\u001b[39;00m n_jobs \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[1;32m---> 66\u001b[0m         _optimize_sequential(\n\u001b[0;32m     67\u001b[0m             study,\n\u001b[0;32m     68\u001b[0m             func,\n\u001b[0;32m     69\u001b[0m             n_trials,\n\u001b[0;32m     70\u001b[0m             timeout,\n\u001b[0;32m     71\u001b[0m             catch,\n\u001b[0;32m     72\u001b[0m             callbacks,\n\u001b[0;32m     73\u001b[0m             gc_after_trial,\n\u001b[0;32m     74\u001b[0m             reseed_sampler_rng\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[0;32m     75\u001b[0m             time_start\u001b[39m=\u001b[39;49m\u001b[39mNone\u001b[39;49;00m,\n\u001b[0;32m     76\u001b[0m             progress_bar\u001b[39m=\u001b[39;49mprogress_bar,\n\u001b[0;32m     77\u001b[0m         )\n\u001b[0;32m     78\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m     79\u001b[0m         \u001b[39mif\u001b[39;00m n_jobs \u001b[39m==\u001b[39m \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m:\n",
            "File \u001b[1;32mc:\\Users\\ineeji\\anaconda3\\envs\\v1\\lib\\site-packages\\optuna\\study\\_optimize.py:163\u001b[0m, in \u001b[0;36m_optimize_sequential\u001b[1;34m(study, func, n_trials, timeout, catch, callbacks, gc_after_trial, reseed_sampler_rng, time_start, progress_bar)\u001b[0m\n\u001b[0;32m    160\u001b[0m         \u001b[39mbreak\u001b[39;00m\n\u001b[0;32m    162\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 163\u001b[0m     frozen_trial \u001b[39m=\u001b[39m _run_trial(study, func, catch)\n\u001b[0;32m    164\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[0;32m    165\u001b[0m     \u001b[39m# The following line mitigates memory problems that can be occurred in some\u001b[39;00m\n\u001b[0;32m    166\u001b[0m     \u001b[39m# environments (e.g., services that use computing containers such as GitHub Actions).\u001b[39;00m\n\u001b[0;32m    167\u001b[0m     \u001b[39m# Please refer to the following PR for further details:\u001b[39;00m\n\u001b[0;32m    168\u001b[0m     \u001b[39m# https://github.com/optuna/optuna/pull/325.\u001b[39;00m\n\u001b[0;32m    169\u001b[0m     \u001b[39mif\u001b[39;00m gc_after_trial:\n",
            "File \u001b[1;32mc:\\Users\\ineeji\\anaconda3\\envs\\v1\\lib\\site-packages\\optuna\\study\\_optimize.py:251\u001b[0m, in \u001b[0;36m_run_trial\u001b[1;34m(study, func, catch)\u001b[0m\n\u001b[0;32m    244\u001b[0m         \u001b[39massert\u001b[39;00m \u001b[39mFalse\u001b[39;00m, \u001b[39m\"\u001b[39m\u001b[39mShould not reach.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    246\u001b[0m \u001b[39mif\u001b[39;00m (\n\u001b[0;32m    247\u001b[0m     frozen_trial\u001b[39m.\u001b[39mstate \u001b[39m==\u001b[39m TrialState\u001b[39m.\u001b[39mFAIL\n\u001b[0;32m    248\u001b[0m     \u001b[39mand\u001b[39;00m func_err \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m    249\u001b[0m     \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(func_err, catch)\n\u001b[0;32m    250\u001b[0m ):\n\u001b[1;32m--> 251\u001b[0m     \u001b[39mraise\u001b[39;00m func_err\n\u001b[0;32m    252\u001b[0m \u001b[39mreturn\u001b[39;00m frozen_trial\n",
            "File \u001b[1;32mc:\\Users\\ineeji\\anaconda3\\envs\\v1\\lib\\site-packages\\optuna\\study\\_optimize.py:200\u001b[0m, in \u001b[0;36m_run_trial\u001b[1;34m(study, func, catch)\u001b[0m\n\u001b[0;32m    198\u001b[0m \u001b[39mwith\u001b[39;00m get_heartbeat_thread(trial\u001b[39m.\u001b[39m_trial_id, study\u001b[39m.\u001b[39m_storage):\n\u001b[0;32m    199\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 200\u001b[0m         value_or_values \u001b[39m=\u001b[39m func(trial)\n\u001b[0;32m    201\u001b[0m     \u001b[39mexcept\u001b[39;00m exceptions\u001b[39m.\u001b[39mTrialPruned \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    202\u001b[0m         \u001b[39m# TODO(mamu): Handle multi-objective cases.\u001b[39;00m\n\u001b[0;32m    203\u001b[0m         state \u001b[39m=\u001b[39m TrialState\u001b[39m.\u001b[39mPRUNED\n",
            "\u001b[1;32mc:\\Users\\ineeji\\Desktop\\HD\\XGB_v1.ipynb Cell 19\u001b[0m line \u001b[0;36m1\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/ineeji/Desktop/HD/XGB_v1.ipynb#X15sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mOptimizing hyperparameters for fold \u001b[39m\u001b[39m{\u001b[39;00mfold\u001b[39m+\u001b[39m\u001b[39m1\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m...\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/ineeji/Desktop/HD/XGB_v1.ipynb#X15sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m study \u001b[39m=\u001b[39m optuna\u001b[39m.\u001b[39mcreate_study(direction\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mminimize\u001b[39m\u001b[39m'\u001b[39m, sampler\u001b[39m=\u001b[39mTPESampler(seed\u001b[39m=\u001b[39m\u001b[39m1234\u001b[39m))\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/ineeji/Desktop/HD/XGB_v1.ipynb#X15sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m study\u001b[39m.\u001b[39moptimize(\u001b[39mlambda\u001b[39;00m trial: objective(trial, X_train, y_train, X_val, y_val\u001b[39m.\u001b[39;49mvalues), n_trials\u001b[39m=\u001b[39m\u001b[39m20\u001b[39m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/ineeji/Desktop/HD/XGB_v1.ipynb#X15sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m best_params \u001b[39m=\u001b[39m study\u001b[39m.\u001b[39mbest_params\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/ineeji/Desktop/HD/XGB_v1.ipynb#X15sZmlsZQ%3D%3D?line=17'>18</a>\u001b[0m best_score \u001b[39m=\u001b[39m study\u001b[39m.\u001b[39mbest_value\n",
            "\u001b[1;32mc:\\Users\\ineeji\\Desktop\\HD\\XGB_v1.ipynb Cell 19\u001b[0m line \u001b[0;36m5\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/ineeji/Desktop/HD/XGB_v1.ipynb#X15sZmlsZQ%3D%3D?line=52'>53</a>\u001b[0m \u001b[39m#'task_type' : 'GPU',\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/ineeji/Desktop/HD/XGB_v1.ipynb#X15sZmlsZQ%3D%3D?line=53'>54</a>\u001b[0m \u001b[39m#\"eval_metric\":'RMSE',\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/ineeji/Desktop/HD/XGB_v1.ipynb#X15sZmlsZQ%3D%3D?line=54'>55</a>\u001b[0m cat \u001b[39m=\u001b[39m CatBoostRegressor(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mparams)\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/ineeji/Desktop/HD/XGB_v1.ipynb#X15sZmlsZQ%3D%3D?line=55'>56</a>\u001b[0m cat\u001b[39m.\u001b[39;49mfit(X_train, y_train, eval_set\u001b[39m=\u001b[39;49m[(X_train,y_train),(X_val,y_val)],\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/ineeji/Desktop/HD/XGB_v1.ipynb#X15sZmlsZQ%3D%3D?line=56'>57</a>\u001b[0m           verbose\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/ineeji/Desktop/HD/XGB_v1.ipynb#X15sZmlsZQ%3D%3D?line=57'>58</a>\u001b[0m cat_pred \u001b[39m=\u001b[39m cat\u001b[39m.\u001b[39mpredict(X_val)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/ineeji/Desktop/HD/XGB_v1.ipynb#X15sZmlsZQ%3D%3D?line=58'>59</a>\u001b[0m score \u001b[39m=\u001b[39m mean_absolute_error(y_val, cat_pred)\n",
            "File \u001b[1;32mc:\\Users\\ineeji\\anaconda3\\envs\\v1\\lib\\site-packages\\catboost\\core.py:5734\u001b[0m, in \u001b[0;36mCatBoostRegressor.fit\u001b[1;34m(self, X, y, cat_features, text_features, embedding_features, sample_weight, baseline, use_best_model, eval_set, verbose, logging_level, plot, plot_file, column_description, verbose_eval, metric_period, silent, early_stopping_rounds, save_snapshot, snapshot_file, snapshot_interval, init_model, callbacks, log_cout, log_cerr)\u001b[0m\n\u001b[0;32m   5731\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39m'\u001b[39m\u001b[39mloss_function\u001b[39m\u001b[39m'\u001b[39m \u001b[39min\u001b[39;00m params:\n\u001b[0;32m   5732\u001b[0m     CatBoostRegressor\u001b[39m.\u001b[39m_check_is_compatible_loss(params[\u001b[39m'\u001b[39m\u001b[39mloss_function\u001b[39m\u001b[39m'\u001b[39m])\n\u001b[1;32m-> 5734\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_fit(X, y, cat_features, text_features, embedding_features, \u001b[39mNone\u001b[39;49;00m, sample_weight, \u001b[39mNone\u001b[39;49;00m, \u001b[39mNone\u001b[39;49;00m, \u001b[39mNone\u001b[39;49;00m, \u001b[39mNone\u001b[39;49;00m, baseline,\n\u001b[0;32m   5735\u001b[0m                  use_best_model, eval_set, verbose, logging_level, plot, plot_file, column_description,\n\u001b[0;32m   5736\u001b[0m                  verbose_eval, metric_period, silent, early_stopping_rounds,\n\u001b[0;32m   5737\u001b[0m                  save_snapshot, snapshot_file, snapshot_interval, init_model, callbacks, log_cout, log_cerr)\n",
            "File \u001b[1;32mc:\\Users\\ineeji\\anaconda3\\envs\\v1\\lib\\site-packages\\catboost\\core.py:2357\u001b[0m, in \u001b[0;36mCatBoost._fit\u001b[1;34m(self, X, y, cat_features, text_features, embedding_features, pairs, sample_weight, group_id, group_weight, subgroup_id, pairs_weight, baseline, use_best_model, eval_set, verbose, logging_level, plot, plot_file, column_description, verbose_eval, metric_period, silent, early_stopping_rounds, save_snapshot, snapshot_file, snapshot_interval, init_model, callbacks, log_cout, log_cerr)\u001b[0m\n\u001b[0;32m   2353\u001b[0m allow_clear_pool \u001b[39m=\u001b[39m train_params[\u001b[39m\"\u001b[39m\u001b[39mallow_clear_pool\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[0;32m   2355\u001b[0m \u001b[39mwith\u001b[39;00m log_fixup(log_cout, log_cerr), \\\n\u001b[0;32m   2356\u001b[0m     plot_wrapper(plot, plot_file, \u001b[39m'\u001b[39m\u001b[39mTraining plots\u001b[39m\u001b[39m'\u001b[39m, [_get_train_dir(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mget_params())]):\n\u001b[1;32m-> 2357\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_train(\n\u001b[0;32m   2358\u001b[0m         train_pool,\n\u001b[0;32m   2359\u001b[0m         train_params[\u001b[39m\"\u001b[39;49m\u001b[39meval_sets\u001b[39;49m\u001b[39m\"\u001b[39;49m],\n\u001b[0;32m   2360\u001b[0m         params,\n\u001b[0;32m   2361\u001b[0m         allow_clear_pool,\n\u001b[0;32m   2362\u001b[0m         train_params[\u001b[39m\"\u001b[39;49m\u001b[39minit_model\u001b[39;49m\u001b[39m\"\u001b[39;49m]\n\u001b[0;32m   2363\u001b[0m     )\n\u001b[0;32m   2365\u001b[0m \u001b[39m# Have property feature_importance possibly set\u001b[39;00m\n\u001b[0;32m   2366\u001b[0m loss \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_object\u001b[39m.\u001b[39m_get_loss_function_name()\n",
            "File \u001b[1;32mc:\\Users\\ineeji\\anaconda3\\envs\\v1\\lib\\site-packages\\catboost\\core.py:1761\u001b[0m, in \u001b[0;36m_CatBoostBase._train\u001b[1;34m(self, train_pool, test_pool, params, allow_clear_pool, init_model)\u001b[0m\n\u001b[0;32m   1760\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_train\u001b[39m(\u001b[39mself\u001b[39m, train_pool, test_pool, params, allow_clear_pool, init_model):\n\u001b[1;32m-> 1761\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_object\u001b[39m.\u001b[39;49m_train(train_pool, test_pool, params, allow_clear_pool, init_model\u001b[39m.\u001b[39;49m_object \u001b[39mif\u001b[39;49;00m init_model \u001b[39melse\u001b[39;49;00m \u001b[39mNone\u001b[39;49;00m)\n\u001b[0;32m   1762\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_set_trained_model_attributes()\n",
            "File \u001b[1;32m_catboost.pyx:4624\u001b[0m, in \u001b[0;36m_catboost._CatBoost._train\u001b[1;34m()\u001b[0m\n",
            "File \u001b[1;32m_catboost.pyx:4673\u001b[0m, in \u001b[0;36m_catboost._CatBoost._train\u001b[1;34m()\u001b[0m\n",
            "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "train_x = train.drop(['CI_HOUR'],axis=1)\n",
        "train_y = train[['CI_HOUR']]\n",
        "\n",
        "kf = KFold(n_splits=5, shuffle=True, random_state=3553)\n",
        "fold_results = []\n",
        "test_predictions = []\n",
        "\n",
        "# 각 Fold에 대해서 Optuna로 하이퍼파라미터 튜닝\n",
        "for fold, (train_index, val_index) in enumerate(kf.split(train_x)):\n",
        "    X_train, X_val = train_x.iloc[train_index, :], train_x.iloc[val_index, :]\n",
        "    y_train, y_val = train_y.iloc[train_index, :], train_y.iloc[val_index, :]\n",
        "\n",
        "    print(f\"Optimizing hyperparameters for fold {fold+1}...\")\n",
        "    study = optuna.create_study(direction='minimize', sampler=TPESampler(seed=1234))\n",
        "    study.optimize(lambda trial: objective(trial, X_train, y_train, X_val, y_val.values), n_trials=20)\n",
        "\n",
        "    best_params = study.best_params\n",
        "    best_score = study.best_value\n",
        "    \n",
        "    print(f\"Best RMSE for fold {fold+1}: {best_score}\")\n",
        "    print(f\"Best hyperparameters for fold {fold+1}: {best_params}\")\n",
        "    \n",
        "    fold_results.append({\n",
        "        'fold': fold+1,\n",
        "        'best_score': best_score,\n",
        "        'best_params': best_params\n",
        "    })\n",
        "    \n",
        "    # 최적의 하이퍼파라미터로 테스트 데이터 예측\n",
        "    model = CatBoostRegressor(**best_params)\n",
        "    model.fit(X_train, y_train, cat_features=cat_features)\n",
        "    test_pred = model.predict(test)\n",
        "    test_predictions.append(test_pred)\n",
        "\n",
        "# 평균 앙상블\n",
        "final_prediction = np.mean(test_predictions, axis=0)\n",
        "\n",
        "# 결과 출력\n",
        "for result in fold_results:\n",
        "    print(f\"Fold {result['fold']}, Best MAE: {result['best_score']}, Best hyperparameters: {result['best_params']}\")\n",
        "\n",
        "# 최종 예측 저장\n",
        "final_prediction_df = pd.DataFrame(final_prediction, columns=['MLM'])\n",
        "submission['CI_HOUR'] = final_prediction"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P3oVH9QIxrAc"
      },
      "outputs": [],
      "source": [
        "submission.to_csv('XGB_Optuna_915.csv', index = False, encoding = \"utf-8-sig\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {
        "id": "bHexh3orVzUq"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>AlogP</th>\n",
              "      <th>Molecular_Weight</th>\n",
              "      <th>Num_H_Acceptors</th>\n",
              "      <th>Num_H_Donors</th>\n",
              "      <th>Num_RotatableBonds</th>\n",
              "      <th>LogD</th>\n",
              "      <th>Molecular_PolarSurfaceArea</th>\n",
              "      <th>nAcid</th>\n",
              "      <th>nBase</th>\n",
              "      <th>SpAbs_A</th>\n",
              "      <th>...</th>\n",
              "      <th>MACCS_key_158</th>\n",
              "      <th>MACCS_key_159</th>\n",
              "      <th>MACCS_key_160</th>\n",
              "      <th>MACCS_key_161</th>\n",
              "      <th>MACCS_key_162</th>\n",
              "      <th>MACCS_key_163</th>\n",
              "      <th>MACCS_key_164</th>\n",
              "      <th>MACCS_key_165</th>\n",
              "      <th>MLM</th>\n",
              "      <th>HLM</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>3.259</td>\n",
              "      <td>400.495</td>\n",
              "      <td>5</td>\n",
              "      <td>2</td>\n",
              "      <td>8</td>\n",
              "      <td>3.259</td>\n",
              "      <td>117.37</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>35.689316</td>\n",
              "      <td>...</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>26.010</td>\n",
              "      <td>50.680</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2.169</td>\n",
              "      <td>301.407</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>2.172</td>\n",
              "      <td>73.47</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>26.575899</td>\n",
              "      <td>...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>29.270</td>\n",
              "      <td>50.590</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1.593</td>\n",
              "      <td>297.358</td>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>1.585</td>\n",
              "      <td>62.45</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>29.802128</td>\n",
              "      <td>...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>5.586</td>\n",
              "      <td>80.892</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4.771</td>\n",
              "      <td>494.652</td>\n",
              "      <td>6</td>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "      <td>3.475</td>\n",
              "      <td>92.60</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>45.884166</td>\n",
              "      <td>...</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>5.710</td>\n",
              "      <td>2.000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2.335</td>\n",
              "      <td>268.310</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>2.337</td>\n",
              "      <td>42.43</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>26.308663</td>\n",
              "      <td>...</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>93.270</td>\n",
              "      <td>99.990</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3466</th>\n",
              "      <td>3.409</td>\n",
              "      <td>396.195</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>5</td>\n",
              "      <td>3.409</td>\n",
              "      <td>64.74</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>30.902711</td>\n",
              "      <td>...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1.556</td>\n",
              "      <td>3.079</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3467</th>\n",
              "      <td>1.912</td>\n",
              "      <td>359.381</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>1.844</td>\n",
              "      <td>77.37</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>35.887372</td>\n",
              "      <td>...</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>35.560</td>\n",
              "      <td>47.630</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3468</th>\n",
              "      <td>1.941</td>\n",
              "      <td>261.320</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>6</td>\n",
              "      <td>2.124</td>\n",
              "      <td>70.14</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>23.546531</td>\n",
              "      <td>...</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>56.150</td>\n",
              "      <td>1.790</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3469</th>\n",
              "      <td>0.989</td>\n",
              "      <td>284.696</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>5</td>\n",
              "      <td>0.989</td>\n",
              "      <td>91.51</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>23.936088</td>\n",
              "      <td>...</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0.030</td>\n",
              "      <td>2.770</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3470</th>\n",
              "      <td>4.321</td>\n",
              "      <td>295.399</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>4.321</td>\n",
              "      <td>50.36</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>27.713581</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0.450</td>\n",
              "      <td>2.650</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>3471 rows × 5313 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "      AlogP  Molecular_Weight  Num_H_Acceptors  Num_H_Donors  \\\n",
              "0     3.259           400.495                5             2   \n",
              "1     2.169           301.407                2             1   \n",
              "2     1.593           297.358                5             0   \n",
              "3     4.771           494.652                6             0   \n",
              "4     2.335           268.310                3             0   \n",
              "...     ...               ...              ...           ...   \n",
              "3466  3.409           396.195                3             1   \n",
              "3467  1.912           359.381                4             1   \n",
              "3468  1.941           261.320                3             1   \n",
              "3469  0.989           284.696                5             1   \n",
              "3470  4.321           295.399                2             0   \n",
              "\n",
              "      Num_RotatableBonds   LogD  Molecular_PolarSurfaceArea  nAcid  nBase  \\\n",
              "0                      8  3.259                      117.37      0      0   \n",
              "1                      2  2.172                       73.47      0      0   \n",
              "2                      3  1.585                       62.45      2      1   \n",
              "3                      5  3.475                       92.60      0      1   \n",
              "4                      1  2.337                       42.43      0      0   \n",
              "...                  ...    ...                         ...    ...    ...   \n",
              "3466                   5  3.409                       64.74      0      0   \n",
              "3467                   3  1.844                       77.37      0      0   \n",
              "3468                   6  2.124                       70.14      0      0   \n",
              "3469                   5  0.989                       91.51      0      0   \n",
              "3470                   4  4.321                       50.36      0      0   \n",
              "\n",
              "        SpAbs_A  ...  MACCS_key_158  MACCS_key_159  MACCS_key_160  \\\n",
              "0     35.689316  ...              1              1              1   \n",
              "1     26.575899  ...              1              0              1   \n",
              "2     29.802128  ...              1              0              1   \n",
              "3     45.884166  ...              1              1              1   \n",
              "4     26.308663  ...              1              1              1   \n",
              "...         ...  ...            ...            ...            ...   \n",
              "3466  30.902711  ...              1              0              1   \n",
              "3467  35.887372  ...              1              1              1   \n",
              "3468  23.546531  ...              1              1              1   \n",
              "3469  23.936088  ...              1              1              0   \n",
              "3470  27.713581  ...              0              0              1   \n",
              "\n",
              "      MACCS_key_161  MACCS_key_162  MACCS_key_163  MACCS_key_164  \\\n",
              "0                 1              1              1              1   \n",
              "1                 1              1              1              1   \n",
              "2                 1              1              1              0   \n",
              "3                 1              1              1              1   \n",
              "4                 1              1              1              1   \n",
              "...             ...            ...            ...            ...   \n",
              "3466              1              1              0              1   \n",
              "3467              1              1              1              1   \n",
              "3468              1              1              1              1   \n",
              "3469              1              1              1              1   \n",
              "3470              1              1              1              1   \n",
              "\n",
              "      MACCS_key_165     MLM     HLM  \n",
              "0                 1  26.010  50.680  \n",
              "1                 1  29.270  50.590  \n",
              "2                 1   5.586  80.892  \n",
              "3                 1   5.710   2.000  \n",
              "4                 1  93.270  99.990  \n",
              "...             ...     ...     ...  \n",
              "3466              1   1.556   3.079  \n",
              "3467              1  35.560  47.630  \n",
              "3468              1  56.150   1.790  \n",
              "3469              1   0.030   2.770  \n",
              "3470              1   0.450   2.650  \n",
              "\n",
              "[3471 rows x 5313 columns]"
            ]
          },
          "execution_count": 58,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.16"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
